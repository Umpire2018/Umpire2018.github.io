<!doctype html><html lang=zh-Hans dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="版本所有：© 2023 Reworkd AI, Inc. 原文链接：Reworkd Blog 生成式预训练变换器（GPT）的发明是近十年来人工智能技术最重要的进步之一。为当今的大型语言模型"><title>洞悉 Agent-GPT</title><link rel=canonical href=https://umpire2018.github.io/p/%E6%B4%9E%E6%82%89-agent-gpt/><link rel=stylesheet href=/scss/style.min.abbd69b2908fdfcd5179898beaafd374514a86538d81639ddd2c58c06ae54e40.css><meta property="og:title" content="洞悉 Agent-GPT"><meta property="og:description" content="版本所有：© 2023 Reworkd AI, Inc. 原文链接：Reworkd Blog 生成式预训练变换器（GPT）的发明是近十年来人工智能技术最重要的进步之一。为当今的大型语言模型"><meta property="og:url" content="https://umpire2018.github.io/p/%E6%B4%9E%E6%82%89-agent-gpt/"><meta property="og:site_name" content="Arno's Blog"><meta property="og:type" content="article"><meta property="article:section" content="Post"><meta property="article:published_time" content="2023-09-21T20:07:13+08:00"><meta property="article:modified_time" content="2023-09-21T20:07:13+08:00"><meta name=twitter:title content="洞悉 Agent-GPT"><meta name=twitter:description content="版本所有：© 2023 Reworkd AI, Inc. 原文链接：Reworkd Blog 生成式预训练变换器（GPT）的发明是近十年来人工智能技术最重要的进步之一。为当今的大型语言模型"><link rel="shortcut icon" href=/favicon.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu648d6f62cb85fc48f15853bd9bc5009b_4973957_300x0_resize_box_3.png width=300 height=240 class=site-logo loading=lazy alt=Avatar></a>
<span class=emoji>😁</span></figure><div class=site-meta><h1 class=site-name><a href=/>Arno's Blog</a></h1><h2 class=site-description>悟已往者不谏,知来者知可追</h2></div></header><ol class=social-menu><li><a href=https://github.com/Umpire2018 target=_blank title=GitHub rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=https://twitter.com target=_blank title=Twitter rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-twitter" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M22 4.01c-1 .49-1.98.689-3 .99-1.121-1.265-2.783-1.335-4.38-.737S11.977 6.323 12 8v1c-3.245.083-6.135-1.395-8-4 0 0-4.182 7.433 4 11-1.872 1.247-3.739 2.088-6 2 3.308 1.803 6.913 2.423 10.034 1.517 3.58-1.04 6.522-3.723 7.651-7.742a13.84 13.84.0 00.497-3.753C20.18 7.773 21.692 5.25 22 4.009z"/></svg></a></li></ol><ol class=menu id=main-menu><li class=current><a href=/post/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg><span>Home</span></a></li><li><a href=/archives/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg><span>Archives</span></a></li><li><a href=/search/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg><span>Search</span></a></li><li><a href=/links/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg><span>Links</span></a></li><div class=menu-bottom-section><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><span>暗色模式</span></li></div></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#llm-有很多限制>LLM 有很多限制</a></li><li><a href=#what-are-agents什么是代理>What are agents? 什么是代理？</a><ol><li><a href=#engineering-this-system-consists-of-3-parts该系统的工程由-3-部分组成>Engineering this system consists of 3 parts.该系统的工程由 3 部分组成。</a></li></ol></li><li><a href=#how-do-we-get-agents-to-act-intelligently我们如何让代理人明智地行动>How do we get agents to act intelligently?我们如何让代理人明智地行动？</a><ol><li><a href=#a-brief-intro-to-prompt-engineering快速工程简介>A Brief Intro to Prompt Engineering快速工程简介</a></li><li><a href=#how-agentgpt-uses-prompt-engineeringagentgpt-如何使用即时工程>How AgentGPT Uses Prompt EngineeringAgentGPT 如何使用即时工程</a></li></ol></li><li><a href=#how-do-we-give-agents-a-working-memory我们如何为代理提供工作记忆>How do we give agents a working memory?我们如何为代理提供工作记忆？</a><ol><li><a href=#vector-databases-demystified揭秘矢量数据库>Vector Databases Demystified揭秘矢量数据库</a></li><li><a href=#vector-libraries-like向量库如>Vector libraries like 向量库如</a></li></ol></li><li><a href=#tools-to-interact-with-the-environment与环境交互的工具>Tools to interact with the environment与环境交互的工具</a><ol><li><a href=#engineering-robust-function-calls工程稳健的函数调用>Engineering Robust Function Calls工程稳健的函数调用</a></li></ol></li><li><a href=#the-future-of-llm-powered-agents-is-brightllm-代理人的未来是光明的>The future of LLM-powered agents is bright!LLM 代理人的未来是光明的！</a></li><li><a href=#conclusion结论>Conclusion 结论</a></li></ol></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/categories/ai/>AI</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/%E6%B4%9E%E6%82%89-agent-gpt/>洞悉 Agent-GPT</a></h2></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg><time class=article-time--published>Sep 21, 2023</time></div><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg><time class=article-time--reading>阅读时长: 16 分钟</time></div></footer></div></header><section class=article-content><blockquote><p>版本所有：© 2023 Reworkd AI, Inc.</p><p>原文链接：<a class=link href=https://reworkd.ai/blog/Understanding-AgentGPT target=_blank rel=noopener>Reworkd Blog</a></p></blockquote><p>生成式预训练变换器（GPT）的发明是近十年来人工智能技术最重要的进步之一。为当今的大型语言模型 (LLM) 提供支持的 GPT 展示了卓越的推理、理解和规划能力。然而，它们的真正潜力尚未完全发挥。</p><p>在 Reworkd，我们相信 LLMs 的真正力量在于代理行为。通过设计一个利用 LLM 的新兴能力的系统并提供支持环境相互作用的生态系统，我们可以充分发挥 GPT-4 等模型的潜力。以下是 AgentGPT 的工作原理。</p><h2 id=llm-有很多限制>LLM 有很多限制</h2><p><a class=link href=https://www.techopedia.com/definition/34826/foundation-model target=_blank rel=noopener>Foundation Model - Techopedia</a>. 基础模型 - 技术百科。</p><p>如果您熟悉 OpenAI 的 API，则与模型聊天时可能使用的常用公式可能包括：</p><ul><li>获取用户指令。</li><li>添加聊天历史。</li><li>通过 API 发送聊天历史记录以获取回答。</li></ul><p>当对话范围较小时，此方法效果很好；然而，当您继续向聊天历史记录中添加新消息时，完成的大小和复杂性会不断增加，您很快就会碰壁：可怕的上下文限制。</p><p>首先引入 <strong>tokens</strong> 这个概念，形如 字 word 是人类来计算文本长度的最小单位（比如一句话有十个字），而 tokens 则是自然语言处理文本长度的最小单位。数据表明，一个汉字平均在 ChatGPT(GPT3.5和GPT4) 下大概消耗1.12个token。而在一次与 Model 进行交互的过程中，上下文限制则是在一次交互过程中可以输入到模型中的最大标记数。随着我们添加更多的 tokens ，Model 用于计算的成本往往呈指数增长，所以这往往是提示工程师的孽缘。</p><p>一种解决方案是统计聊天历史记录中的 token 数量，将旧消息删除再将其发送到 Model 中以确保其符合 token 限制。虽然这种方法有效，但它最终会减少可用于求知的知识量。</p><p>LLM 们面临的另一个问题是需要人工指导。从根本上说，LLM 们用来预测下一个词的，通常，它们的内部结构本质上并不适合高阶思维过程，例如通过复杂任务进行推理。但这种不足并不意味着它们不能或不会<strong>推理</strong>。事实上，有几项 <a class=link href=https://arxiv.org/abs/2205.11916 target=_blank rel=noopener>研究</a> 表明它们可以。然而，这确实意味着它们面临某些障碍。例如，LLM 自身可以创建一个逻辑步骤列表；然而，它没有观察和反思该清单的内置机制。</p><p>A pre-trained model is essentially a &ldquo;black box&rdquo; for the end user in which the final product that is shipped has <em>limited to no capability of actively updating its knowledge base and tends to act in unpredictable ways</em>. As a result, it&rsquo;s <a class=link href=https://arxiv.org/abs/2202.03629 target=_blank rel=noopener>hallucination</a>-prone.对于最终用户来说，预训练模型本质上是一个“黑匣子”，其最终交付的产品几乎没有主动更新其知识库的能力，并且往往以不可预测的方式运行，所以很容易产生<a class=link href=https://arxiv.org/abs/2202.03629 target=_blank rel=noopener>幻觉</a>。</p><p>Thus, it requires a lot of effort on the user&rsquo;s part to guide the model&rsquo;s output, and prompting the LLM itself becomes a job on its own. This extra work is a far cry from our vision of an AI-powered future.因此，需要用户付出很大的努力来指导模型的输出，而促使LLM本身就成为了一项工作。这项额外的工作与我们对人工智能驱动的未来的愿景相去甚远。</p><p>By providing a platform to give LLMs agentic abilities, <em>AgentGPT aims to overcome the limitations of standalone LLMs by leveraging prompt engineering techniques, vector databases, and API tooling.</em> Here’s some interesting work that is being done with the agent concept:通过提供一个平台来赋予法学硕士代理能力，AgentGPT 旨在利用即时工程技术、矢量数据库和 API 工具来克服独立法学硕士的局限性。以下是利用代理概念所做的一些有趣的工作：</p><p><a class=link href=https://twitter.com/DrJimFan/status/1673006745067847683 target=_blank rel=noopener><img src="https://platform.twitter.com/embed/Tweet.html?dnt=false&amp;embedId=twitter-widget-0&amp;frame=false&amp;hideCard=false&amp;hideThread=false&amp;id=1673006745067847683&amp;lang=en&amp;origin=https%3A%2F%2Fpublish.twitter.com%2F%3Fquery%3Dhttps3A2F2Ftwitter.com2FDrJimFan2Fstatus2F1673006745067847683%26widget%3DTweet&amp;theme=light&amp;widgetsVersion=82e1070%3A1619632193066&amp;width=550px" loading=lazy alt="Tweet by Dr. Jim Fan"></a></p><blockquote><p>Alt: A Twitter post by Dr. Jim FanAlt：Jim Fan 博士的 Twitter 帖子</p></blockquote><h2 id=what-are-agents什么是代理>What are agents? 什么是代理？</h2><p>In a general sense, <a class=link href=https://zapier.com/blog/ai-agent/ target=_blank rel=noopener>agents</a> are rational actors. They use thinking and reasoning to influence their environment. <em>This could be in the form of solving problems or pursuing specific goals. They might interact with humans or utilize tools.</em> Ultimately, we can apply this concept to LLMs to instill more intelligent and logical behavior.
一般意义上，代理人是理性的行为者。他们利用思考和推理来影响他们的环境。这可以是解决问题或追求特定目标的形式。他们可能与人类互动或使用工具。最终，我们可以将这一概念应用于法学硕士，以灌输更多智能和逻辑行为。</p><p>In AgentGPT, large language models essentially function as the <strong>brain</strong> of each agent. As a result, we can produce powerful agents by cleverly <em>manipulating the English language</em> and engineering a <em>framework that supports interoperability between LLM completions and a diverse set of APIs</em>.
在 AgentGPT 中，大型语言模型本质上充当每个代理的大脑。因此，我们可以通过巧妙地操作英语并设计一个支持 LLM 完成和各种 API 之间互操作性的框架来生产强大的代理。</p><h3 id=engineering-this-system-consists-of-3-parts该系统的工程由-3-部分组成>Engineering this system consists of 3 parts.该系统的工程由 3 部分组成。</h3><p><strong>Reasoning and Planning.</strong> If you were to simply take a general goal, such as &ldquo;build a scaling e-commerce platform,&rdquo; and give it to ChatGPT, you would likely get a response along the lines of &ldquo;As an AI language model….&rdquo; However, through <strong>prompt engineering</strong>, we can get a model to <em>break down goals into digestible steps and reflect on them</em> with a method called chain of thought prompting.
推理和计划。如果您只是简单地提出一个总体目标，例如“构建一个可扩展的电子商务平台”，并将其交给 ChatGPT，您可能会得到类似“作为人工智能语言模型&mldr;&mldr;”的响应。然而，通过提示工程，我们可以得到一个模型，将目标分解为可消化的步骤，并用一种称为思维链提示的方法对其进行反思。</p><p><strong>Memory.</strong> When dealing with memory, we divide the problem into <strong>short-term</strong> and <strong>long-term</strong>. In managing short-term memory, we can use prompting techniques such as <em>few-shot prompting to steer LLM responses</em>. However, <em>cost and context limits make it tricky to generate completions without limiting the breadth of information</em> a model can use to make decisions.
记忆。在处理记忆时，我们将问题分为短期和长期。在管理短期记忆时，我们可以使用提示技术（例如几次提示）来引导法学硕士的反应。然而，成本和上下文限制使得在不限制模型可用于做出决策的信息广度的情况下生成完成结果变得很棘手。</p><p>Similarly, this issue also arises in <strong>long-term memory</strong> because it would be impossible to provide an appropriate corpus of writing to bridge the gap between GPT -4&rsquo;s cutoff date, 2021, till today. By using vector databases, we attempt to overcome this using specialized models for <em>information retrieval in high-dimensional vector spaces</em>.
同样，这个问题也出现在长期记忆中，因为不可能提供适当的写作语料库来弥合 GPT -4 的截止日期 2021 年与今天之间的差距。通过使用向量数据库，我们尝试使用高维向量空间中的信息检索专用模型来克服这个问题。</p><p><strong>Tools</strong>. Another challenge in using LLMs as general actors is their confinement to text outputs. Again, we can use prompt engineering techniques to solve this issue. We can generate predictable function calls from the LLM through few-shot and chain-of-thought methods, utilizing API tools like <strong>Google Search</strong>, <strong>Hugging Face</strong>, <strong>Dall-E</strong>, etc. In addition, we can use fine-tuned LLMs that only return responses in specialized formatting, like JSON. This is the approach OpenAI took when they recently released the function calling feature for their API.
工具。使用法学硕士作为一般参与者的另一个挑战是它们仅限于文本输出。同样，我们可以使用及时的工程技术来解决这个问题。我们可以利用 Google Search、Hugging Face、Dall-E 等 API 工具，通过少样本和思维链方法从 LLM 生成可预测的函数调用。此外，我们可以使用仅返回的微调 LLM采用特殊格式的响应，例如 JSON。这是 OpenAI 最近发布其 API 的函数调用功能时所采用的方法。</p><p>These three concepts have formed the backbone of multiple successful agent-based LLM platforms such as <a class=link href=https://github.com/microsoft/JARVIS target=_blank rel=noopener>Microsoft Jarvis</a>, <a class=link href=https://github.com/Significant-Gravitas/Auto-GPT target=_blank rel=noopener>AutoGPT</a>, <a class=link href=https://github.com/yoheinakajima/babyagi target=_blank rel=noopener>BabyAGI</a>, and of course, AgentGPT. With this brief overview in mind, let&rsquo;s dive deeper into each component.
这三个概念构成了多个成功的基于代理的 LLM 平台的支柱，例如 Microsoft Jarvis、AutoGPT、BabyAGI，当然还有 AgentGPT。记住这个简短的概述，让我们更深入地了解每个组件。</p><h2 id=how-do-we-get-agents-to-act-intelligently我们如何让代理人明智地行动>How do we get agents to act intelligently?我们如何让代理人明智地行动？</h2><p><strong>Prompt engineering</strong> has become highly popularized, and it&rsquo;s only natural given its ability to <em>increase the reliability of LLM responses</em>, opening a wide avenue of potential applications for generative AI. AgentGPT&rsquo;s ability to think and reason is a result of novel prompting methods.
即时工程已经高度普及，考虑到它能够提高法学硕士反应的可靠性，为生成式人工智能的潜在应用开辟了广阔的途径，这是很自然的。 AgentGPT 的思考和推理能力是新颖的提示方法的结果。</p><h3 id=a-brief-intro-to-prompt-engineering快速工程简介>A Brief Intro to Prompt Engineering快速工程简介</h3><p>Prompt engineering is a largely empirical field that aims to find methods to steer LLM responses by finding clever ways to use the English language. *You can think of it like lawyering, where every nuance in the wording of a prompt counts.
即时工程是一个很大程度上是经验性的领域，旨在通过巧妙地使用英语来找到指导 LLM 反应的方法。你可以把它想象成律师，提示措辞中的每一个细微差别都很重要。</p><p>These are the main concepts and building blocks for more advanced prompting techniques:这些是更高级提示技术的主要概念和构建模块：</p><ol><li><strong>Zero-Shot</strong> involves sending the raw command directly to the LLM with little to no formatting.零射击涉及将原始命令直接发送到 LLM，几乎不需要格式化。</li><li><strong>Few-Shot</strong> gives context for completions in the form of example responses.Few-Shot 以示例响应的形式提供完成的上下文。</li><li><strong>Chain-of-Thought</strong> guides the model in reasoning through generating and reasoning over a complex task.思想链通过对复杂任务的生成和推理来指导模型进行推理。</li></ol><h3 id=how-agentgpt-uses-prompt-engineeringagentgpt-如何使用即时工程>How AgentGPT Uses Prompt EngineeringAgentGPT 如何使用即时工程</h3><p>AgentGPT uses an advanced form of chain-of-thought prompting called <strong>Plan-and-Solve</strong> to generate the steps you see when operating the agents.AgentGPT 使用一种称为“计划与解决”的高级思维链提示形式来生成您在操作代理时看到的步骤。</p><p>Traditionally, chain-of-thought prompting utilized few-shot techniques to provide examples of a thinking and reasoning process. However, as is becomes a theme, it becomes more costly as the complexity of a task increases because we will need to provide more context.
传统上，思维链提示利用小样本技术来提供思维和推理过程的示例。然而，当它成为一个主题时，随着任务复杂性的增加，它的成本也会变得更高，因为我们需要提供更多的上下文。</p><p><strong>Plan-and-solve (PS):</strong> By virtue of being a zero-shot method, it provides a <em>prompting framework for LLM-guided reasoning using &ldquo;trigger&rdquo; words</em>. These keywords trigger a reasoning response from the model.计划与解决（PS）：由于是一种零样本方法，它为使用“触发”词的 LLM 引导推理提供了一个提示框架。这些关键字触发模型的推理响应。</p><p>We can expand on this concept by <em>modifying the prompt to extract important variables and steps to generate a final response with a cohesive format</em>. This method allows us to parse the final response and display it for the end user as well as feed sub-steps into future plan-and-solve prompts.我们可以通过修改提取重要变量的提示和生成具有内聚格式的最终响应的步骤来扩展这个概念。此方法允许我们解析最终响应并将其显示给最终用户，并将子步骤提供给未来的计划和解决提示。</p><p><img src="https://petal-diplodocus-04a.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F29d8c98c-21e6-4991-992d-62d95fd40dba%2FScreen_Shot_2023-07-01_at_12.25.37_PM.png?id=021895a6-149a-4282-aa8e-6719e7d7c47a&amp;table=block&amp;spaceId=46c3481b-d8de-4c34-8647-2292d63a5f29&amp;width=2000&amp;userId=&amp;cache=v2" loading=lazy alt="Screen Shot 2023-07-01 at 12.25.37 PM.png"></p><blockquote><p>Alt: Picture of Plan & SolveAlt：计划和解决方案的图片</p></blockquote><p>While PS prompting helps evoke a reasoning response, it still misses a fundamental concept in reasoning, and that is proper handling for reflection and action. <strong>Reflection</strong>is <em>fundamental for any agent because it must rationalize an action, perform that action, and use feedback to adjust future actions.</em> Without it, the agent would be stateless and unchanging.
虽然 PS 提示有助于唤起推理反应，但它仍然忽略了推理中的一个基本概念，那就是对反思和行动的正确处理。反思对于任何智能体来说都是基础，因为它必须合理化某个动作、执行该动作并使用反馈来调整未来的动作。没有它，代理将是无状态且不变的。</p><p>AgentGPT uses a prompting framework called Reasoning and Acting (<a class=link href=https://arxiv.org/pdf/2210.03629.pdf target=_blank rel=noopener>ReAct</a>) to expand on the capabilities of the Plan-and-Solve concept. <strong>ReAct</strong> aims to <em>enable a framework for the model to access fresh knowledge through external knowledge bases and make observations of actions it has taken</em>. Using those observations, the LLM can make educated decisions on the next set of steps to complete while performing actions to query knowledge bases such as <strong>Google Search</strong> or <strong>Wikipedia API</strong>.
AgentGPT 使用称为推理和行动 (ReAct) 的提示框架来扩展计划和解决概念的功能。 ReAct 旨在为模型提供一个框架，使其能够通过外部知识库获取新知识并观察其所采取的行动。利用这些观察结果，法学硕士可以对下一组要完成的步骤做出明智的决策，同时执行查询知识库（例如 Google 搜索或维基百科 API）的操作。</p><p>Prompt engineering is largely effective in resolving challenges in short-term memory as well as instilling the reasoning behavior that you can see when AgentGPT is at work. However, prompt engineering does not resolve the issue of long-term memory. This issue is where vector databases come in, and we will look at those next.
即时工程在解决短期记忆挑战以及灌输 AgentGPT 工作时可以看到的推理行为方面非常有效。然而，即时工程并不能解决长期记忆的问题。这个问题就是矢量数据库的用武之地，我们接下来将讨论这些问题。</p><p><img src="https://petal-diplodocus-04a.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F481f0812-00e5-4cb1-9ed6-4f2f9215eef5%2FScreen_Shot_2023-07-03_at_3.12.56_AM.png?id=8002f409-2913-4e68-b8b6-6100c4128cf5&amp;table=block&amp;spaceId=46c3481b-d8de-4c34-8647-2292d63a5f29&amp;width=2000&amp;userId=&amp;cache=v2" loading=lazy alt="Screen Shot 2023-07-03 at 3.12.56 AM.png"></p><blockquote><p>Alt : ReAct (Reason + Act) Logic PictureAlt : ReAct (理性 + 行动) 逻辑图</p></blockquote><blockquote><p>The ReAct framework allows us to generate a reasoning response, an action, and a reflection to steer the model’s response. This example is courtesy of the following paper: <a class=link href=https://arxiv.org/abs/2210.03629 target=_blank rel=noopener>ReAct: Synergizing Reasoning and Acting in Language Models</a>*ReAct 框架允许我们生成推理响应、操作和反射来引导模型的响应。此示例由以下论文提供：ReAct：在语言模型中协同推理和行动*</p></blockquote><h2 id=how-do-we-give-agents-a-working-memory我们如何为代理提供工作记忆>How do we give agents a working memory?我们如何为代理提供工作记忆？</h2><p>While we have seen that <em>prompt engineering is largely effective in resolving issues with short-term memory and reasoning</em>, we cannot solve long-term memory solely through clever English. Since we are not allowed to update the model to learn our data, we must build an external system for storing and retrieving knowledge.虽然我们已经看到即时工程在解决短期记忆和推理问题方面非常有效，但我们不能仅通过聪明的英语来解决长期记忆。由于我们不允许更新模型来学习数据，因此我们必须构建一个外部系统来存储和检索知识。</p><p>A clever solution might use an LLM to <em>generate summaries of previous conversations as context for the prompt</em>. However, there are three significant issues with this. First, we are diluting the relevant information for the conversation; second, it introduces another cost area by paying for API usage for those summaries; and third, it&rsquo;s unscalable.一个聪明的解决方案可能会使用法学硕士来生成以前对话的摘要作为提示的上下文。然而，这存在三个重大问题。首先，我们淡化对话的相关信息；其次，它引入了另一个成本领域，即为这些摘要的 API 使用付费；第三，它是不可扩展的。</p><p>Thus, prompts appear to be ineffective for long-term memory. Seeing as <em>long-term memory is a problem of storage and efficient retrieval of information</em>, there is no absence of research in the study of search, so we must look towards vector databases.因此，提示似乎对长期记忆无效。由于长期记忆是一个信息存储和高效检索的问题，搜索的研究并不缺乏，因此我们必须将目光投向向量数据库。</p><h3 id=vector-databases-demystified揭秘矢量数据库>Vector Databases Demystified揭秘矢量数据库</h3><p><strong><a class=link href=https://aws.amazon.com/what-is/vector-databases/ target=_blank rel=noopener>Vector databases</a></strong> have been hyped up for a while now, and the hype is very deserved. They are an efficient way of storing and retrieving vectors by allowing us to use some fun new *algorithms to query billions - even trillions - of data records in milliseconds.*矢量数据库已经被炒作有一段时间了，而且这种炒作是非常值得的。它们是存储和检索向量的有效方法，允许我们使用一些有趣的新算法在几毫秒内查询数十亿甚至数万亿条数据记录。</p><p>Let&rsquo;s start with a little bit of vocabulary:让我们从一些词汇开始：</p><ul><li>A <strong>vector</strong> in the context of an LLM is a representation of a piece of text that a model like GPT-4 encodes.LLM 上下文中的向量是 GPT-4 等模型编码的一段文本的表示。</li><li>A <strong>vector space</strong> contains many of these vectors.向量空间包含许多这样的向量。</li><li>An <strong>embedding</strong> is the vectorized version of a text.嵌入是文本的矢量化版本。</li></ul><h3 id=vector-libraries-like向量库如>Vector libraries like 向量库如</h3><p><a class=link href="https://www.bing.com/ck/a?!&&amp;p=a0f4167bc6cd7db9JmltdHM9MTY4ODM0MjQwMCZpZ3VpZD0zOTYwYjczZS1hNzg2LTY5Y2MtMjM2YS1hNDdmYTYwMjY4MjImaW5zaWQ9NTIwMQ&amp;ptn=3&amp;hsh=3&amp;fclid=3960b73e-a786-69cc-236a-a47fa6026822&amp;psq=faiss+github&amp;u=a1aHR0cHM6Ly9naXRodWIuY29tL2ZhY2Vib29rcmVzZWFyY2gvZmFpc3M&amp;ntb=1" target=_blank rel=noopener>Facebook AI Similarity Search</a> ( FAISS) give us access to valuable *tools to control these vectors and locate them efficiently in the vector space.*Facebook AI 相似性搜索 (FAISS) 为我们提供了宝贵的工具来控制这些向量并在向量空间中有效地定位它们。</p><p>Since the text is in a numerical embedding dictated by the model type (i.e., text-embedding-ada-002), there is some location in space that the text exists in, and it&rsquo;s based on the numbers that compose its vector. That means <em>similar texts will be represented as vectors with similar numbers, and thus, they will likely be grouped closely. On the other hand, less similar texts will be further away</em>. For example, texts about cooking will be closer to food than texts about physics.由于文本处于由模型类型指定的数字嵌入中（即 text-embedding-ada-002），因此文本存在于空间中的某个位置，并且它基于组成其向量的数字。这意味着相似的文本将被表示为具有相似数字的向量，因此它们可能会被紧密地分组。另一方面，不太相似的文本会离得更远。例如，关于烹饪的文本比关于物理的文本更接近食物。</p><p>There are several different algorithms for querying the vector space, but the most relevant to this discussion is the cosine similarity search. <strong><a class=link href=https://www.geeksforgeeks.org/cosine-similarity/ target=_blank rel=noopener>Cosine similarity</a></strong> measures the cosine of the angle between two non-zero vectors. <em>It is a measure of orientation, meaning that it&rsquo;s used to determine how similar two documents (or whatever the vectors represent) are</em>. Cosine similarity can range from -1 to 1, with -1 meaning the vectors are diametrically opposed (completely opposite), 0 meaning the vectors are orthogonal (or unrelated), and 1 meaning the vectors are identical.有几种不同的算法用于查询向量空间，但与本讨论最相关的是余弦相似度搜索。余弦相似度测量两个非零向量之间角度的余弦。它是方向的度量，这意味着它用于确定两个文档（或向量表示的任何内容）的相似程度。余弦相似度的范围为 -1 到 1，其中 -1 表示向量完全相反（完全相反），0 表示向量正交（或不相关），1 表示向量相同。</p><p>FAISS is helpful in managing these vector spaces, but it is not a database. <em>Vector libraries lack <a class=link href=https://www.freecodecamp.org/news/crud-operations-explained/ target=_blank rel=noopener>CRUD</a> operations, which makes them alone unviable for long-term memory</em>, and that&rsquo;s where cloud services such as Pinecone and Weaviate step in.FAISS 有助于管理这些向量空间，但它不是数据库。矢量库缺乏 CRUD 操作，这使得它们无法单独用于长期记忆，而这正是 Pinecone 和 Weaviate 等云服务介入的地方。</p><p><strong>Pinecone</strong> and <strong>Weaviate</strong> essentially do all the hard work of managing our vectors. They provide an API that allows you to upload embeddings, perform various types of searches, and store those vectors for later. *They provide the typical CRUD functions we need to instill memory into LLMs in easily-accessible Python modules.*Pinecone 和 Weaviate 基本上完成了管理我们载体的所有艰苦工作。他们提供了一个 API，允许您上传嵌入、执行各种类型的搜索并存储这些向量以供以后使用。它们提供了我们需要的典型 CRUD 函数，以便将内存注入到易于访问的 Python 模块中的 LLM 中。</p><p>By using them, we can encode large amounts of information for future storage and retrieval. For instance, when the LLM needs extra knowledge to complete a task, we can prompt it to query the vector space to find relevant information. Thus, we can create long-term memory.通过使用它们，我们可以对大量信息进行编码以供将来存储和检索。例如，当LLM需要额外的知识来完成任务时，我们可以提示它查询向量空间以查找相关信息。因此，我们可以创造长期记忆。</p><p><img src="https://petal-diplodocus-04a.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fad2521b3-1c6b-4f16-b719-d2b766570c61%2FCybrCo_Art_A_human-like_robot_touching_a_flower_for_the_first_t_92e97d56-54fa-4bb0-8581-5a1e15fd94aa.webp?id=8d261d10-f4e4-4798-bc33-8f40da67bb42&amp;table=block&amp;spaceId=46c3481b-d8de-4c34-8647-2292d63a5f29&amp;width=2000&amp;userId=&amp;cache=v2" loading=lazy alt=CybrCo_Art_A_human-like_robot_touching_a_flower_for_the_first_t_92e97d56-54fa-4bb0-8581-5a1e15fd94aa.webp></p><blockquote><p>Alt : Robot With A Rose In HandAlt : 手握玫瑰的机器人</p></blockquote><h2 id=tools-to-interact-with-the-environment与环境交互的工具>Tools to interact with the environment与环境交互的工具</h2><p>While <strong>prompt engineering</strong> and <strong>vector databases</strong> resolve many of the limitations and challenges of LLMs, there is still the problem of agent interaction. *How can we extend the capabilities of an LLM to interact with the environment outside of text?*虽然即时工程和矢量数据库解决了法学硕士的许多限制和挑战，但仍然存在代理交互的问题。我们如何扩展法学硕士与文本之外的环境交互的能力？</p><p>APIs are the answer. By utilizing APIs, we can give our agents the ability to perform a wide range of actions and access external resources.API 就是答案。通过利用 API，我们可以让我们的代理能够执行各种操作并访问外部资源。</p><p>Here are a few examples:这里有一些例子：</p><ul><li><strong>Google Search API</strong>: Allows agents to search the web and retrieve relevant information.Google Search API：允许代理搜索网络并检索相关信息。</li><li><strong>Hugging Face</strong>: Provides access to various NLP models and transformers for tasks such as summarization, translation, sentiment analysis, and more.Hugging Face：提供对各种 NLP 模型和转换器的访问，以执行摘要、翻译、情感分析等任务。</li><li><strong>Dall-E</strong>: Enables agents to generate images from textual descriptions.Dall-E：使代理能够根据文本描述生成图像。</li><li><strong>OpenAI&rsquo;s GPT API</strong>: Allows agents to utilize the GPT-4 model for text completion and generation.OpenAI 的 GPT API：允许代理利用 GPT-4 模型进行文本完成和生成。</li></ul><p>Using API tools in combination with prompt engineering techniques, we can create prompts that generate predictable function calls and utilize the output of API requests to enhance the agent&rsquo;s capabilities. This enables agents to interact with the environment in a meaningful way beyond text-based interactions.使用 API 工具与提示工程技术相结合，我们可以创建生成可预测函数调用的提示，并利用 API 请求的输出来增强代理的功能。这使得代理能够以一种超越基于文本的交互的有意义的方式与环境交互。</p><h3 id=engineering-robust-function-calls工程稳健的函数调用>Engineering Robust Function Calls工程稳健的函数调用</h3><p>Again, we can achieve tooling through prompt engineering by <em>representing the tool we want to provide for the model</em> as a <strong>function</strong>. <em>We can then tell the model that this function exists in a prompt, so our program can call it programmatically based on the model&rsquo;s response</em>. First, however, we should examine the main challenges in implementing tool interactions: consistency, context, and format.同样，我们可以通过将我们想要为模型提供的工具表示为函数来通过即时工程来实现工具。然后我们可以告诉模型该函数存在于提示中，因此我们的程序可以根据模型的响应以编程方式调用它。然而，首先，我们应该检查实现工具交互的主要挑战：一致性、上下文和格式。</p><p>For example, responses tend to vary among chat completions that use the same prompt. Thus, getting the LLM to issue a function call consistently is challenging. A minor solution may include adjusting the <strong>temperature</strong> of the model (a parameter to control the randomness), but the best solution should leverage an LLM&rsquo;s reasoning abilities. Thus, *we can use the ReAct framework to help the llm understand when to issue function calls.*例如，使用相同提示的聊天完成之间的响应往往会有所不同。因此，让法学硕士一致地发出函数调用是具有挑战性的。一个次要的解决方案可能包括调整模型的温度（控制随机性的参数），但最好的解决方案应该利用法学硕士的推理能力。因此，我们可以使用 ReAct 框架来帮助 llm 了解何时发出函数调用。</p><p>In doing this, we will still run into another major issue. How will the LLMs understand what tools are at their disposal? We could include the available tools in a prompt, but this could significantly increase the number of tokens we would need to send to the model. While this may be fine for an application that runs on a couple of tools, it will increase costs as we add more tools to the system. Thus, *we would use vector databases to help the LLM look up relevant tools it needs.*在这样做的过程中，我们还会遇到另一个重大问题。法学硕士如何了解他们可以使用哪些工具？我们可以在提示中包含可用的工具，但这可能会显着增加我们需要发送到模型的令牌数量。虽然这对于在多个工具上运行的应用程序来说可能没问题，但随着我们向系统添加更多工具，它会增加成本。因此，我们将使用向量数据库来帮助法学硕士查找其所需的相关工具。</p><p>Finally, we need to generate function calls in a predictable format. This format should include provisions for the name of the function and the parameters it takes, and it must include delimiters that allow us to parse and execute the response for those parameters programmatically. *For instance, you can prompt the model to only return responses in JSON and then use built-in Python libraries to parse the stringified JSON.*最后，我们需要以可预测的格式生成函数调用。此格式应包括函数名称及其采用的参数的规定，并且必须包括允许我们以编程方式解析和执行这些参数的响应的分隔符。例如，您可以提示模型仅返回 JSON 格式的响应，然后使用内置 Python 库来解析字符串化的 JSON。</p><p>Recently, it became even easier to use this type of method as well. In late June, OpenAI released <strong>gpt-4-0613</strong> and <strong>gpt-3.5-turbo-16k-0613</strong> (whew, these names are getting long). They natively support function calls by using a model fine-tuned for JSON to return easy-to-use function calls. You can read more about it <a class=link href=https://platform.openai.com/docs/guides/gpt/function-calling target=_blank rel=noopener>here</a>.最近，使用这种方法也变得更加容易。 6月下旬，OpenAI发布了gpt-4-0613和gpt-3.5-turbo-16k-0613（哇，这些名字越来越长了）。它们通过使用针对 JSON 进行微调的模型来原生支持函数调用，以返回易于使用的函数调用。你可以在这里读更多关于它的内容。</p><h2 id=the-future-of-llm-powered-agents-is-brightllm-代理人的未来是光明的>The future of LLM-powered agents is bright!LLM 代理人的未来是光明的！</h2><p>Large language models have been one of the most significant advances of the past decade. Capable of reasoning and talking like a human, they appear to be able to do anything. Despite this, several engineering challenges arise in building around an LLM, such as context limits, reasoning, and long-term retention.大型语言模型是过去十年最重大的进步之一。它们能够像人类一样推理和说话，似乎能够做任何事情。尽管如此，围绕法学硕士的构建仍会出现一些工程挑战，例如上下文限制、推理和长期保留。</p><p>Using the methods described above, <strong>AgentGPT</strong> unlocks the full potential of powerful models such as GPT-4. <em>We can give any model superpowers using novel prompting methods, efficient vector databases, and abundant API tools</em>. It&rsquo;s only the start, and we hope you&rsquo;ll join us on this journey.使用上述方法，AgentGPT 释放了 GPT-4 等强大模型的全部潜力。通过新颖的提示方法、高效的向量数据库、丰富的API工具，我们可以赋予任何模型超能力。这只是一个开始，我们希望您能加入我们的旅程。</p><h2 id=conclusion结论>Conclusion 结论</h2><p>AgentGPT represents a powerful approach to building AI agents that reason, remember, and perform. By leveraging prompt engineering, vector databases, and API tools, we can overcome the limitations of standalone LLMs and create agents that demonstrate agentic behavior.AgentGPT 代表了构建具有推理、记忆和执行功能的 AI 代理的强大方法。通过利用即时工程、矢量数据库和 API 工具，我们可以克服独立法学硕士的局限性，并创建能够展示代理行为的代理。</p><p>With the ability to reason, plan, and reflect, AgentGPT agents can tackle complex tasks and interact with the environment in a meaningful way. By incorporating long-term memory through vector databases and utilizing APIs, we provide agents with access to a vast pool of knowledge and resources.凭借推理、计划和反思的能力，AgentGPT 代理可以处理复杂的任务并以有意义的方式与环境交互。通过向量数据库整合长期记忆并利用 API，我们为代理提供了访问大量知识和资源的机会。</p><p>AgentGPT is a step towards unlocking the full potential of LLMs and creating intelligent agents that can assist and collaborate with humans in various domains. The combination of language models, prompt engineering, external memory, and API interactions opens up exciting possibilities for AI agents in the future.AgentGPT 是朝着释放法学硕士的全部潜力和创建可以在各个领域协助人类并与人类协作的智能代理迈出的一步。语言模型、即时工程、外部存储器和 API 交互的结合为人工智能代理的未来开辟了令人兴奋的可能性。</p></section><footer class=article-footer><section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg><span>Licensed under CC BY-NC-SA 4.0</span></section></footer></article><aside class=related-content--wrapper><h2 class=section-title>相关文章</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/p/xagent-video-%E5%A4%A7%E7%BA%B2/><div class=article-details><h2 class=article-title>Xagent Video 大纲</h2></div></a></article><article class=has-image><a href=/p/agentverse/><div class=article-image><img src=/p/agentverse/cover.c0a185479fc7a02ece872a95b555cf71_hu562ff14b3d00ed1bfd5a51b32681b45e_1477547_250x150_fill_box_smart1_3.png width=250 height=150 loading=lazy alt="Featured image of post Agentverse" data-hash="md5-wKGFR5/HoC7OhyqVtVXPcQ=="></div><div class=article-details><h2 class=article-title>Agentverse</h2></div></a></article></div></div></aside><div class=disqus-container><div id=disqus_thread></div><script type=application/javascript>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//Arno.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><style>.disqus-container{background-color:var(--card-background);border-radius:var(--card-border-radius);box-shadow:var(--shadow-l1);padding:var(--card-padding)}</style><script>window.addEventListener("onColorSchemeChange",e=>{typeof DISQUS=="object"&&DISQUS.reset({reload:!0})})</script><footer class=site-footer><section class=copyright>&copy;
2023 Arno's Blog</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.21.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script>
<script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>