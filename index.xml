<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Arno's Blog</title><link>https://umpire2018.github.io/</link><description>Recent content on Arno's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-Hans</language><lastBuildDate>Tue, 24 Oct 2023 12:02:30 +0800</lastBuildDate><atom:link href="https://umpire2018.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Xagent Video 大纲</title><link>https://umpire2018.github.io/p/xagent-video-%E5%A4%A7%E7%BA%B2/</link><pubDate>Tue, 24 Oct 2023 12:02:30 +0800</pubDate><guid>https://umpire2018.github.io/p/xagent-video-%E5%A4%A7%E7%BA%B2/</guid><description>&lt;h2 id="参考视频">参考视频&lt;/h2>
&lt;div class="video-wrapper">
&lt;video
controls
src="https://www.youtube.com/watch?v=X6dna0O6pCw"
>
&lt;p>
Your browser doesn't support HTML5 video. Here is a
&lt;a href="https://www.youtube.com/watch?v=X6dna0O6pCw">link to the video&lt;/a> instead.
&lt;/p>
&lt;/video>
&lt;/div>
&lt;p>XAgent: AutoGen 2.0? An Autonomous Agent for Complex Task Solving (Installation Tutorial)&lt;/p>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;p>XAgent是一个名为&amp;quot;AutoGen 2.0&amp;quot;的自主代理，目的在于解决复杂任务。本视频介绍了XAgent的能力和如何安装它。&lt;/p>
&lt;h3 id="highlights">Highlights&lt;/h3>
&lt;p>2023年，自主代理技术逐渐兴起。目前的AI代理受到人为规则、知识和偏见的限制，通信不一致，任务管理不灵活。XAgent旨在解决这些问题，实现复杂任务的自主解决。&lt;/p>
&lt;p>[🔧] XAgent是一个开源项目，利用大型语言模型驱动自主代理，可以自动解决各种任务。&lt;/p>
&lt;p>[📢] 除了基本功能，XAgent还提供了工具服务器，配备了多种工具来帮助执行各种任务。&lt;/p>
&lt;p>[🖥️] 本教程详细介绍了如何安装和运行XAgent，包括所需的系统要求和步骤。&lt;/p>
&lt;p>[📈] XAgent在多个测试领域中都超越了基本的GPT模型和其他AI代理。&lt;/p>
&lt;p>[🧠] XAgent的目标是创建一个超级智能代理，可以解决各种任务，尽管它仍处于早期阶段。&lt;/p>
&lt;p>[🔒] XAgent运行在Docker容器内，确保安全性。&lt;/p>
&lt;p>[📦] XAgent可扩展性强，允许添加新插件、模型和工具来增强代理的能力。&lt;/p>
&lt;p>[🖼️] XAgent提供友好的GUI，方便用户与代理进行交互。&lt;/p>
&lt;p>[🤝] XAgent支持与人类的合作，用户可以与代理一起解决任务。&lt;/p>
&lt;p>注意XAgent需要至少8GB RAM才能运行。安装需要Git、Python和Docker支持。可通过命令行或GUI运行XAgent，配置API密钥后即可运行任务。
XAgent是一个旨在解决复杂任务的自主代理项目，使用大型语言模型来自动执行各种任务。尽管项目仍处于早期阶段，但它有潜力成为一个全能的自主代理，具有强大的扩展性和安全性。用户可以通过命令行或GUI与XAgent交互，并配置API密钥以运行任务。项目还提供了一系列工具，如文件编辑器、Python笔记本、Web浏览等，以支持任务的执行。最重要的是，XAgent的目标是不断改进，以成为一个可以解决各种任务的超级智能代理。&lt;/p>
&lt;h3 id="大纲">大纲&lt;/h3>
&lt;h3 id="1-背景介绍与xagent概览-2分钟">1. 背景介绍与XAgent概览 (2分钟)&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>视频视觉：&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>利用缓慢的平移镜头展示相关行业背景图片。&lt;/li>
&lt;li>使用动态图表展示技术进展。&lt;/li>
&lt;li>XAgent的标志短暂放大或3D旋转进入镜头。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>音频：&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>背景音乐：轻快、科技感的音乐。&lt;/li>
&lt;li>配音：专业的旁白，用平和的语气进行介绍。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="2-xagent项目demo与实际应用-65分钟">2. XAgent项目DEMO与实际应用 (6.5分钟)&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>视频视觉：&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>使用屏幕录制工具捕捉实际的界面操作、任务处理过程。&lt;/li>
&lt;li>当解释双循环机制时，使用动态或3D动画来展示双循环的工作流程。&lt;/li>
&lt;li>插入实际应用案例的短片或客户反馈。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>音频：&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>背景音乐：中速、有节奏的音乐，突出操作的流畅性。&lt;/li>
&lt;li>配音：解说DEMO的每一步，并强调其实际应用价值。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="3-人机交互与新智能-5分钟">3. 人机交互与新智能 (5分钟)&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>视频视觉：&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>展示AI与用户的交互情景，可以使用角色扮演或动画。&lt;/li>
&lt;li>展示XAgent的界面、特色功能、交互过程，辅以箭头、高亮等效果。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>音频：&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>背景音乐：平稳、和谐。&lt;/li>
&lt;li>配音：解释每一个交互步骤和其背后的逻辑。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="4-整合大模型与协同工作-3分钟">4. 整合大模型与协同工作 (3分钟)&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>视频视觉：&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>各种大模型和工具的图标快速组合或3D旋转效果。&lt;/li>
&lt;li>展示实际的操作界面，特别是模型间的互动部分。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>音频：&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>背景音乐：低调、深沉。&lt;/li>
&lt;li>配音：解释模型的整合方式和协同的优势。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="5-结束与展望-25分钟">5. 结束与展望 (2.5分钟)&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>视频视觉：&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>回顾XAgent的主要特点，可以使用快速回放或白板动画。&lt;/li>
&lt;li>展望未来，使用渐变、飞入效果展示潜在的应用场景或新特性。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>音频：&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>背景音乐：充满希望和展望的旋律。&lt;/li>
&lt;li>配音：总结XAgent的贡献，表达对未来的期待。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="相关链接">相关链接&lt;/h2>
&lt;ul>
&lt;li>&lt;a class="link" href="https://medium.com/future-organization-lab-%E6%9C%AA%E4%BE%86%E7%B5%84%E7%B9%94%E5%AF%A6%E9%A9%97%E5%AE%A4/%E8%A1%8C%E5%8B%95%E7%A7%91%E5%AD%B8%E4%B8%AD%E7%9A%84%E9%9B%99%E7%92%B0%E5%AD%B8%E7%BF%92-double-loop-learning-%E5%9C%98%E9%9A%8A%E5%9C%A8%E8%A7%A3%E6%B1%BA%E8%A1%A8%E9%9D%A2%E5%95%8F%E9%A1%8C-%E9%82%84%E6%98%AF%E6%94%B9%E5%96%84%E9%80%A0%E6%88%90%E5%95%8F%E9%A1%8C%E7%9A%84%E5%BF%83%E6%99%BA%E6%A8%A1%E5%9E%8B-1fbdcd475201" target="_blank" rel="noopener"
>團隊在解決表面問題，還是改善造成問題的心智模型？&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://zhuanlan.zhihu.com/p/77165674" target="_blank" rel="noopener"
>思维模型No.54|双环学习，让你的经验变成智慧&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://x-agent.net/share" target="_blank" rel="noopener"
>demo 地址&lt;/a> 建议：1. 取消密码 2. 增加暗黑模式 3. 点击即运行&lt;/li>
&lt;/ul>
&lt;h2 id="ryan对项目的理解">Ryan对项目的理解&lt;/h2>
&lt;h3 id="整体理解">整体理解：&lt;/h3>
&lt;p>这是一个致力于能使用的多个ai共同协作解决任何问题的系统。以下是本人总结该系统的各个特性和优势。&lt;/p>
&lt;ol>
&lt;li>自主性：能在接受问题时将任务分解以提高效率。这个系统不依赖人的调试或者干预，具有自主性，甚至能为自己的工作部署各种工具。&lt;/li>
&lt;li>安全性：可以安全运行，由于其在一个docker中运行，所以不会影响主要环境，同时意味着其能够更广泛的运用在生活工作之中。&lt;/li>
&lt;li>GUI：对XAgent的操作对用户友好，使用合理的图形化界面和命令行结合，可以满足各种用户的需求。&lt;/li>
&lt;li>可拓展性能：项目本身开源，意味着可以增加新的设计功能，或者利用它进行新的系统实现。&lt;/li>
&lt;li>创造性（智能性）：在传统ai系统的基础上，结合热门的chatGPT系统。不仅有能力在行进中遵循人类指导来解决复杂的任务，而且在遇到挑战，条件模糊时能主动向人类寻求细节指令，之后提出创造性决策。&lt;/li>
&lt;/ol>
&lt;h2 id="原文细节">原文细节：&lt;/h2>
&lt;p>&lt;strong>内外双循环&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>外循环：负责全局任务规划，将复杂任务分解为可操作的简单任务。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>内循环：负责局部任务执行，专注于细节。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>外循环会将给定的复杂任务分解成更小、更易管理的“子任务”，生成 “初始规划”，形成任务序列。
随后，它将逐次把每个子任务传递给内循环解决。在这个过程中，外循环会不断监督任务的进度和状态，并根据反馈对后续规划进行 “迭代优化”。&lt;/p>
&lt;p>内循环中有特定的根据子任务性质的不同，它可以从外部系统中检索工具，并针对子任务进行一步步求解。
在子任务完成后，它将生成当前子任务执行过程的反思，反馈给外循环，指示当前任务是否完成，以及任务执行中的潜在优化点。&lt;/p>
&lt;p>内外双循环有利于多个ai共同促进，能对工作进行完善。由于外循环任务的分解，能让效率提高，内循环对子任务专事专干，能解决更多问题，使得系统的稳定性提高。重要的是，任务的明确分解使得人在指导系统工作时候能够对各个部分对症下药。&lt;/p>
&lt;p>&lt;strong>人机交互新智能&lt;/strong>&lt;/p>
&lt;p>主动向人类询问更加具提条件，在真正执行之前解决必须解决的问题，而不是出错后再改正，能够使工作更加节省资源。&lt;/p>
&lt;p>这是一个突破性进展，继让ai生成文字，图片，视频，程序等等后出现了让ai生成相关的问题角度，由一个主要题目生成了细节问题。&lt;/p>
&lt;p>&lt;em>想法：问题可以是除了关键字还主动给出人类倾向的解决方案，让用户选择现成的。也能给出那么人类在回答问题时候也不必拘泥于文字形式，可以是各种文件类型。&lt;/em>&lt;/p>
&lt;p>&lt;strong>整合大模型&lt;/strong>&lt;/p>
&lt;p>该系统整合了各种先进的大模型，ToolServer 的关键组件包括：ToolServerNode、ToolServerMonitor、ToolServerManager，在执行操作、节点检查、周期管理等方面提供强大的能力。
目前，XAgent 的 ToolSever 支持 FileSystemEnv、PythonNotoBook、WebEnv、ExecuteShell、RapidAPIEnv、AskHumanforHelp 等多种工具。使各模型的优缺点互补，从而解放模型性能。&lt;/p>
&lt;p>&lt;em>想法：如果能增加更多的模型，如画图ai或者其他生成型ai，就能扩展系统的功能，增强力量。而且在调用工具的时候能考虑添加监视，防止导致崩溃。&lt;/em>&lt;/p>
&lt;p>&lt;strong>用户界面（GUI）&lt;/strong>&lt;/p>
&lt;p>XAgent的界面直观和清晰，对比很多系统都是大优势。&lt;/p>
&lt;p>&lt;em>想法：是否也能考虑新增个性化主题设置，和环境联动，满足各种人群的需求&lt;/em>&lt;/p>
&lt;h2 id="原视频文稿">原视频文稿&lt;/h2>
&lt;p>00:00 autonomous agents have been popping around in the year of 2023 with the hopes of achieving a step closer to AI we&amp;rsquo;ve seen this many times with different types of AI agents we covered on this channel with super AGI Auto gbt as well as with baby AGI now while these pioneering projects have demonstrated potential in this direction the journey to fully automate AI agents still presents quite a formidable challenge now this is specifically with autonomy where existing agents are bounded to human imposed rules knowledges as well&lt;/p>
&lt;p>00:37 as by biases then you have the inconsistent communication framework and this is where there is a lack of mode of communication that leads to a potential misunderstanding lastly you have rigged task management this is where existing agents lack the flexibility in having highlevel task management these are these are just basically handful of scenarios in which AI agents have this challenge however let me introduce you a new project called X agent a solution to these challenges an autonomous agent that is targeting the realization of&lt;/p>
&lt;p>01:14 complex task solving task in an autonomous manner this is a project that is working to develop intelligent agents that are capable of mimicking human cognition as well as executing intricate tasks autonomously throughout today&amp;rsquo;s video I&amp;rsquo;m going to be showcasing what you can actually do with X agent talk a little bit more about the capabilities showcase how you can actually install it and going over basically in general what you can do with it so with that thought guys make sure you stay tuned throughout&lt;/p>
&lt;p>01:44 the end of this video and let&amp;rsquo;s get straight to it hey what is up guys welcome back to another YouTube video at the world of AI as you mentioned at the start we&amp;rsquo;re going to take a look at X agent which is an autonomous agent for complex task solving X agent is an open-source project that utilizes large language models to drive autonomous agents so that it can automatically solve various tasks now just note that even though it is designed for solving complex task that doesn&amp;rsquo;t basically mean that it&amp;rsquo;s&lt;/p>
&lt;p>02:17 constrained to only solving complex tasks it&amp;rsquo;s designed to be a general purpose agent so that it could be applied to wide ranges of tasks whether it is a complex task or just a regular task something to note is is that this project is fairly new in its early stages so keep that in mind as it was just recently released about yesterday the goal of this project as stated at the start is that they want to create a super intelligent agent that can basically solve any sort of task that it&amp;rsquo;s been basically given it&amp;rsquo;s in its&lt;/p>
&lt;p>02:49 early stages so they&amp;rsquo;re continuous to working on this but it&amp;rsquo;s something that they&amp;rsquo;re going to keep on improving over the months so with that thought let&amp;rsquo;s now explore some cool features that are associated with X agent so you can get some more like idea as to what you can actually do with it and understand some of the capabilities about ex agent if you guys would like to access our private Discord in which you can get exclusive features such as our AI subscriptions to different types of tools for free you have giveaways you&lt;/p>
&lt;p>03:19 have different types of consultation for free you have different methods of just interacting with the community which can get you networking opportunities Daily News and so much more if you&amp;rsquo;re interested in all that I highly recommend that you check out the patreon link in the description below if you guys haven&amp;rsquo;t followed world of AI on Twitter I highly recommend that you do so so you can stay up to date with the latest AI news lastly make sure you guys subscribe turn notification Bell like this video and check out our previous&lt;/p>
&lt;p>03:45 videos because there&amp;rsquo;s a lot of content that I highly recommend would benefit you so with that thought guys thank you guys so much for watching and let&amp;rsquo;s get right back into the video now guys as you mentioned it&amp;rsquo;s something that can help solve complex task in which they have have worked upon in different categories you have the autonomy in which it is a feature that X agent can automatically solve various task without human participation now this is something that we&amp;rsquo;ve seen with many different autonomous agents on my&lt;/p>
&lt;p>04:15 channel where we&amp;rsquo;ve seen autonomous AI agents like super agent as well as autogen as well as other ones that we mentioned such as the mgpt where you have multiple AI agents working together alongside with other agents to collaborativ solve a project this is the same sort of idea that X agent is trying to accomplish but the thing is you have one agent that does this and it does it on its own without any sort of human participation in terms of safety we have X agent in which it is designed to run safely all actions are constrained&lt;/p>
&lt;p>04:51 inside a Docker container so run it anyways another feature is its extendability X agent is basically designed to be extendable and and this basically means that you&amp;rsquo;re able to build upon this add new plugins add new models add new tools so that it enhances the agent&amp;rsquo;s abilities it makes new agents it grows the agent and it makes basically X agent so much more like better in a way cuz you&amp;rsquo;re able to customize it you have a GUI and it provides this friendly GUI for users to interact with their agents you have&lt;/p>
&lt;p>05:24 another feature in which you have cooperation with human as you&amp;rsquo;re basically able to inut your participation with ex agent so that you can collaborate to tackle certain tasks and this these are just some of the cool features now they have stated some couple things but we will cover in the next segment to speak further on some of the capabilities of X agent we have the tool server which is a server that equips X agent with a set of different types of robust and secure tools to tackle a range of different types of tasks it operates as a Docker&lt;/p>
&lt;p>05:58 container and what this basically means is that it offers this protective environment in which X agent can execute its operations we can see that it offers some of these tools such as a file editor which provides the text editing tool that can write read and modify files you have the python notebook which provides an interactive python notebook that can run python code to validate ideas as well as drawing figures you have the web browsing feature which provides you access to the web browser so you can search and visit different&lt;/p>
&lt;p>06:26 types of web pages you have the shell which provides a Bash shell tool that can execute any bat commands or shell commands sorry and even install programs and host Services you have the rapid API which provides a tool to retrieve apis from Rapid API and you&amp;rsquo;re able to call them which provides a wide range of apis that X agent can use you can see tool bench to provide like this is another application that provides the list of different apis and it&amp;rsquo;s a platform for providing you different ranges of API&lt;/p>
&lt;p>06:57 callings so that you can utilize it with within this collection now it also says that you can also easily add new tools to the tool server to enhance the capabilities you can see over here you&amp;rsquo;re able to have and build upon this and you can see there&amp;rsquo;s a build and setup tool server which is one of the action pieces to help improve the capabilities now we&amp;rsquo;ll get to the next step of the video and showcase how you can install X agent now guys I highly recommend that you have at least 8 gabt of ram to actually run this otherwise&lt;/p>
&lt;p>07:29 it&amp;rsquo;s not even feasible to run on your local desktop if you do not have that requirement if you do fulfill that we can move forward in the installation process you need to make sure that you have git installed which is an application that will help you clone this repository onto your desktop you&amp;rsquo;ll need python as your code editor and you&amp;rsquo;ll need Docker so once you have these three things fulfilled we can move forward with installation so what we&amp;rsquo;ll need to do is first go on to the GitHub repository I&amp;rsquo;ll leave all these links in&lt;/p>
&lt;p>07:56 the description below so that you can access it fairly easily now what you want to do is click on this green button once you&amp;rsquo;re on the repository copy the link scroll down go onto the actual quick start command area open up your command prompt type in get clone paste the link and click enter I always mess this up in every video but once you have cloned the repository what you will need to do is copy this command CD tool server and this is where you&amp;rsquo;re going to be going into the tool server and building the actual docker post for&lt;/p>
&lt;p>08:30 it now guys act after you install tool server and clone this repository you need to go into the folder and type in the command Docker compose up once this is done you&amp;rsquo;re going to create the docker compose and once this is done you just need to build the docker image for Tool server and you&amp;rsquo;re able to start this container once you have started up you can start running and setting up X agent this is by typing in PIP install our requirements now this is fairly easy you just go into the X agent file once&lt;/p>
&lt;p>09:01 you&amp;rsquo;re inside paste this command pip install our requirements you&amp;rsquo;re going to be able to start installing these requirements this might take a couple minutes to a couple seconds depending on your computer so once it has finished installing all the requirements you&amp;rsquo;re able to start running it fairly easily now I&amp;rsquo;m going to be using visual studio code to show and execute how you can run different types of tasks so I&amp;rsquo;m going to load this up on Visual Studio code and I&amp;rsquo;ll be right back now to start&lt;/p>
&lt;p>09:29 executing task you will need to open up your code editor or your ID that you can use in this case I&amp;rsquo;m going to use Visual Studio code so I&amp;rsquo;m going to open the folder up find where I basically cloned it open up X agent once you have done that you trust the authors you need to go on the configuration this is where you input your API keys for whatever model that you want to use in this case I&amp;rsquo;m going to be using GPT 3.&lt;/p>
&lt;p>09:55 5 so I&amp;rsquo;ll put my key over here once I have used that or saved it I basically go and click save and you&amp;rsquo;ll be able to start running it now once I have done that you need to go into the actual uh terminal and you need to copy this code over here in this case you have the run.py you can easily just run it off of here it&amp;rsquo;s fairly easy but in this case if you want to give it a command as well as run the model that you want you will need to copy this code and select whatever model that you want to play with so what you can do is just&lt;/p>
&lt;p>10:27 uh create a new terminal I&amp;rsquo;m just gonna open this up a little bit so it&amp;rsquo;s easily accessible so once I have created a new terminal you can easily just write paste this command in Python run.py you give it a task you put your model so in this case you can say uh create me a snake game and the model is right over here I&amp;rsquo;m going to use gp3 3.&lt;/p>
&lt;p>10:55 5 so I can put GPT 3.5 and click enter now I don&amp;rsquo;t have my API key connected so it won&amp;rsquo;t work but once I have inputed this it will start executing the task now in this case you can see that it&amp;rsquo;s not going to be able to do this cuz I don&amp;rsquo;t have my API key connected but it&amp;rsquo;s easy as that guys once you have inputed your keys you&amp;rsquo;re able to execute this task now another thing is is that you&amp;rsquo;re able to run this agent with the GUI it&amp;rsquo;s fairly easy and what you can do is go onto your command prompt go back into&lt;/p>
&lt;p>11:28 the actual X agent server once you&amp;rsquo;re in that you basically just compose the docker up again once you have done that you just need to install the requirements that are needed install the python start server this is by basically starting the server up and you&amp;rsquo;ll be able to access it on your local host and now guys it will look like this basically it&amp;rsquo;s going to look like exactly like this you&amp;rsquo;re going to you can see that you can input certain types of configurations you can give your input which is can you help me use&lt;/p>
&lt;p>11:59 python to analyze the given data you are able to upload this data and it will then give you a step-by-step analysis as to how it can graph it so in this case it gives you a good demonstration as to how it explains the data and it gives you a good use with python and that&amp;rsquo;s basically a good example now let&amp;rsquo;s actually take a look at a cool demo so we can get a better idea as to what you can actually do with xation in this case we have a demo relating to python on code in this case the input is I want to&lt;/p>
&lt;p>12:32 play a game of 24 and it basically then uses uh the plus sign minus sign multiplication division to get 24 using four numbers each number can be used only once please give me 10 examples of combinations of numbers that can get to 24 write the code and show me in this case it executes it it focuses on thoughts reasoning it gives it a plan and it also gives you criticism on what should be associated with the code generation and then uses the different tools and explains to you which tools that they actually use now I don&amp;rsquo;t know&lt;/p>
&lt;p>13:07 about you guys but this is something that I&amp;rsquo;ve never seen with any other autonomous agent as it gives you a good breakdown as to how it&amp;rsquo;s going to solve your answer or your input if you go down a little bit more it works forward into doing this 10 more times it has a task refinement which works on improving the task and it shows the Milestones that it took to basically achieve the input that was actually given now guys I want to end off on this last note where this diagram above is basically showcasing how X Agent X agent&lt;/p>
&lt;p>13:43 sorry outperforms the basic GPT models in different tested areas we can see that it has been able to outperform autog gbt as well in different like areas it fully beats uh autog gbt in data analysis it beats it in math you have search and Reporting life assistant as well as in coding and developing which is really really impressive now it not only beats it with auto gbt but it&amp;rsquo;s able to beat it with gbts for on EX existing AI benchmarks it&amp;rsquo;s able to do this in many different areas with fresh QA which are fresh question answers you&lt;/p>
&lt;p>14:23 have different metrics as to how it&amp;rsquo;s able to Benchmark autonomous AI agents now this is really impressive as to how it&amp;rsquo;s able to comp like basically compare with these different models as well as different AI agents now I highly recommend that you check this blog post out as it gives you more details as to how they&amp;rsquo;re basically able to achieve this gives you a good understanding as to its framework and goes further more in detail about X agent now if you&amp;rsquo;re interested I&amp;rsquo;ll leave all these links in&lt;/p>
&lt;p>14:52 the description below but guys in conclusion this is quite an intricate application and as it&amp;rsquo;s an autonomous agent for complex task solving so if you&amp;rsquo;re interested in this I&amp;rsquo;ll leave all these links in the description below so that you can access it fairly easily but thank you guys so much for watching I really really appreciate it guys all the support that you guys have been giving me make sure you check out the patreon page you want to access our private Discord definitely give world of AI a follow if you guys haven&amp;rsquo;t on Twitter&lt;/p>
&lt;p>15:20 and lastly make sure you guys subscribe turn notification Bell like this video and check out our previous videos so you can stay up to date with the latest AI news with that thought let&amp;rsquo;s get all let&amp;rsquo;s get to the next step of the video but thank you guys so much for watching if you are interested definitely subscribe I&amp;rsquo;ll see you guys next time have an amazing day stay positive and see you soon guys by&lt;/p></description></item><item><title>🧑‍✈️ GPT Pilot</title><link>https://umpire2018.github.io/p/%EF%B8%8F-gpt-pilot/</link><pubDate>Sat, 23 Sep 2023 21:28:46 +0800</pubDate><guid>https://umpire2018.github.io/p/%EF%B8%8F-gpt-pilot/</guid><description>&lt;img src="https://umpire2018.github.io/p/%EF%B8%8F-gpt-pilot/cover.png" alt="Featured image of post 🧑‍✈️ GPT Pilot" />&lt;blockquote>
&lt;p>GPT Pilot 帮助开发人员以 20 倍的速度构建应用程序&lt;/p>
&lt;/blockquote>
&lt;p>您可以明确说明想要构建什么样的应用程序。然后，GPT Pilot 会提出明确的问题，创建产品和技术要求，设置环境，并&lt;strong>开始一步一步地编写应用程序，就像在现实生活中一样，同时由您监督开发过程&lt;/strong>。每完成一项任务，它都会要求您进行审核，或在遇到困难时提供帮助。这样，GPT Pilot 就扮演了一个程序员，而您则是一个技术经理，负责审查代码并在需要时提供帮助。&lt;/p>
&lt;p>GPT Pilot 的目标是研究在开发人员监督实施下， GPT-4 可以在多大程度上被用于生成完全可用、可投入生产的应用程序。&lt;/p>
&lt;p>&lt;strong>我们的主要想法是，人工智能可以编写应用程序的大部分代码（可能占 95%），但剩下的 5%，在我们实现完全的人工智能之前，仍然需要开发人员来完成。&lt;/strong>.&lt;/p>
&lt;p>以下文章详细介绍了 GPT Pilot 背后的理念及其工作原理：:&lt;/p>
&lt;p>&lt;strong>&lt;a class="link" href="https://blog.pythagora.ai/2023/08/23/430/" target="_blank" rel="noopener"
>[Part 1/3] High-level concepts + GPT Pilot workflow until the coding part&lt;/a>&lt;/strong>&lt;/p>
&lt;p>&lt;strong>&lt;em>[Part 2/3] GPT Pilot coding workflow (在路上)&lt;/em>&lt;/strong>&lt;/p>
&lt;p>&lt;strong>&lt;em>[Part 3/3] Other important concepts and future plans (在路上)&lt;/em>&lt;/strong>&lt;/p>
&lt;h2 id="-gpt-pilot--编写的应用程序示例">&lt;strong>[👉 GPT Pilot 👈 编写的应用程序示例]&lt;/strong>&lt;/h2>
&lt;div class="video-wrapper">
&lt;video
controls
src="https://github.com/Pythagora-io/gpt-pilot/assets/10895136/0495631b-511e-451b-93d5-8a42acf22d3d"
>
&lt;p>
Your browser doesn't support HTML5 video. Here is a
&lt;a href="https://github.com/Pythagora-io/gpt-pilot/assets/10895136/0495631b-511e-451b-93d5-8a42acf22d3d">link to the video&lt;/a> instead.
&lt;/p>
&lt;/video>
&lt;/div>
&lt;h2 id="-要求">🔌 要求&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Python 3.10+&lt;/strong>&lt;/li>
&lt;li>PostgreSQL (可选安装, 项目默认使用 sqlite)
需要数据库有多种原因，例如如果您必须在任何时候停止或应用程序崩溃，则需要继续应用程序开发，返回到特定步骤，以便您可以更改开发中的一些后续步骤，更容易调试，将来我们将添加更新项目的功能（更改现有项目中的一些内容或向项目添加新功能等等）&amp;hellip;&lt;/li>
&lt;/ul>
&lt;h2 id="如何使用-gpt-pilot">🚦如何使用 gpt-pilot？&lt;/h2>
&lt;p>安装 Python 后，请按照以下步骤操作：&lt;/p>
&lt;ol>
&lt;li>&lt;code>git clone https://github.com/Pythagora-io/gpt-pilot.git&lt;/code> （克隆存储库）&lt;/li>
&lt;li>&lt;code>cd gpt-pilot&lt;/code>&lt;/li>
&lt;li>&lt;code>python -m venv Pilot-env&lt;/code> （创建虚拟环境）&lt;/li>
&lt;li>&lt;code>source Pilot-env/bin/activate&lt;/code> （激活虚拟环境）&lt;/li>
&lt;li>&lt;code>pip install -r requirements.txt&lt;/code> （安装依赖项）
6 . &lt;code>cd Pilot&lt;/code>&lt;/li>
&lt;li>&lt;code>mv .env.example .env&lt;/code> （创建 .env 文件）&lt;/li>
&lt;li>将您的配置信息 (OpenAI/Azure)、API 密钥和 SQLite/PostgreSQL 数据库信息添加到 &lt;code>.env&lt;/code>文件
&lt;ul>
&lt;li>要在 .env 中从 SQLite 更改为 PostgreSQL，只需设置 &lt;code>DATABASE_TYPE=postgres&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>python db_init.py&lt;/code> （初始化数据库）&lt;/li>
&lt;li>&lt;code>python main.py&lt;/code> （启动 GPT Pilot）&lt;/li>
&lt;/ol>
&lt;p>之后，您只需按照终端中的说明操作即可。&lt;/p>
&lt;p>所有生成的代码将存储在以您启动时输入的应用程序名称命名的文件夹内的 “workspace” 文件夹中。&lt;/p>
&lt;h2 id="-其他参数">🧑‍💻️ 其他参数&lt;/h2>
&lt;ul>
&lt;li>继续处理现有应用&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">python main.py &lt;span class="nv">app_id&lt;/span>&lt;span class="o">=&lt;/span>&amp;lt;ID_OF_THE_APP&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>从特定步骤继续处理现有应用程序&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">python main.py &lt;span class="nv">app_id&lt;/span>&lt;span class="o">=&lt;/span>&amp;lt;ID_OF_THE_APP&amp;gt; &lt;span class="nv">step&lt;/span>&lt;span class="o">=&lt;/span>&amp;lt;STEP_FROM_CONST_COMMON&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>从特定开发步骤继续处理现有应用程序&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">python main.py &lt;span class="nv">app_id&lt;/span>&lt;span class="o">=&lt;/span>&amp;lt;ID_OF_THE_APP&amp;gt; &lt;span class="nv">skip_until_dev_step&lt;/span>&lt;span class="o">=&lt;/span>&amp;lt;DEV_STEP&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>这与 &lt;code>step&lt;/code> 基本相同，但在实际开发过程中。如果您想使用 gpt-pilot，这可能是您经常使用的标志。&lt;/p>
&lt;ul>
&lt;li>删除之前完成的所有开发步骤，并从开发开始继续处理现有应用程序&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">python main.py &lt;span class="nv">app_id&lt;/span>&lt;span class="o">=&lt;/span>&amp;lt;ID_OF_THE_APP&amp;gt; &lt;span class="nv">skip_until_dev_step&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="m">0&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="-示例">🔎 示例&lt;/h2>
&lt;p>以下是 GPT Pilot 自己创建的几个示例应用程序：&lt;/p>
&lt;h3 id="-实时聊天应用程序">📱 实时聊天应用程序&lt;/h3>
&lt;ul>
&lt;li>💬 提示：&lt;code>一个具有实时通信功能的简单聊天应用程序&lt;/code>&lt;/li>
&lt;li>▶️ &lt;a class="link" href="https://youtu.be/bUj9DbMRYhA" target="_blank" rel="noopener"
>应用程序创建过程的视频&lt;/a>&lt;/li>
&lt;li>💻️ &lt;a class="link" href="https://github.com/Pythagora-io/gpt-pilot-chat-app-demo" target="_blank" rel="noopener"
>GitHub 存储库&lt;/a>&lt;/li>
&lt;/ul>
&lt;h3 id="-markdown-编辑器">📝 Markdown 编辑器&lt;/h3>
&lt;ul>
&lt;li>💬 提示：&lt;code>使用 HTML、CSS 和 JavaScript 构建一个简单的 Markdown 编辑器。允许用户输入 Markdown 文本并实时显示格式化输出。&lt;/code>&lt;/li>
&lt;li>▶️ &lt;a class="link" href="https://youtu.be/uZeA1iX9dgg" target="_blank" rel="noopener"
>应用程序创建过程的视频&lt;/a>&lt;/li>
&lt;li>💻️ &lt;a class="link" href="https://github.com/Pythagora-io/gpt-pilot-demo-markdown-editor.git" target="_blank" rel="noopener"
>GitHub 存储库&lt;/a>&lt;/li>
&lt;/ul>
&lt;h3 id="-计时器应用程序">⏱️ 计时器应用程序&lt;/h3>
&lt;ul>
&lt;li>💬 提示：&lt;code>使用 HTML、CSS 和 JavaScript 创建一个简单的计时器应用程序，允许用户设置倒计时器并在时间到时收到警报。&lt;/code>&lt;/li>
&lt;li>▶️ &lt;a class="link" href="https://youtu.be/CMN3W18zfiE" target="_blank" rel="noopener"
>应用程序创建视频流程&lt;/a>&lt;/li>
&lt;li>💻️ &lt;a class="link" href="https://github.com/Pythagora-io/gpt-pilot-timer-app-demo" target="_blank" rel="noopener"
>GitHub 存储库&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="-gpt-pilot-的主要支柱">🏛 GPT Pilot 的主要支柱：&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>为了让 AI 创建功能齐全的应用程序，&lt;strong>开发人员需要参与&lt;/strong>应用程序创建过程。他们需要能够随时更改代码，并且 GPT Pilot 需要继续处理这些更改（例如，添加 API 密钥或在 AI 卡住时修复问题)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>应用程序需要像开发人员编写的那样逐步编写&lt;/strong> - 假设您想要创建一个简单的应用程序，并且您知道编码所需的所有内容，并且脑子里有整个架构。即使这样，您也不会完全编写代码，然后第一次运行它并立即调试所有问题。相反，您将实现一些简单的事情，例如添加路由，运行它，看看它是如何工作的，然后继续执行下一个任务。这样，您就可以在出现问题时进行调试。人工智能编码的情况也应该如此。它肯定会犯错误，因此为了更轻松地调试问题并让开发人员了解正在发生的情况，人工智能不应该立即吐出整个代码库。相反，应用程序应该像开发人员编写代码一样逐步开发 - 例如。设置路由、添加数据库连接等。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>该方法需要可扩展&lt;/strong>，以便 AI 可以创建可用于生产的应用程序&lt;/p>
&lt;ol>
&lt;li>&lt;strong>上下文倒带&lt;/strong> - 用于解决每个开发任务，发给 LLM 的第一条消息的上下文大小必须相对相同。例如，实现开发任务#5 时的第一条LLM 消息的上下文大小必须与开发任务#50 时的第一条消息大致相同。因此，每项任务都需要将对话退回到第一条消息。 &lt;a class="link" href="https://blogpythagora.files.wordpress.com/2023/08/pythagora-product-development-frame-3-1.jpg?w=1714" target="_blank" rel="noopener"
>参见此处的图表&lt;/a>。&lt;/li>
&lt;li>&lt;strong>递归对话&lt;/strong>是以可以“递归”使用的方式设置的 LLM 对话。例如，如果 GPT Pilot 检测到错误，则需要对其进行调试，但假设在调试过程中发生了另一个错误。然后，GPT Pilot 需要停止调试第一个问题，修复第二个问题，然后再返回修复第一个问题。我认为，这是一个非常重要的概念，需要努力使人工智能能够自行构建大型且可扩展的应用程序。它的工作原理是倒回上下文并分别解释递归中的每个错误。一旦修复了最深层次的错误，我们就会在递归中向上移动并继续修复该错误。我们这样做直到整个递归完成。&lt;/li>
&lt;li>&lt;strong>TDD（测试驱动开发）&lt;/strong> - 为了使 GPT Pilot 能够扩展代码库，它需要能够在不破坏以前编写的代码的情况下创建新代码。没有比使用 TDD 方法更好的方法了。对于 GPT Pilot 编写的每个代码，都需要编写测试来检查代码是否按预期工作，以便每当进行新的更改时，都可以运行之前的所有测试。&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ol>
&lt;p>这个想法是，如果没有开发人员的参与，人工智能将无法（至少在不久的将来）从头开始创建应用程序。这就是为什么我们创建了一个交互式工具，它可以生成代码，但也要求开发人员检查每个步骤，以便他们能够了解正在发生的事情，以便人工智能可以更好地了解整个代码库。&lt;/p>
&lt;p>显然，它仍然无法创建任何生产就绪的应用程序，但它如何工作的一般概念已经存在。&lt;/p>
&lt;h2 id="-gpt-pilot-是如何工作的以下是-gpt-pilot-创建应用程序所需的步骤">🏗 GPT Pilot 是如何工作的？以下是 GPT Pilot 创建应用程序所需的步骤：&lt;/h2>
&lt;p>&lt;img src="https://github.com/Pythagora-io/gpt-pilot/assets/10895136/d89ba1d4-1208-4b7f-b3d4-76e3ccea584e"
loading="lazy"
alt="GPT Pilot 工作流程"
>&lt;/p>
&lt;ol>
&lt;li>您输入应用程序名称和描述&lt;/li>
&lt;li>&lt;strong>产品负责人代理&lt;/strong> 会问几个问题以更好地理解需求&lt;/li>
&lt;li>&lt;strong>产品负责人代理&lt;/strong> 编写用户故事并询问您是否全部正确（这有助于稍后创建代码）&lt;/li>
&lt;li>&lt;strong>架构师代理&lt;/strong> 编写将用于应用程序的技术&lt;/li>
&lt;li>&lt;strong>DevOps 代理&lt;/strong> 检查计算机上是否安装了所有技术，如果没有安装则安装它们&lt;/li>
&lt;li>&lt;strong>技术主管代理&lt;/strong> 编写开发人员需要实施的开发任务。这是一个重要的部分，因为对于每个步骤，技术主管都需要指定用户（现实世界的开发人员）如何检查任务是否完成（例如，打开 localhost:3000 并执行某些操作）&lt;/li>
&lt;li>&lt;strong>开发人员代理&lt;/strong>接受每项任务并写下实施该任务需要做什么。该描述采用人类可读的形式。&lt;/li>
&lt;li>最后，&lt;strong>Code Monkey 代理&lt;/strong>获取开发人员的描述和当前实施文件，并将更改实施到其中。我们意识到这比立即将其交给开发人员实施更改要有效得多。&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="https://github.com/Pythagora-io/gpt-pilot/assets/10895136/53ea246c-cefe-401c-8ba0-8e4dd49c987b"
loading="lazy"
alt="GPT Pilot 编码工作流程"
>&lt;/p>
&lt;h1 id="gpt-pilot-与其他项目有什么不同">🕴GPT Pilot 与其他项目有什么不同？&lt;/h1>
&lt;ul>
&lt;li>&lt;strong>GPT Pilot 与开发人员合作创建完全可用于生产的应用程序&lt;/strong>&lt;/li>
&lt;li>我认为人工智能无法（至少在不久的将来）在没有开发人员参与的情况下创建应用程序。因此，&lt;strong>GPT Pilot 逐步对应用程序进行编码&lt;/strong>，就像开发人员在现实生活中一样。这样，它可以调试在整个开发过程中出现的问题。如果遇到问题，您（负责的开发人员）可以检查代码并解决问题。其他类似的工具可以立即为您提供整个代码库&lt;/li>
&lt;li>这样，对于人工智能和作为开发人员的您来说，修复错误都要困难得多。&lt;/li>
&lt;li>&lt;strong>大规模工作&lt;/strong> - GPT Pilot 并不是为了创建简单的应用程序，而是为了让它可以在任何规模上工作。它具有过滤代码的机制，因此在每个 LLM 对话中，它不需要在上下文中存储整个代码库，但它只向 LLM 显示与其当前正在处理的任务相关的代码。应用程序完成后，您始终可以通过编写有关要添加哪些功能的说明来继续开发它。&lt;/li>
&lt;/ul></description></item><item><title>洞悉 Agent-GPT</title><link>https://umpire2018.github.io/p/%E6%B4%9E%E6%82%89-agent-gpt/</link><pubDate>Thu, 21 Sep 2023 20:07:13 +0800</pubDate><guid>https://umpire2018.github.io/p/%E6%B4%9E%E6%82%89-agent-gpt/</guid><description>&lt;blockquote>
&lt;p>版本所有：© 2023 Reworkd AI, Inc.&lt;/p>
&lt;p>原文链接：&lt;a class="link" href="https://reworkd.ai/blog/Understanding-AgentGPT" target="_blank" rel="noopener"
>Reworkd Blog&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>生成式预训练变换器（GPT）的发明是近十年来人工智能技术最重要的进步之一。为当今的大型语言模型 (LLM) 提供支持的 GPT 展示了卓越的推理、理解和规划能力。然而，它们的真正潜力尚未完全发挥。&lt;/p>
&lt;p>在 Reworkd，我们相信 LLMs 的真正力量在于代理行为。通过设计一个利用 LLM 的新兴能力的系统并提供支持环境相互作用的生态系统，我们可以充分发挥 GPT-4 等模型的潜力。以下是 AgentGPT 的工作原理。&lt;/p>
&lt;h2 id="llm-有很多限制">LLM 有很多限制&lt;/h2>
&lt;p>&lt;a class="link" href="https://www.techopedia.com/definition/34826/foundation-model" target="_blank" rel="noopener"
>Foundation Model - Techopedia&lt;/a>. 基础模型 - 技术百科。&lt;/p>
&lt;p>如果您熟悉 OpenAI 的 API，则与模型聊天时可能使用的常用公式可能包括：&lt;/p>
&lt;ul>
&lt;li>获取用户指令。&lt;/li>
&lt;li>添加聊天历史。&lt;/li>
&lt;li>通过 API 发送聊天历史记录以获取回答。&lt;/li>
&lt;/ul>
&lt;p>当对话范围较小时，此方法效果很好；然而，当您继续向聊天历史记录中添加新消息时，完成的大小和复杂性会不断增加，您很快就会碰壁：可怕的上下文限制。&lt;/p>
&lt;p>首先引入 &lt;strong>tokens&lt;/strong> 这个概念，形如 字 word 是人类来计算文本长度的最小单位（比如一句话有十个字），而 tokens 则是自然语言处理文本长度的最小单位。数据表明，一个汉字平均在 ChatGPT(GPT3.5和GPT4) 下大概消耗1.12个token。而在一次与 Model 进行交互的过程中，上下文限制则是在一次交互过程中可以输入到模型中的最大标记数。随着我们添加更多的 tokens ，Model 用于计算的成本往往呈指数增长，所以这往往是提示工程师的孽缘。&lt;/p>
&lt;p>一种解决方案是统计聊天历史记录中的 token 数量，将旧消息删除再将其发送到 Model 中以确保其符合 token 限制。虽然这种方法有效，但它最终会减少可用于求知的知识量。&lt;/p>
&lt;p>LLM 们面临的另一个问题是需要人工指导。从根本上说，LLM 们用来预测下一个词的，通常，它们的内部结构本质上并不适合高阶思维过程，例如通过复杂任务进行推理。但这种不足并不意味着它们不能或不会&lt;strong>推理&lt;/strong>。事实上，有几项 &lt;a class="link" href="https://arxiv.org/abs/2205.11916" target="_blank" rel="noopener"
>研究&lt;/a> 表明它们可以。然而，这确实意味着它们面临某些障碍。例如，LLM 自身可以创建一个逻辑步骤列表；然而，它没有观察和反思该清单的内置机制。&lt;/p>
&lt;p>A pre-trained model is essentially a &amp;ldquo;black box&amp;rdquo; for the end user in which the final product that is shipped has &lt;em>limited to no capability of actively updating its knowledge base and tends to act in unpredictable ways&lt;/em>. As a result, it&amp;rsquo;s &lt;a class="link" href="https://arxiv.org/abs/2202.03629" target="_blank" rel="noopener"
>hallucination&lt;/a>-prone.对于最终用户来说，预训练模型本质上是一个“黑匣子”，其最终交付的产品几乎没有主动更新其知识库的能力，并且往往以不可预测的方式运行，所以很容易产生&lt;a class="link" href="https://arxiv.org/abs/2202.03629" target="_blank" rel="noopener"
>幻觉&lt;/a>。&lt;/p>
&lt;p>Thus, it requires a lot of effort on the user&amp;rsquo;s part to guide the model&amp;rsquo;s output, and prompting the LLM itself becomes a job on its own. This extra work is a far cry from our vision of an AI-powered future.因此，需要用户付出很大的努力来指导模型的输出，而促使LLM本身就成为了一项工作。这项额外的工作与我们对人工智能驱动的未来的愿景相去甚远。&lt;/p>
&lt;p>By providing a platform to give LLMs agentic abilities, &lt;em>AgentGPT aims to overcome the limitations of standalone LLMs by leveraging prompt engineering techniques, vector databases, and API tooling.&lt;/em> Here’s some interesting work that is being done with the agent concept:通过提供一个平台来赋予法学硕士代理能力，AgentGPT 旨在利用即时工程技术、矢量数据库和 API 工具来克服独立法学硕士的局限性。以下是利用代理概念所做的一些有趣的工作：&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/DrJimFan/status/1673006745067847683" target="_blank" rel="noopener"
>&lt;img src="https://platform.twitter.com/embed/Tweet.html?dnt=false&amp;amp;embedId=twitter-widget-0&amp;amp;frame=false&amp;amp;hideCard=false&amp;amp;hideThread=false&amp;amp;id=1673006745067847683&amp;amp;lang=en&amp;amp;origin=https%3A%2F%2Fpublish.twitter.com%2F%3Fquery%3Dhttps3A2F2Ftwitter.com2FDrJimFan2Fstatus2F1673006745067847683%26widget%3DTweet&amp;amp;theme=light&amp;amp;widgetsVersion=82e1070%3A1619632193066&amp;amp;width=550px"
loading="lazy"
alt="Tweet by Dr. Jim Fan"
>&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>Alt: A Twitter post by Dr. Jim FanAlt：Jim Fan 博士的 Twitter 帖子&lt;/p>
&lt;/blockquote>
&lt;h2 id="what-are-agents什么是代理">What are agents? 什么是代理？&lt;/h2>
&lt;p>In a general sense, &lt;a class="link" href="https://zapier.com/blog/ai-agent/" target="_blank" rel="noopener"
>agents&lt;/a> are rational actors. They use thinking and reasoning to influence their environment. &lt;em>This could be in the form of solving problems or pursuing specific goals. They might interact with humans or utilize tools.&lt;/em> Ultimately, we can apply this concept to LLMs to instill more intelligent and logical behavior.
一般意义上，代理人是理性的行为者。他们利用思考和推理来影响他们的环境。这可以是解决问题或追求特定目标的形式。他们可能与人类互动或使用工具。最终，我们可以将这一概念应用于法学硕士，以灌输更多智能和逻辑行为。&lt;/p>
&lt;p>In AgentGPT, large language models essentially function as the &lt;strong>brain&lt;/strong> of each agent. As a result, we can produce powerful agents by cleverly &lt;em>manipulating the English language&lt;/em> and engineering a &lt;em>framework that supports interoperability between LLM completions and a diverse set of APIs&lt;/em>.
在 AgentGPT 中，大型语言模型本质上充当每个代理的大脑。因此，我们可以通过巧妙地操作英语并设计一个支持 LLM 完成和各种 API 之间互操作性的框架来生产强大的代理。&lt;/p>
&lt;h3 id="engineering-this-system-consists-of-3-parts该系统的工程由-3-部分组成">Engineering this system consists of 3 parts.该系统的工程由 3 部分组成。&lt;/h3>
&lt;p>&lt;strong>Reasoning and Planning.&lt;/strong> If you were to simply take a general goal, such as &amp;ldquo;build a scaling e-commerce platform,&amp;rdquo; and give it to ChatGPT, you would likely get a response along the lines of &amp;ldquo;As an AI language model….&amp;rdquo; However, through &lt;strong>prompt engineering&lt;/strong>, we can get a model to &lt;em>break down goals into digestible steps and reflect on them&lt;/em> with a method called chain of thought prompting.
推理和计划。如果您只是简单地提出一个总体目标，例如“构建一个可扩展的电子商务平台”，并将其交给 ChatGPT，您可能会得到类似“作为人工智能语言模型&amp;hellip;&amp;hellip;”的响应。然而，通过提示工程，我们可以得到一个模型，将目标分解为可消化的步骤，并用一种称为思维链提示的方法对其进行反思。&lt;/p>
&lt;p>&lt;strong>Memory.&lt;/strong> When dealing with memory, we divide the problem into &lt;strong>short-term&lt;/strong> and &lt;strong>long-term&lt;/strong>. In managing short-term memory, we can use prompting techniques such as &lt;em>few-shot prompting to steer LLM responses&lt;/em>. However, &lt;em>cost and context limits make it tricky to generate completions without limiting the breadth of information&lt;/em> a model can use to make decisions.
记忆。在处理记忆时，我们将问题分为短期和长期。在管理短期记忆时，我们可以使用提示技术（例如几次提示）来引导法学硕士的反应。然而，成本和上下文限制使得在不限制模型可用于做出决策的信息广度的情况下生成完成结果变得很棘手。&lt;/p>
&lt;p>Similarly, this issue also arises in &lt;strong>long-term memory&lt;/strong> because it would be impossible to provide an appropriate corpus of writing to bridge the gap between GPT -4&amp;rsquo;s cutoff date, 2021, till today. By using vector databases, we attempt to overcome this using specialized models for &lt;em>information retrieval in high-dimensional vector spaces&lt;/em>.
同样，这个问题也出现在长期记忆中，因为不可能提供适当的写作语料库来弥合 GPT -4 的截止日期 2021 年与今天之间的差距。通过使用向量数据库，我们尝试使用高维向量空间中的信息检索专用模型来克服这个问题。&lt;/p>
&lt;p>&lt;strong>Tools&lt;/strong>. Another challenge in using LLMs as general actors is their confinement to text outputs. Again, we can use prompt engineering techniques to solve this issue. We can generate predictable function calls from the LLM through few-shot and chain-of-thought methods, utilizing API tools like &lt;strong>Google Search&lt;/strong>, &lt;strong>Hugging Face&lt;/strong>, &lt;strong>Dall-E&lt;/strong>, etc. In addition, we can use fine-tuned LLMs that only return responses in specialized formatting, like JSON. This is the approach OpenAI took when they recently released the function calling feature for their API.
工具。使用法学硕士作为一般参与者的另一个挑战是它们仅限于文本输出。同样，我们可以使用及时的工程技术来解决这个问题。我们可以利用 Google Search、Hugging Face、Dall-E 等 API 工具，通过少样本和思维链方法从 LLM 生成可预测的函数调用。此外，我们可以使用仅返回的微调 LLM采用特殊格式的响应，例如 JSON。这是 OpenAI 最近发布其 API 的函数调用功能时所采用的方法。&lt;/p>
&lt;p>These three concepts have formed the backbone of multiple successful agent-based LLM platforms such as &lt;a class="link" href="https://github.com/microsoft/JARVIS" target="_blank" rel="noopener"
>Microsoft Jarvis&lt;/a>, &lt;a class="link" href="https://github.com/Significant-Gravitas/Auto-GPT" target="_blank" rel="noopener"
>AutoGPT&lt;/a>, &lt;a class="link" href="https://github.com/yoheinakajima/babyagi" target="_blank" rel="noopener"
>BabyAGI&lt;/a>, and of course, AgentGPT. With this brief overview in mind, let&amp;rsquo;s dive deeper into each component.
这三个概念构成了多个成功的基于代理的 LLM 平台的支柱，例如 Microsoft Jarvis、AutoGPT、BabyAGI，当然还有 AgentGPT。记住这个简短的概述，让我们更深入地了解每个组件。&lt;/p>
&lt;h2 id="how-do-we-get-agents-to-act-intelligently我们如何让代理人明智地行动">How do we get agents to act intelligently?我们如何让代理人明智地行动？&lt;/h2>
&lt;p>&lt;strong>Prompt engineering&lt;/strong> has become highly popularized, and it&amp;rsquo;s only natural given its ability to &lt;em>increase the reliability of LLM responses&lt;/em>, opening a wide avenue of potential applications for generative AI. AgentGPT&amp;rsquo;s ability to think and reason is a result of novel prompting methods.
即时工程已经高度普及，考虑到它能够提高法学硕士反应的可靠性，为生成式人工智能的潜在应用开辟了广阔的途径，这是很自然的。 AgentGPT 的思考和推理能力是新颖的提示方法的结果。&lt;/p>
&lt;h3 id="a-brief-intro-to-prompt-engineering快速工程简介">A Brief Intro to Prompt Engineering快速工程简介&lt;/h3>
&lt;p>Prompt engineering is a largely empirical field that aims to find methods to steer LLM responses by finding clever ways to use the English language. *You can think of it like lawyering, where every nuance in the wording of a prompt counts.
即时工程是一个很大程度上是经验性的领域，旨在通过巧妙地使用英语来找到指导 LLM 反应的方法。你可以把它想象成律师，提示措辞中的每一个细微差别都很重要。&lt;/p>
&lt;p>These are the main concepts and building blocks for more advanced prompting techniques:这些是更高级提示技术的主要概念和构建模块：&lt;/p>
&lt;ol>
&lt;li>&lt;strong>Zero-Shot&lt;/strong> involves sending the raw command directly to the LLM with little to no formatting.零射击涉及将原始命令直接发送到 LLM，几乎不需要格式化。&lt;/li>
&lt;li>&lt;strong>Few-Shot&lt;/strong> gives context for completions in the form of example responses.Few-Shot 以示例响应的形式提供完成的上下文。&lt;/li>
&lt;li>&lt;strong>Chain-of-Thought&lt;/strong> guides the model in reasoning through generating and reasoning over a complex task.思想链通过对复杂任务的生成和推理来指导模型进行推理。&lt;/li>
&lt;/ol>
&lt;h3 id="how-agentgpt-uses-prompt-engineeringagentgpt-如何使用即时工程">How AgentGPT Uses Prompt EngineeringAgentGPT 如何使用即时工程&lt;/h3>
&lt;p>AgentGPT uses an advanced form of chain-of-thought prompting called &lt;strong>Plan-and-Solve&lt;/strong> to generate the steps you see when operating the agents.AgentGPT 使用一种称为“计划与解决”的高级思维链提示形式来生成您在操作代理时看到的步骤。&lt;/p>
&lt;p>Traditionally, chain-of-thought prompting utilized few-shot techniques to provide examples of a thinking and reasoning process. However, as is becomes a theme, it becomes more costly as the complexity of a task increases because we will need to provide more context.
传统上，思维链提示利用小样本技术来提供思维和推理过程的示例。然而，当它成为一个主题时，随着任务复杂性的增加，它的成本也会变得更高，因为我们需要提供更多的上下文。&lt;/p>
&lt;p>&lt;strong>Plan-and-solve (PS):&lt;/strong> By virtue of being a zero-shot method, it provides a &lt;em>prompting framework for LLM-guided reasoning using &amp;ldquo;trigger&amp;rdquo; words&lt;/em>. These keywords trigger a reasoning response from the model.计划与解决（PS）：由于是一种零样本方法，它为使用“触发”词的 LLM 引导推理提供了一个提示框架。这些关键字触发模型的推理响应。&lt;/p>
&lt;p>We can expand on this concept by &lt;em>modifying the prompt to extract important variables and steps to generate a final response with a cohesive format&lt;/em>. This method allows us to parse the final response and display it for the end user as well as feed sub-steps into future plan-and-solve prompts.我们可以通过修改提取重要变量的提示和生成具有内聚格式的最终响应的步骤来扩展这个概念。此方法允许我们解析最终响应并将其显示给最终用户，并将子步骤提供给未来的计划和解决提示。&lt;/p>
&lt;p>&lt;img src="https://petal-diplodocus-04a.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F29d8c98c-21e6-4991-992d-62d95fd40dba%2FScreen_Shot_2023-07-01_at_12.25.37_PM.png?id=021895a6-149a-4282-aa8e-6719e7d7c47a&amp;amp;table=block&amp;amp;spaceId=46c3481b-d8de-4c34-8647-2292d63a5f29&amp;amp;width=2000&amp;amp;userId=&amp;amp;cache=v2"
loading="lazy"
alt="Screen Shot 2023-07-01 at 12.25.37 PM.png"
>&lt;/p>
&lt;blockquote>
&lt;p>Alt: Picture of Plan &amp;amp; SolveAlt：计划和解决方案的图片&lt;/p>
&lt;/blockquote>
&lt;p>While PS prompting helps evoke a reasoning response, it still misses a fundamental concept in reasoning, and that is proper handling for reflection and action. &lt;strong>Reflection&lt;/strong>is &lt;em>fundamental for any agent because it must rationalize an action, perform that action, and use feedback to adjust future actions.&lt;/em> Without it, the agent would be stateless and unchanging.
虽然 PS 提示有助于唤起推理反应，但它仍然忽略了推理中的一个基本概念，那就是对反思和行动的正确处理。反思对于任何智能体来说都是基础，因为它必须合理化某个动作、执行该动作并使用反馈来调整未来的动作。没有它，代理将是无状态且不变的。&lt;/p>
&lt;p>AgentGPT uses a prompting framework called Reasoning and Acting (&lt;a class="link" href="https://arxiv.org/pdf/2210.03629.pdf" target="_blank" rel="noopener"
>ReAct&lt;/a>) to expand on the capabilities of the Plan-and-Solve concept. &lt;strong>ReAct&lt;/strong> aims to &lt;em>enable a framework for the model to access fresh knowledge through external knowledge bases and make observations of actions it has taken&lt;/em>. Using those observations, the LLM can make educated decisions on the next set of steps to complete while performing actions to query knowledge bases such as &lt;strong>Google Search&lt;/strong> or &lt;strong>Wikipedia API&lt;/strong>.
AgentGPT 使用称为推理和行动 (ReAct) 的提示框架来扩展计划和解决概念的功能。 ReAct 旨在为模型提供一个框架，使其能够通过外部知识库获取新知识并观察其所采取的行动。利用这些观察结果，法学硕士可以对下一组要完成的步骤做出明智的决策，同时执行查询知识库（例如 Google 搜索或维基百科 API）的操作。&lt;/p>
&lt;p>Prompt engineering is largely effective in resolving challenges in short-term memory as well as instilling the reasoning behavior that you can see when AgentGPT is at work. However, prompt engineering does not resolve the issue of long-term memory. This issue is where vector databases come in, and we will look at those next.
即时工程在解决短期记忆挑战以及灌输 AgentGPT 工作时可以看到的推理行为方面非常有效。然而，即时工程并不能解决长期记忆的问题。这个问题就是矢量数据库的用武之地，我们接下来将讨论这些问题。&lt;/p>
&lt;p>&lt;img src="https://petal-diplodocus-04a.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F481f0812-00e5-4cb1-9ed6-4f2f9215eef5%2FScreen_Shot_2023-07-03_at_3.12.56_AM.png?id=8002f409-2913-4e68-b8b6-6100c4128cf5&amp;amp;table=block&amp;amp;spaceId=46c3481b-d8de-4c34-8647-2292d63a5f29&amp;amp;width=2000&amp;amp;userId=&amp;amp;cache=v2"
loading="lazy"
alt="Screen Shot 2023-07-03 at 3.12.56 AM.png"
>&lt;/p>
&lt;blockquote>
&lt;p>Alt : ReAct (Reason + Act) Logic PictureAlt : ReAct (理性 + 行动) 逻辑图&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>The ReAct framework allows us to generate a reasoning response, an action, and a reflection to steer the model’s response. This example is courtesy of the following paper: &lt;a class="link" href="https://arxiv.org/abs/2210.03629" target="_blank" rel="noopener"
>ReAct: Synergizing Reasoning and Acting in Language Models&lt;/a>*ReAct 框架允许我们生成推理响应、操作和反射来引导模型的响应。此示例由以下论文提供：ReAct：在语言模型中协同推理和行动*&lt;/p>
&lt;/blockquote>
&lt;h2 id="how-do-we-give-agents-a-working-memory我们如何为代理提供工作记忆">How do we give agents a working memory?我们如何为代理提供工作记忆？&lt;/h2>
&lt;p>While we have seen that &lt;em>prompt engineering is largely effective in resolving issues with short-term memory and reasoning&lt;/em>, we cannot solve long-term memory solely through clever English. Since we are not allowed to update the model to learn our data, we must build an external system for storing and retrieving knowledge.虽然我们已经看到即时工程在解决短期记忆和推理问题方面非常有效，但我们不能仅通过聪明的英语来解决长期记忆。由于我们不允许更新模型来学习数据，因此我们必须构建一个外部系统来存储和检索知识。&lt;/p>
&lt;p>A clever solution might use an LLM to &lt;em>generate summaries of previous conversations as context for the prompt&lt;/em>. However, there are three significant issues with this. First, we are diluting the relevant information for the conversation; second, it introduces another cost area by paying for API usage for those summaries; and third, it&amp;rsquo;s unscalable.一个聪明的解决方案可能会使用法学硕士来生成以前对话的摘要作为提示的上下文。然而，这存在三个重大问题。首先，我们淡化对话的相关信息；其次，它引入了另一个成本领域，即为这些摘要的 API 使用付费；第三，它是不可扩展的。&lt;/p>
&lt;p>Thus, prompts appear to be ineffective for long-term memory. Seeing as &lt;em>long-term memory is a problem of storage and efficient retrieval of information&lt;/em>, there is no absence of research in the study of search, so we must look towards vector databases.因此，提示似乎对长期记忆无效。由于长期记忆是一个信息存储和高效检索的问题，搜索的研究并不缺乏，因此我们必须将目光投向向量数据库。&lt;/p>
&lt;h3 id="vector-databases-demystified揭秘矢量数据库">Vector Databases Demystified揭秘矢量数据库&lt;/h3>
&lt;p>&lt;strong>&lt;a class="link" href="https://aws.amazon.com/what-is/vector-databases/" target="_blank" rel="noopener"
>Vector databases&lt;/a>&lt;/strong> have been hyped up for a while now, and the hype is very deserved. They are an efficient way of storing and retrieving vectors by allowing us to use some fun new *algorithms to query billions - even trillions - of data records in milliseconds.*矢量数据库已经被炒作有一段时间了，而且这种炒作是非常值得的。它们是存储和检索向量的有效方法，允许我们使用一些有趣的新算法在几毫秒内查询数十亿甚至数万亿条数据记录。&lt;/p>
&lt;p>Let&amp;rsquo;s start with a little bit of vocabulary:让我们从一些词汇开始：&lt;/p>
&lt;ul>
&lt;li>A &lt;strong>vector&lt;/strong> in the context of an LLM is a representation of a piece of text that a model like GPT-4 encodes.LLM 上下文中的向量是 GPT-4 等模型编码的一段文本的表示。&lt;/li>
&lt;li>A &lt;strong>vector space&lt;/strong> contains many of these vectors.向量空间包含许多这样的向量。&lt;/li>
&lt;li>An &lt;strong>embedding&lt;/strong> is the vectorized version of a text.嵌入是文本的矢量化版本。&lt;/li>
&lt;/ul>
&lt;h3 id="vector-libraries-like向量库如">Vector libraries like 向量库如&lt;/h3>
&lt;p>&lt;a class="link" href="https://www.bing.com/ck/a?!&amp;amp;&amp;amp;p=a0f4167bc6cd7db9JmltdHM9MTY4ODM0MjQwMCZpZ3VpZD0zOTYwYjczZS1hNzg2LTY5Y2MtMjM2YS1hNDdmYTYwMjY4MjImaW5zaWQ9NTIwMQ&amp;amp;ptn=3&amp;amp;hsh=3&amp;amp;fclid=3960b73e-a786-69cc-236a-a47fa6026822&amp;amp;psq=faiss&amp;#43;github&amp;amp;u=a1aHR0cHM6Ly9naXRodWIuY29tL2ZhY2Vib29rcmVzZWFyY2gvZmFpc3M&amp;amp;ntb=1" target="_blank" rel="noopener"
>Facebook AI Similarity Search&lt;/a> ( FAISS) give us access to valuable *tools to control these vectors and locate them efficiently in the vector space.*Facebook AI 相似性搜索 (FAISS) 为我们提供了宝贵的工具来控制这些向量并在向量空间中有效地定位它们。&lt;/p>
&lt;p>Since the text is in a numerical embedding dictated by the model type (i.e., text-embedding-ada-002), there is some location in space that the text exists in, and it&amp;rsquo;s based on the numbers that compose its vector. That means &lt;em>similar texts will be represented as vectors with similar numbers, and thus, they will likely be grouped closely. On the other hand, less similar texts will be further away&lt;/em>. For example, texts about cooking will be closer to food than texts about physics.由于文本处于由模型类型指定的数字嵌入中（即 text-embedding-ada-002），因此文本存在于空间中的某个位置，并且它基于组成其向量的数字。这意味着相似的文本将被表示为具有相似数字的向量，因此它们可能会被紧密地分组。另一方面，不太相似的文本会离得更远。例如，关于烹饪的文本比关于物理的文本更接近食物。&lt;/p>
&lt;p>There are several different algorithms for querying the vector space, but the most relevant to this discussion is the cosine similarity search. &lt;strong>&lt;a class="link" href="https://www.geeksforgeeks.org/cosine-similarity/" target="_blank" rel="noopener"
>Cosine similarity&lt;/a>&lt;/strong> measures the cosine of the angle between two non-zero vectors. &lt;em>It is a measure of orientation, meaning that it&amp;rsquo;s used to determine how similar two documents (or whatever the vectors represent) are&lt;/em>. Cosine similarity can range from -1 to 1, with -1 meaning the vectors are diametrically opposed (completely opposite), 0 meaning the vectors are orthogonal (or unrelated), and 1 meaning the vectors are identical.有几种不同的算法用于查询向量空间，但与本讨论最相关的是余弦相似度搜索。余弦相似度测量两个非零向量之间角度的余弦。它是方向的度量，这意味着它用于确定两个文档（或向量表示的任何内容）的相似程度。余弦相似度的范围为 -1 到 1，其中 -1 表示向量完全相反（完全相反），0 表示向量正交（或不相关），1 表示向量相同。&lt;/p>
&lt;p>FAISS is helpful in managing these vector spaces, but it is not a database. &lt;em>Vector libraries lack &lt;a class="link" href="https://www.freecodecamp.org/news/crud-operations-explained/" target="_blank" rel="noopener"
>CRUD&lt;/a> operations, which makes them alone unviable for long-term memory&lt;/em>, and that&amp;rsquo;s where cloud services such as Pinecone and Weaviate step in.FAISS 有助于管理这些向量空间，但它不是数据库。矢量库缺乏 CRUD 操作，这使得它们无法单独用于长期记忆，而这正是 Pinecone 和 Weaviate 等云服务介入的地方。&lt;/p>
&lt;p>&lt;strong>Pinecone&lt;/strong> and &lt;strong>Weaviate&lt;/strong> essentially do all the hard work of managing our vectors. They provide an API that allows you to upload embeddings, perform various types of searches, and store those vectors for later. *They provide the typical CRUD functions we need to instill memory into LLMs in easily-accessible Python modules.*Pinecone 和 Weaviate 基本上完成了管理我们载体的所有艰苦工作。他们提供了一个 API，允许您上传嵌入、执行各种类型的搜索并存储这些向量以供以后使用。它们提供了我们需要的典型 CRUD 函数，以便将内存注入到易于访问的 Python 模块中的 LLM 中。&lt;/p>
&lt;p>By using them, we can encode large amounts of information for future storage and retrieval. For instance, when the LLM needs extra knowledge to complete a task, we can prompt it to query the vector space to find relevant information. Thus, we can create long-term memory.通过使用它们，我们可以对大量信息进行编码以供将来存储和检索。例如，当LLM需要额外的知识来完成任务时，我们可以提示它查询向量空间以查找相关信息。因此，我们可以创造长期记忆。&lt;/p>
&lt;p>&lt;img src="https://petal-diplodocus-04a.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fad2521b3-1c6b-4f16-b719-d2b766570c61%2FCybrCo_Art_A_human-like_robot_touching_a_flower_for_the_first_t_92e97d56-54fa-4bb0-8581-5a1e15fd94aa.webp?id=8d261d10-f4e4-4798-bc33-8f40da67bb42&amp;amp;table=block&amp;amp;spaceId=46c3481b-d8de-4c34-8647-2292d63a5f29&amp;amp;width=2000&amp;amp;userId=&amp;amp;cache=v2"
loading="lazy"
alt="CybrCo_Art_A_human-like_robot_touching_a_flower_for_the_first_t_92e97d56-54fa-4bb0-8581-5a1e15fd94aa.webp"
>&lt;/p>
&lt;blockquote>
&lt;p>Alt : Robot With A Rose In HandAlt : 手握玫瑰的机器人&lt;/p>
&lt;/blockquote>
&lt;h2 id="tools-to-interact-with-the-environment与环境交互的工具">Tools to interact with the environment与环境交互的工具&lt;/h2>
&lt;p>While &lt;strong>prompt engineering&lt;/strong> and &lt;strong>vector databases&lt;/strong> resolve many of the limitations and challenges of LLMs, there is still the problem of agent interaction. *How can we extend the capabilities of an LLM to interact with the environment outside of text?*虽然即时工程和矢量数据库解决了法学硕士的许多限制和挑战，但仍然存在代理交互的问题。我们如何扩展法学硕士与文本之外的环境交互的能力？&lt;/p>
&lt;p>APIs are the answer. By utilizing APIs, we can give our agents the ability to perform a wide range of actions and access external resources.API 就是答案。通过利用 API，我们可以让我们的代理能够执行各种操作并访问外部资源。&lt;/p>
&lt;p>Here are a few examples:这里有一些例子：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Google Search API&lt;/strong>: Allows agents to search the web and retrieve relevant information.Google Search API：允许代理搜索网络并检索相关信息。&lt;/li>
&lt;li>&lt;strong>Hugging Face&lt;/strong>: Provides access to various NLP models and transformers for tasks such as summarization, translation, sentiment analysis, and more.Hugging Face：提供对各种 NLP 模型和转换器的访问，以执行摘要、翻译、情感分析等任务。&lt;/li>
&lt;li>&lt;strong>Dall-E&lt;/strong>: Enables agents to generate images from textual descriptions.Dall-E：使代理能够根据文本描述生成图像。&lt;/li>
&lt;li>&lt;strong>OpenAI&amp;rsquo;s GPT API&lt;/strong>: Allows agents to utilize the GPT-4 model for text completion and generation.OpenAI 的 GPT API：允许代理利用 GPT-4 模型进行文本完成和生成。&lt;/li>
&lt;/ul>
&lt;p>Using API tools in combination with prompt engineering techniques, we can create prompts that generate predictable function calls and utilize the output of API requests to enhance the agent&amp;rsquo;s capabilities. This enables agents to interact with the environment in a meaningful way beyond text-based interactions.使用 API 工具与提示工程技术相结合，我们可以创建生成可预测函数调用的提示，并利用 API 请求的输出来增强代理的功能。这使得代理能够以一种超越基于文本的交互的有意义的方式与环境交互。&lt;/p>
&lt;h3 id="engineering-robust-function-calls工程稳健的函数调用">Engineering Robust Function Calls工程稳健的函数调用&lt;/h3>
&lt;p>Again, we can achieve tooling through prompt engineering by &lt;em>representing the tool we want to provide for the model&lt;/em> as a &lt;strong>function&lt;/strong>. &lt;em>We can then tell the model that this function exists in a prompt, so our program can call it programmatically based on the model&amp;rsquo;s response&lt;/em>. First, however, we should examine the main challenges in implementing tool interactions: consistency, context, and format.同样，我们可以通过将我们想要为模型提供的工具表示为函数来通过即时工程来实现工具。然后我们可以告诉模型该函数存在于提示中，因此我们的程序可以根据模型的响应以编程方式调用它。然而，首先，我们应该检查实现工具交互的主要挑战：一致性、上下文和格式。&lt;/p>
&lt;p>For example, responses tend to vary among chat completions that use the same prompt. Thus, getting the LLM to issue a function call consistently is challenging. A minor solution may include adjusting the &lt;strong>temperature&lt;/strong> of the model (a parameter to control the randomness), but the best solution should leverage an LLM&amp;rsquo;s reasoning abilities. Thus, *we can use the ReAct framework to help the llm understand when to issue function calls.*例如，使用相同提示的聊天完成之间的响应往往会有所不同。因此，让法学硕士一致地发出函数调用是具有挑战性的。一个次要的解决方案可能包括调整模型的温度（控制随机性的参数），但最好的解决方案应该利用法学硕士的推理能力。因此，我们可以使用 ReAct 框架来帮助 llm 了解何时发出函数调用。&lt;/p>
&lt;p>In doing this, we will still run into another major issue. How will the LLMs understand what tools are at their disposal? We could include the available tools in a prompt, but this could significantly increase the number of tokens we would need to send to the model. While this may be fine for an application that runs on a couple of tools, it will increase costs as we add more tools to the system. Thus, *we would use vector databases to help the LLM look up relevant tools it needs.*在这样做的过程中，我们还会遇到另一个重大问题。法学硕士如何了解他们可以使用哪些工具？我们可以在提示中包含可用的工具，但这可能会显着增加我们需要发送到模型的令牌数量。虽然这对于在多个工具上运行的应用程序来说可能没问题，但随着我们向系统添加更多工具，它会增加成本。因此，我们将使用向量数据库来帮助法学硕士查找其所需的相关工具。&lt;/p>
&lt;p>Finally, we need to generate function calls in a predictable format. This format should include provisions for the name of the function and the parameters it takes, and it must include delimiters that allow us to parse and execute the response for those parameters programmatically. *For instance, you can prompt the model to only return responses in JSON and then use built-in Python libraries to parse the stringified JSON.*最后，我们需要以可预测的格式生成函数调用。此格式应包括函数名称及其采用的参数的规定，并且必须包括允许我们以编程方式解析和执行这些参数的响应的分隔符。例如，您可以提示模型仅返回 JSON 格式的响应，然后使用内置 Python 库来解析字符串化的 JSON。&lt;/p>
&lt;p>Recently, it became even easier to use this type of method as well. In late June, OpenAI released &lt;strong>gpt-4-0613&lt;/strong> and &lt;strong>gpt-3.5-turbo-16k-0613&lt;/strong> (whew, these names are getting long). They natively support function calls by using a model fine-tuned for JSON to return easy-to-use function calls. You can read more about it &lt;a class="link" href="https://platform.openai.com/docs/guides/gpt/function-calling" target="_blank" rel="noopener"
>here&lt;/a>.最近，使用这种方法也变得更加容易。 6月下旬，OpenAI发布了gpt-4-0613和gpt-3.5-turbo-16k-0613（哇，这些名字越来越长了）。它们通过使用针对 JSON 进行微调的模型来原生支持函数调用，以返回易于使用的函数调用。你可以在这里读更多关于它的内容。&lt;/p>
&lt;h2 id="the-future-of-llm-powered-agents-is-brightllm-代理人的未来是光明的">The future of LLM-powered agents is bright!LLM 代理人的未来是光明的！&lt;/h2>
&lt;p>Large language models have been one of the most significant advances of the past decade. Capable of reasoning and talking like a human, they appear to be able to do anything. Despite this, several engineering challenges arise in building around an LLM, such as context limits, reasoning, and long-term retention.大型语言模型是过去十年最重大的进步之一。它们能够像人类一样推理和说话，似乎能够做任何事情。尽管如此，围绕法学硕士的构建仍会出现一些工程挑战，例如上下文限制、推理和长期保留。&lt;/p>
&lt;p>Using the methods described above, &lt;strong>AgentGPT&lt;/strong> unlocks the full potential of powerful models such as GPT-4. &lt;em>We can give any model superpowers using novel prompting methods, efficient vector databases, and abundant API tools&lt;/em>. It&amp;rsquo;s only the start, and we hope you&amp;rsquo;ll join us on this journey.使用上述方法，AgentGPT 释放了 GPT-4 等强大模型的全部潜力。通过新颖的提示方法、高效的向量数据库、丰富的API工具，我们可以赋予任何模型超能力。这只是一个开始，我们希望您能加入我们的旅程。&lt;/p>
&lt;h2 id="conclusion结论">Conclusion 结论&lt;/h2>
&lt;p>AgentGPT represents a powerful approach to building AI agents that reason, remember, and perform. By leveraging prompt engineering, vector databases, and API tools, we can overcome the limitations of standalone LLMs and create agents that demonstrate agentic behavior.AgentGPT 代表了构建具有推理、记忆和执行功能的 AI 代理的强大方法。通过利用即时工程、矢量数据库和 API 工具，我们可以克服独立法学硕士的局限性，并创建能够展示代理行为的代理。&lt;/p>
&lt;p>With the ability to reason, plan, and reflect, AgentGPT agents can tackle complex tasks and interact with the environment in a meaningful way. By incorporating long-term memory through vector databases and utilizing APIs, we provide agents with access to a vast pool of knowledge and resources.凭借推理、计划和反思的能力，AgentGPT 代理可以处理复杂的任务并以有意义的方式与环境交互。通过向量数据库整合长期记忆并利用 API，我们为代理提供了访问大量知识和资源的机会。&lt;/p>
&lt;p>AgentGPT is a step towards unlocking the full potential of LLMs and creating intelligent agents that can assist and collaborate with humans in various domains. The combination of language models, prompt engineering, external memory, and API interactions opens up exciting possibilities for AI agents in the future.AgentGPT 是朝着释放法学硕士的全部潜力和创建可以在各个领域协助人类并与人类协作的智能代理迈出的一步。语言模型、即时工程、外部存储器和 API 交互的结合为人工智能代理的未来开辟了令人兴奋的可能性。&lt;/p></description></item><item><title>《综述：全新大语言模型驱动的Agent》——4.5万字详细解读复旦NLP和米哈游最新Agent Survey</title><link>https://umpire2018.github.io/p/%E7%BB%BC%E8%BF%B0%E5%85%A8%E6%96%B0%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E9%A9%B1%E5%8A%A8%E7%9A%84agent4.5%E4%B8%87%E5%AD%97%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BB%E5%A4%8D%E6%97%A6nlp%E5%92%8C%E7%B1%B3%E5%93%88%E6%B8%B8%E6%9C%80%E6%96%B0agent-survey/</link><pubDate>Wed, 20 Sep 2023 23:01:39 +0800</pubDate><guid>https://umpire2018.github.io/p/%E7%BB%BC%E8%BF%B0%E5%85%A8%E6%96%B0%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E9%A9%B1%E5%8A%A8%E7%9A%84agent4.5%E4%B8%87%E5%AD%97%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BB%E5%A4%8D%E6%97%A6nlp%E5%92%8C%E7%B1%B3%E5%93%88%E6%B8%B8%E6%9C%80%E6%96%B0agent-survey/</guid><description>&lt;img src="https://umpire2018.github.io/p/%E7%BB%BC%E8%BF%B0%E5%85%A8%E6%96%B0%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E9%A9%B1%E5%8A%A8%E7%9A%84agent4.5%E4%B8%87%E5%AD%97%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BB%E5%A4%8D%E6%97%A6nlp%E5%92%8C%E7%B1%B3%E5%93%88%E6%B8%B8%E6%9C%80%E6%96%B0agent-survey/cover.png" alt="Featured image of post 《综述：全新大语言模型驱动的Agent》——4.5万字详细解读复旦NLP和米哈游最新Agent Survey" />&lt;blockquote>
&lt;p>原文作者 &lt;a class="link" href="https://www.zhihu.com/people/shou-zu-ji-qiang-bing" target="_blank" rel="noopener"
>知乎用户：兽族机枪兵&lt;/a>&lt;/p>
&lt;p>原文出处：https://zhuanlan.zhihu.com/p/656676717&lt;/p>
&lt;p>原文讨论论文链接：https://arxiv.org/pdf/2309.07864v1.pdf&lt;/p>
&lt;p>TITLE：The Rise and Potential of Large Language Model Based Agents: A Survey&lt;/p>
&lt;/blockquote>
&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>本文章主要分为五个大的模块：&lt;/p>
&lt;p>第2章主要是一些背景介绍，对于搞学术的人而言，很多灵感和故事都是从一个概念的源头被启发出来的，因此我也将原文的Background部分在第1章进行了精炼。&lt;/p>
&lt;p>第3章节讲的是LLM-based Agent的基本构成。本文认为，构成LLM-based Agent的核心部件有三个：&lt;/p>
&lt;p>brain: 主要目标有2个——信息记忆、信息处理
perception: 主要目标在于让agent能够感受到更多不同模态的信息
action: 主要目标在于输出文字、控制智能体的行为、使用工具，从而能针对环境变化做出反应。
第4章讲的是LLM-based Agent的应用。本文将这些应用也分为三块进行详述：&lt;/p>
&lt;p>Single-Agent
Multi-Agent
Human-Agent Collaboration
第5章讲的是LLM-based Agent Society。这块的目标在于探究agent如何认识环境，以及如何与其他agent进行复杂的社会性交互。本文也将Agent Society拆为三快内容进行详述：&lt;/p>
&lt;p>Human-like behavior and personality
对于目前主流的环境介绍，包括Text-based Environment, virtual sandbox environment, physical world environment.
Social Phenomena：主要涉及一些多agent在虚拟环境中交互的反馈
第6章主要就是一些讨论，这些讨论还蛮有意思的，主要有这么五个主题：&lt;/p>
&lt;p>Mutual Benefits
Evaluation efforts
Potential risks
Scaling up agent counts
Several open problems&lt;/p>
&lt;h2 id="background">Background&lt;/h2>
&lt;h3 id="agent这个词是如何出现的">Agent这个词是如何出现的&lt;/h3>
&lt;p>有很多人或许会疑惑，Agent这个东西看起来跟LLM也没差得那么远，那为啥最近突然Agent那么火，而不称之为LLM-Application或者其他的词呢？这就得从agent的来历上说起了，因为Agent是个很古老的术语，甚至可以追溯至亚里士多德和休谟等人的言论。从哲学意义上讲，“代理人”是指具有行动能力的实体，而“代理”一词则表示这种能力的行使或体现。而从狭义上讲，“代理”通常是指有意行动的表现；相应地，“代理人”一词表示拥有欲望、信念、意图和行动能力的实体。需要注意的是，代理人不仅包括人类个体，还包括物理世界和虚拟世界中的其他实体。重要的是，“代理”的概念涉及个人的自主性，赋予他们行使意志、做出选择和采取行动的能力，而不是被动地对外部刺激做出反应。&lt;/p>
&lt;p>在 20 世纪 80 年代中后期之前，主流人工智能界的研究人员对Agent相关概念的关注相对较少，这可能会让人感到惊讶。然而，从那时起，计算机科学和人工智能界对这一话题的兴趣就大大增加了。正如 Wooldridge 等人所言，我们可以这样定义人工智能：“它是计算机科学的一个子领域，旨在设计和构建基于计算机的、表现出智能行为各个方面的Agent。”因此，我们可以把Agent作为人工智能的核心概念。当Agent这一概念被引入人工智能领域时，其含义发生了一些变化。在哲学领域，Agent可以是人、动物，甚至是具有自主性的概念或实体。然而，在人工智能领域，Agent是一个计算实体。由于意识和欲望等概念对于计算实体来说似乎具有形而上学的性质，而且我们只能观察机器的行为，包括艾伦-图灵在内的许多人工智能研究者建议暂时搁置Agent是否“真正”在思考或是否真的拥有“思想”的问题。相反，研究人员采用其他属性来帮助描述Agent，如自主性、反应性、主动性和社交能力等属性。也有研究者认为，智能是“看人的眼睛”；它不是与生俱来的、孤立的属性。从本质上讲，AI Agent并不等同于Philosophy Agent；相反，它是Agent这一哲学概念在人工智能领域的具体化。在本文中，作者将AI Agent视为人工实体，它们能够使用传感器感知周围环境，做出决策，然后使用执行器采取行动。&lt;/p>
&lt;h3 id="ai-agent研究中的技术演变史">AI Agent研究中的技术演变史&lt;/h3>
&lt;p>Symbolic Agents: 在人工智能研究的早期阶段，最主要的方法是符号人工智能，其特点是依赖符号逻辑。这种方法采用逻辑规则和符号表示来封装知识和促进推理过程。它们主要关注两个问题：转换问题和表示/推理问题。这些Agent旨在模拟人类的思维模式。它们拥有明确的、可解释的推理框架，而且由于其符号性质，它们表现出高度的表达能力。这种方法的一个典型例子是基于知识的专家系统。然而，Symbolic Agent在处理不确定性和大规模现实世界问题时面临着局限性。此外，由于符号推理算法错综复杂，要找到一种能在有限时间内产生有意义结果的高效算法也很有挑战性。&lt;/p>
&lt;p>Reactive Agents: 与Symbolic Agent不同，Reactive Agent不使用复杂的符号推理。相反，它们主要关注Agent与其Environment之间的交互，强调快速和实时响应。这类Agent的设计优先考虑直接将输入输出进行映射，而不是复杂的推理和符号操作。Reactive Agent通常需要较少的计算资源，从而能做出更快的反应，但可能缺乏复杂的高层决策和规划能力。&lt;/p>
&lt;p>RL-based Agents: 该领域的主要关注点是如何让Agent通过与环境的交互进行学习，使其在特定任务中获得最大的累积奖励。最初，RL-based Agent主要基于强化学习算法，如策略搜索和价值函数优化，Q-learning和SARSA就是一个例子。随着深度学习的兴起，出现了深度神经网络与强化学习的整合，即深度强化学习。这使得Agent可以从高维输入中学习复杂的策略，从而取得了众多重大成就，如AlphaGo和DQN。这种方法的优势在于它能让Agent在未知环境中自主学习，而无需明确的人工干预。这使得它能广泛应用于从游戏到机器人控制等一系列领域。然而，强化学习也面临着一些挑战，包括训练时间长、采样效率低以及稳定性问题，尤其是在复杂的真实世界环境中应用时。&lt;/p>
&lt;p>Agent with transfer learning and meta learning: 传统上，训练强化学习Agent需要大量样本和较长的训练时间，而且缺乏泛化能力。因此，研究人员引入了迁移学习来加速Agent对新任务的学习。迁移学习减轻了新任务培训的负担，促进了知识在不同任务间的共享和迁移，从而提高了学习效率、绩效和泛化能力。此外，AI Agent也引入了元学习。元学习的重点是学习如何学习，使Agent能从少量样本中迅速推断出新任务的最优策略。这样的Agent在面对新任务时，可以利用已获得的一般知识和策略迅速调整其学习方法，从而减少对大量样本的依赖。然而，当源任务和目标任务之间存在显著差异时，迁移学习的效果可能达不到预期，并可能出现负迁移。此外，元学习需要大量的预训练和大量样本，因此很难建立通用的学习策略。&lt;/p>
&lt;p>LLM-based Agent: 由于大型语言模型已经展示出令人印象深刻的新兴能力，并受到广泛欢迎，研究人员已经开始利用这些模型来构建AI Agent。具体来说，他们采用 LLM 作为这些Agent的大脑或控制器的主要组成部分，并通过多模态感知和工具利用等策略来扩展其感知和行动空间。通过思维链（CoT）和问题分解等技术，这些基于 LLM 的Agent可以表现出与Symbolic Agen相当的推理和规划能力。它们还可以通过从反馈中学习和执行新的行动，获得与环境互动的能力，类似于Reactive Agent。同样，大型语言模型在大规模语料库中进行预训练，并显示出少量泛化的能力，从而实现任务间的无缝转移，而无需更新参数。LLM-based Agent已被应用于各种现实世界场景、如软件开发和科学研究。由于具有自然语言理解和生成能力，它们可以无缝互动，从而促进多个Agent之间的协作和竞争。&lt;/p>
&lt;h3 id="为什么llm能够作为agent的全新大脑">为什么LLM能够作为Agent的全新大脑&lt;/h3>
&lt;p>本文将深入探讨一些Agent关键属性，阐明它们与 LLM 的相关性，从而阐述为什么 LLM 非常适合作为AI Agent大脑。&lt;/p>
&lt;p>自主性（Autonomy）：自主性是指一个Agent在没有人类或其他人直接干预的情况下运行，并对其行动和内部状态拥有一定程度的控制。这意味着，AI Agent不仅应具备按照人类的明确指令完成任务的能力，还应表现出独立发起和执行行动的能力。这意味着一定程度的自主探索和决策，Auto-GPT等应用体现了 LLM 在构建Autonomious Agent方面的巨大潜力——只需向它们提供一项任务和一套可用工具，它们就能自主制定计划并执行计划，以实现最终目标。本文认为LLMs在自主性方面的表现主要体现在以下几点：&lt;/p>
&lt;p>LLMs可以通过生成类似人类的文本参与对话，并在没有详细步骤指示的情况下执行各种任务的能力来展示一种自主性。
LLMs能根据环境输入动态调整输出，体现出一定程度的自适应能力。
LLMs能通过展示创造力来体现自主性，比如提出新颖的想法、故事或解决方案，而这些并没有明确编入它们的程序。
反应性（Reactivity）：Agent的反应能力是指它对环境中的即时变化和刺激做出快速反应的能力。这意味着Agent可以感知周围环境的变化，并迅速采取适当的行动。传统上，语言模型的感知空间局限于文本输入，而行动空间则局限于文本输出。不过，研究人员已经证明，利用多模态融合技术可以扩展语言模型的感知空间，使其能够快速处理来自环境的视觉和听觉信息。这些进步使 LLMs 能够有效地与真实世界的物理环境互动，并在其中执行任务。一个主要挑战是：LLM-based Agent在执行非文本操作时，需要一个中间步骤，即以文本形式产生想法或制定工具使用方法，然后最终将其转化为具体操作。这一中间过程会消耗时间，降低响应速度。不过，这与人类的行为模式密切相关，因为人类的行为模式遵循“先思考后行动”的原则。&lt;/p>
&lt;p>主动性（Pro-activeness）：积极主动指的是，Agent不仅仅会对环境做出反应，它们还能积极主动地采取以目标为导向的行动。这一特性强调，Agent可以在行动中进行推理、制定计划和采取主动措施，以实现特定目标或适应环境变化。虽然直观上，LLMs 中的下一个标记预测范式可能不具备意图或愿望，但研究表明，它们可以隐式地生成这些状态的表征，并指导模型的推理过程。LLMs 具有很强的概括推理和规划能力。通过向大型语言模型发出类似 &amp;ldquo;让我们一步一步地思考 &amp;ldquo;的指令，我们可以激发它们的推理能力，如逻辑推理和数学推理。同样，大型语言模型也以目标重拟、任务分解和根据环境变化调整计划等形式显示了规划的新兴能力。&lt;/p>
&lt;p>社会能力（Social Ability）：社交能力指的是一个Agent通过某种Agent交流语言与其他Agent（包括人类）进行交互的能力。大型语言模型具有很强的自然语言交互能力，如理解和生成能力。与结构化语言或其他通信原语相比，这种能力使它们能够以可解释的方式与其他模型或人类进行交互，这构成了LLM-based Agent的社会能力的基石。许多研究人员已经证明，LLM-based Agent可以通过协作和竞争等社会行为提高任务绩效（Meta GPT）。通过输入特定的提示，LLM 也可以扮演不同的角色，从而模拟现实世界中的社会分工（Overcooked）。此外，当我们将多个具有不同身份的Agent放入一个社会中时，可以观察到新出现的社会现象（Generative Agent）。&lt;/p>
&lt;h2 id="the-birth-of-an-agent-construction-of-llm-based-agents">The Birth of An Agent: Construction of LLM-based Agents&lt;/h2>
&lt;p>图1：LLM-based Agent的概念框架，由大脑、感知、行动三个部分组成。作为控制器，大脑模块承担记忆、思考和决策等基本任务；感知模块负责感知和处理来自外部环境的多模态信息；行动模块负责使用工具执行任务并影响周围环境。
本文提出了LLM-based Agent的总体概念框架，由大脑、感知、行动三个关键部分组成（见图1）。&lt;/p>
&lt;h3 id="agent的大脑模块">Agent的大脑模块&lt;/h3>
&lt;p>图2：大脑模块的拓扑图
大脑主要由一个大型语言模型组成，不仅存储知识和记忆，还承担着信息处理和决策等功能，并可以呈现推理和规划的过程，能很好地应对未知任务。&lt;/p>
&lt;p>运行机制：为确保有效交流，自然语言交互能力(3.1.1)至关重要。在接收感知模块处理的信息后，大脑模块首先转向存储，在知识中检索(3.1.2)并从记忆中回忆(3.1.3)。这些结果有助于Agent制定计划、进行推理和做出明智的决定(3.1.4)。此外，大脑模块还能以摘要、矢量或其他数据结构的形式记忆Agent过去的观察、思考和行动。同时，它还可以更新常识和领域知识等知识，以备将来使用。LLM-based Agent还可以利用其固有的概括和迁移能力来适应陌生场景(3.1.5)。在随后的章节中将详细探讨图2所示的大脑模块的这些非凡功能。&lt;/p>
&lt;h3 id="自然语言交互">自然语言交互&lt;/h3>
&lt;p>作为一种交流媒介，语言包含着丰富的信息。除了直观表达的内容，背后还可能隐藏着说话者的信念、愿望和意图。由于 LLM 本身具有强大的自然语言理解和生成能力，Agent不仅可以熟练地使用多种语言进行基本的交互式对话，还能表现出深入的理解能力，从而使人类能够轻松地理解Agent并与之互动。&lt;/p>
&lt;p>多轮交互对话：多轮对话能力是有效和一致交流的基础。作为大脑模块的核心，LLM能够理解自然语言并生成连贯且与上下文相关的回复，从而帮助Agent更好地理解和处理各种问题。然而，即使是人类也很难在一次交流中不出现混乱，因此需要多轮对话。与 SQuAD 等传统的纯文本阅读理解任务相比，多轮对话具有以下几个特点：&lt;/p>
&lt;p>具有交互性，涉及多个说话者，缺乏连续性；
可能涉及多个话题，对话信息也可能是冗余的，使得文本结构更加复杂。
一般来说，多轮对话主要分为三个步骤： (1) 了解自然语言对话的历史；(2) 决定采取什么行动；(3) 生成自然语言回应。LLM-based Agent能够利用现有信息不断完善输出，进行多轮对话并有效实现最终目标。&lt;/p>
&lt;p>高质量的自然语言生成：最新的 LLM 展示了卓越的自然语言生成能力，可持续生成多种语言的高质量文本。LLM 生成内容的连贯性和语法准确性稳步提高，从GPT-3逐步发展到 InstructGPT，最终达到 GPT-4。这些语言模型可以“适应调节文本的风格和内容”，而像ChatGPT这样的模型在语法错误检测方面表现出色，凸显了其强大的语言能力。在对话语境中，LLMs 在对话质量的关键指标上也表现出色，包括内容、相关性和适当性。重要的是，LLMs 不仅仅复制训练数据，而且还表现出一定程度的创造力，能生成与人类制作的基准文本同样新颖甚至更加新颖的各种文本。同时，通过使用可控提示，确保对这些语言模型生成的内容进行精确控制，人类的监督依然有效。&lt;/p>
&lt;p>意图和含义理解：尽管在大规模语料库中训练出来的模型已经具有足够的智能来理解指令，但它们中的大多数仍无法模拟人类对话或充分利用语言所传达的信息。要想与其他智能机器人进行有效的交流与合作，理解其隐含的意思至关重要，并使人们能够解释他人的反馈。LLMs 的出现凸显了基础模型在理解人类意图方面的潜力，但当涉及到模糊指令或其他含义时，就会给Agent带来巨大挑战。对于人类来说，掌握对话中的隐含意义是自然而然的事，而对于Agent来说，他们应该将隐含意义形式化为奖励函数，使他们能够在看不见的语境中选择符合说话者偏好的选项。奖励建模的主要方法之一是根据反馈推断奖励，反馈主要以比较和无约束自然语言的形式呈现。另一种方法是以行动空间为桥梁，从描述中获取奖励。Jeon 等人认为，人类行为可以映射为从一组隐含选项中做出的选择，这有助于用一个统一的形式解释所有信息。利用对上下文的理解，Agent可以根据具体要求采取高度个性化和准确的行动。&lt;/p>
&lt;h3 id="知识">知识&lt;/h3>
&lt;p>研究表明，在大规模数据集上训练的语言模型可以将各种知识编码到其参数中，并对各种类型的查询做出正确的反应。此外，这些知识还能帮助LLM-based Agent做出明智的决策。所有这些知识可大致分为以下几类：&lt;/p>
&lt;p>语言知识：语言知识表现为一个约束系统，即语法，它定义了语言的所有和唯一可能的句子。它包括词法、句法、语义学和语用学。只有掌握了语言知识的Agent才能理解句子并进行多轮对话。此外，这些Agent可以通过在包含多种语言的数据集上进行训练来获取多语言知识，从而无需额外的翻译模型。
常识知识：常识性知识指的是大多数人在幼年时就已掌握的世界常识。例如，人们通常知道药是用来治病的，伞是用来防雨的。这些信息通常不会在上下文中明确提及。因此，缺乏相应常识性知识的模型可能无法理解或误解其中的含义。同样，缺乏常识性知识的Agent可能会做出错误的决定，比如在下大雨时不打伞。
专业领域知识：专业领域知识是指与特定领域相关的知识，如编程、数学、医学等。它对模型有效解决特定领域内的问题至关重要。例如，用于执行编程任务的模型需要具备编程知识，如代码格式。同样，用于诊断目的的模型应具备医学知识，如特定疾病和处方药的名称。
潜在问题：尽管 LLM 在获取、存储和利用知识方面表现出色，但仍然存在潜在的问题和悬而未决的难题。例如，模型在训练过程中获得的知识可能会过时，甚至从一开始就是错误的。解决这一问题的简单方法是重新训练。但是，这需要先进的数据、大量的时间和计算资源。更糟糕的是，它可能导致灾难性遗忘。因此，一些研究人员尝试编辑 LLM，以找到并修改模型中存储的特定知识。这包括在获取新知识的同时卸载不正确的知识。他们的实验表明，这种方法可以部分编辑事实知识，但其基本机制仍需进一步研究。此外，LLMs 可能会生成与来源或事实信息相冲突的内容，这种现象通常被称为幻觉。这也是 LLM 无法广泛应用于严格的事实任务的重要原因之一。为解决这一问题，一些研究人员提出了衡量幻觉程度的指标，为开发人员提供了评估 LLM 输出可信度的有效参考。此外，一些研究人员还使 LLM 能够利用外部工具来避免错误的 LLM 输出。&lt;/p>
&lt;h3 id="记忆">记忆&lt;/h3>
&lt;p>在本文的框架中，“记忆”存储了Agent过去的观察、思考和行动序列，这与 Nuxoll 等人提出的定义类似。正如人脑依靠记忆系统来回溯利用先前的经验制定策略和做出决策一样，Agent也需要特定的记忆机制来确保其熟练处理一系列连续任务。在面对复杂问题时，记忆机制能帮助行为主体有效地重新审视和应用先前的策略。此外，这些记忆机制还能使个体借鉴过去的经验，适应陌生的环境。随着LLM-based Agent互动周期的扩大，出现了两个主要挑战。第一个挑战与历史记录的长度有关。LLM-based Agent以自然语言格式处理先前的交互，并将历史记录附加到每个后续输入中。随着这些记录的增加，它们可能会超出大多数LLM-based Agent所依赖的 Transformer 架构的限制。在这种情况下，系统可能会截断某些内容。第二个挑战是提取相关记忆的难度。当Agent积累了大量的历史观察和行动序列时，它们就会面临不断升级的记忆负担。这使得在相关主题之间建立联系变得越来越具有挑战性，有可能导致Agent的反应与当前环境不一致。提高记忆能力的方法 下面我们介绍几种增强LLM-based Agent记忆能力的方法。&lt;/p>
&lt;p>提高Trransformer的输入长度限制：第一种方法试图解决或减轻固有的序列长度限制。由于这些固有限制，Transformer架构很难处理长序列。随着序列长度的增加，由于Self-Attention机制中的成对标记计算，计算需求将呈指数级增长。缓解这些长度限制的策略包括文本截断、分割输入，以及强调文本的关键部分。还有一些研究修改了注意力机制，以降低复杂性，从而适应较长的序列。
总结记忆：提高记忆效率的第二种策略取决于记忆总结的概念。这能确保Agent毫不费力地从历史互动中提取关键细节。一些方法利用提示简洁地整合记忆，而另一些方法则强调反思过程，以创建浓缩的记忆表征。分层方法将对话精简为每日快照和总体总结。一些特定的策略将环境反馈转化为文本封装，从而加强了Agent对未来参与的语境把握。此外，在multi-agent环境中，Agent交流的重要元素会被捕获并保留下来 。
用向量或数据结构压缩记忆：通过采用合适的数据结构，智能Agent可提高记忆检索效率，促进对交互做出迅速反应。值得注意的是，有几种方法依赖于为记忆部分、计划或对话历史嵌入向量。另一种方法将句子转化为三元组配置，还有一些方法将记忆视为独特的数据对象，从而促进不同的交互。此外，ChatDB和DB-GPT将 LLMrollers 与 SQL 数据库整合在一起，通过 SQL 命令进行数据操作。
记忆检索方法&lt;/p>
&lt;p>当Agent与其环境或用户交互时，必须从其内存中检索最合适的内容。这可确保Agent访问相关的准确信息，以执行特定操作。这就产生了一个重要问题： Agent如何选择最合适的存储器？通常情况下，Agent要求存储器具有自动检索记忆的能力。自动检索的一个重要方法是考虑三个指标： 最近性（Recency）、相关性（Relevance）和重要性（Importance）。记忆得分由这些指标加权组合而成，得分最高的记忆在模型的上下文中被优先考虑。一些研究引入了交互式记忆对象的概念，即对话历史的表现形式，可以移动、编辑、删除或通过总结进行组合。用户可以查看和操作这些对象，从而影响Agent对对话的感知。同样，其他研究也允许根据用户提供的特定命令进行删除等记忆操作。这些方法确保了记忆内容与用户的期望密切相关。&lt;/p>
&lt;h3 id="推理和规划">推理和规划&lt;/h3>
&lt;p>推理（Reasoning）：推理以证据和逻辑为基础，是人类智力活动的根本，是解决问题、决策和批判性分析的基石。演绎、归纳和归纳是智力活动中常见的主要推理形式。对于LLM-based Agent来说，与人类一样，推理能力对于解决复杂任务至关重要 。关于大型语言模型的推理能力，学术界存在不同观点。一些人认为语言模型在预训练或微调过程中就具备了推理能力，而另一些人则认为推理能力是在达到一定规模后才出现的。具体来说，具有代表性的思维链（CoT）方法通过引导 LLM 在输出答案之前生成理由，已被证明能够激发大型语言模型的推理能力。此外，还提出了其他一些提高 LLM 性能的策略，如自我一致性、自我修正、自我完善和选择推理等。一些研究表明，分步推理的有效性可归因于训练数据的局部统计结构，与对所有变量进行训练相比，变量间局部结构化的依赖关系能产生更高的数据效率。&lt;/p>
&lt;p>规划（Planning）：规划是人类在面对复杂挑战时采用的一种关键策略。对人类来说，规划有助于组织思维、设定目标和确定实现这些目标的步骤。与人类一样，规划能力对Agent也至关重要，而规划模块的核心是推理能力。这为LLM-based Agent提供了一个结构化的思维过程。通过规划，Agent可将复杂的任务分解为更易于管理的子任务，并为每个子任务制定适当的计划。此外，随着任务的进展，Agent可以利用内省来修改其计划，确保计划更符合实际情况，从而适应并成功执行任务。通常，规划包括两个阶段：计划制定和计划反思。&lt;/p>
&lt;p>计划制定：在制定计划的过程中，Agent通常会将总体任务分解成许多子任务，在这一阶段，人们提出了各种方法。值得注意的是，一些著作主张LLM-based Agent一次性全面分解问题，一次性制定完整的计划，然后按顺序执行。与此相反，其他研究（如 CoT 系列）则采用自适应策略，一次规划和处理一个子任务，从而更流畅地处理复杂的整体任务。此外，有些方法强调分层规划，而另一些方法则强调一种策略，即从树状结构的推理步骤中推导出最终计划。后一种方法认为，在最终确定计划之前，Agent应评估所有可能的路径。虽然基于 LLM 的Agent展示了广博的常识，但在遇到需要专业知识的情况时，它们偶尔也会面临挑战。通过将这些Agent与特定领域的规划者相结合来增强它们的能力，已证明能产生更好的性能。
计划反思：制定计划后，必须对其优点进行反思和评估。LLM-based Agent可利用内部反馈机制（通常是从已有模型中汲取灵感）来完善和改进其战略和规划方法。为了更好地与人类的价值观和偏好保持一致，Agent会主动与人类接触，从而纠正一些误解，并将这些有针对性的反馈吸收到其规划方法中。此外，它们还可以从有形或虚拟环境中获得反馈，如任务完成情况的提示或行动后的观察，帮助它们修改和完善计划。&lt;/p>
&lt;h3 id="可迁移性和通用性">可迁移性和通用性&lt;/h3>
&lt;p>在大规模语料库上预先训练的模型可以学习通用语言表征。利用预训练模型的强大功能，只需少量数据进行微调，LLMs 就能在下游任务中表现出卓越的性能。无需从头开始训练新模型，从而节省了大量计算资源。然而，通过这种针对特定任务的微调，模型缺乏通用性，很难推广到其他任务中。LLM-based Agent不只是发挥静态知识库的作用，而是展现出动态学习能力，使其能够快速、稳健地适应新任务。&lt;/p>
&lt;p>看不见的任务泛化：研究表明，LLMs 可以根据自己的理解，按照指令完成在训练阶段没有遇到过的新任务。多任务学习是其中一种实现方式，例如，FLAN 在通过指令描述的任务集合上对语言模型进行微调，而 T0 则引入了一个统一的框架，将每个语言问题转换成文本到文本的格式。提示的选择对于适当的预测至关重要，而直接根据提示进行训练可以提高模型对未知任务进行泛化的鲁棒性。值得期待的是，通过扩大模型规模和训练指令的数量或多样性，可以进一步增强这种泛化能力。&lt;/p>
&lt;p>情境学习：大量研究表明，LLM 可以通过上下文学习（ICL）完成各种复杂任务，上下文学习指的是模型从上下文中的几个例子中学习的能力。少量语境内学习通过将原始输入与几个完整示例串联起来，作为丰富语境的提示，从而提高语言模型的预测性能。ICL 的主要思想是从类比中学习，这与人类的学习过程类似 。此外，由于提示是用自然语言编写的，因此交互是可解释和可改变的，从而更容易将人类知识纳入 LLM 。与监督学习过程不同，ICL 不涉及微调或参数更新，这可以大大降低模型适应新任务的计算成本。除文本外，研究人员还探索了 ICL 在不同多模态任务中的潜在能力，从而使Agent应用于大规模真实世界任务成为可能。&lt;/p>
&lt;p>持续学习：最近的研究强调了 LLM 的规划能力在促进Agent持续学习方面的潜力，这涉及技能的持续获取和更新。持续学习的一个核心挑战是灾难性遗忘：当模型学习新任务时，往往会丢失以前任务的知识。为应对上述挑战，人们做出了大量努力，这些努力大致可分为三类：参照以前的模型引入经常使用的术语 ；近似先验数据分布；设计具有任务自适应参数的架构。Voyager尝试解决由 GPT-4设计的课程学习方案（即难度递增的任务），通过从较简单的程序中综合出复杂的技能，该Agent不仅能迅速增强自身能力，还能有效对抗灾难性遗忘。&lt;/p>
&lt;h2 id="感知模块">感知模块&lt;/h2>
&lt;p>图3：感知模块的拓扑结构
感知模块的核心目的是将Agent的感知空间从纯文字领域扩展到包括文字、听觉和视觉模式在内的多模态领域。&lt;/p>
&lt;h3 id="文本输入">文本输入&lt;/h3>
&lt;p>LLM-based Agent已经具备了通过文本输入和输出与人类交流的基本能力。在用户的文本输入中，除了明确的内容外，还隐藏着信念、愿望和意图。理解隐含含义对于Agent掌握人类用户的潜在和潜在意图至关重要，从而提高Agent与用户的交流效率和质量。一些研究采用强化学习来感知隐含含义，并建立反馈模型以获得奖励。这有助于推断说话者的偏好，从而使Agent做出更个性化、更准确的回应。此外，由于Agent被设计用于复杂的真实世界环境，它将不可避免地遇到许多全新的任务。理解未知任务的文本指示对Agent的文本感知能力提出了更高的要求。经过指令调整的 LLM 可以表现出卓越的零样本指令理解和泛化能力，从而无需针对特定任务进行微调。&lt;/p>
&lt;h3 id="视觉输入">视觉输入&lt;/h3>
&lt;p>视觉输入通常包含大量有关世界的信息，包括Agent周围环境中物体的属性、空间关系、场景布局等。因此，将视觉信息与其他模式的数据整合在一起，可以为Agent提供更广泛的背景和更精确的理解，加深Agent对环境的感知。为了帮助Agent理解图像中包含的信息，一种直接的方法是为图像输入生成相应的文本描述，即图像标题。字幕可以直接与标准文本指令连接，并输入到Agent中。这种方法具有很高的可解释性，而且不需要额外的字幕生成训练，可以节省大量的计算资源。不过，字幕生成是一种低带宽方法，在转换过程中可能会丢失大量潜在信息。此外，Agent对图像的关注可能会带来偏差。&lt;/p>
&lt;p>受Transformer在自然语言处理中出色表现的启发，研究人员已将其应用扩展到计算机视觉领域。ViT/VQVAE等具有代表性的作品成功地利用Transformer对视觉信息进行了编码。研究人员首先将图像分割成固定大小的块，然后将这些块经过线性投影后作为Transformer的输入标记。最后，通过计算标记之间的自注意力，他们就能整合整个图像的信息，从而高效地感知视觉内容。因此，一些研究尝试直接将图像编码器和 LLM 结合起来，以端到端的方式训练整个模型。虽然这种Agent可以实现出色的视觉感知能力，但却要付出大量计算资源的代价。经过广泛预训练的视觉编码器和 LLM 可以大大提高机器人的视觉感知和语言表达能力。在训练过程中冻结视觉编码器和 LLM 中的一个或两个，是一种广泛采用的范式，可在训练资源和模型性能之间实现平衡。&lt;/p>
&lt;p>然而，LLM 无法直接理解视觉编码器的输出，因此有必要将图像编码转换为 LLM 可以理解的嵌入。换句话说，这需要将视觉编码器与 LLM 对齐，这通常需要在两者之间添加一个额外的可学习接口层。例如，BLIP-2 和 InstructBLIP 使用查询转换器（Q-Former）模块作为视觉编码器和 LLM 之间的中间层。Q-Former 是一种转换器，采用可学习的查询向量，使其具有提取语言信息视觉表征的能力。它可以为 LLM 提供最有价值的信息，减轻Agent学习视觉语言对齐的负担，从而减轻灾难性遗忘的问题。同时，一些研究者采用了一种计算效率较高的方法，即使用单个embedding layer来实现视觉-文本对齐，从而减少了训练额外参数的需要。此外，Embedding layer还能与可学习层有效结合，调整其输出的维度，使其与 LLM 兼容。&lt;/p>
&lt;p>视频输入由一系列连续的图像帧组成。因此，Agent用于感知图像的方法可能适用于视频领域，使Agent也能很好地感知视频输入。与图像信息相比，视频信息增加了一个时间维度。因此，Agent对不同帧间时间关系的理解对于感知视频信息至关重要。一些工作，如 Flamingo ，通过使用掩码机制来确保理解视频时的时间顺序。掩码机制限制了Agent的视角，当它感知到视频中的特定帧时，只能从时间上较早的帧中获取视觉信息。&lt;/p>
&lt;h3 id="听觉输入">听觉输入&lt;/h3>
&lt;p>一个非常直观的想法是，Agent可以将 LLMs 用作控制中心，以级联方式调用现有工具集或模型库来感知音频信息。例如，AudioGPT 充分利用了 FastSpeech、GenerSpeech、Whisper等模型的功能，这些模型在文本到语音、风格转换和语音识别等任务中取得了优异的成绩。音频频谱图直观地表示了音频信号随时间变化的频谱，对于一段时间内的一段音频数据，可将其抽象为有限长度的音频频谱图。音频频谱图具有二维表示形式，可视化为平面图像。因此，一些研究致力于将感知方法从视觉领域迁移到音频领域。AST（音频频谱图变换器）采用与 ViT 类似的变换器架构来处理音频频谱图图像。通过将音频频谱图分割成片段，它实现了对音频信息的有效编码。此外，一些研究人员从冻结编码器的想法中获得灵感，以减少训练时间和计算成本。&lt;/p>
&lt;h3 id="其他输入">其他输入&lt;/h3>
&lt;p>如前所述，许多研究都对文本、视觉和音频的感知单元进行了研究。然而，LLM-based Agent可能会配备更丰富的感知模块。未来，它们可以像人类一样感知和理解现实世界中的各种模式。例如，Agent可以拥有独特的触觉和嗅觉器官，从而在与物体交互时收集到更多详细信息。同时，Agent还能清楚地感知周围环境的温度、湿度和亮度，从而采取环境感知行动。&lt;/p>
&lt;p>此外，通过有效整合视觉、文字和光敏感性等基本感知能力，Agent还能开发出各种对人类友好的感知模块。InternGPT引入了指向指令。用户可以通过使用手势或移动光标来选择、拖动或绘制，从而与图像中难以描述的特定部分进行交互。添加指向指令有助于为单个文本指令提供更精确的规范。在此基础上，Agent还有可能感知更复杂的用户输入。例如，AR/VR 设备中的眼球跟踪、身体动作捕捉等技术，甚至是脑机交互中的脑电波信号。&lt;/p>
&lt;p>最后，LLM-baed Agent应具备对更广阔的整体环境的感知能力。目前，许多成熟且被广泛采用的硬件设备可以帮助Agent实现这一目标。激光雷达可以创建三维点云图，帮助Agent检测和识别周围环境中的物体。全球定位系统可以提供精确的位置坐标，并可与地图数据集成。惯性测量单元（IMU）可以测量和记录物体的三维运动，提供物体速度和方向的详细信息。然而，这些感知数据非常复杂，LLM-based Agent无法直接理解。探索Agent如何感知更全面的输入是未来一个很有前景的方向。&lt;/p>
&lt;h2 id="行动模块">行动模块&lt;/h2>
&lt;p>图4：行动模块的拓扑框架图
人类在感知环境后，大脑会对感知到的信息进行整合、分析和推理，并做出决策。随后，他们利用神经系统控制自己的身体，做出适应环境或创造性的行动，如交谈、躲避障碍或生火。当一个Agent拥有类似大脑的结构，具备知识、记忆、推理、规划和概括能力以及多模态感知能力时，它也有望拥有类似人类的各种行动来应对周围环境。在Agent的构建过程中，行动模块接收大脑模块发送的行动序列，并执行与环境互动的行动。&lt;/p>
&lt;h3 id="文本输出">文本输出&lt;/h3>
&lt;p>如第 2.1.1 节所述，基于Transformer的大型语言生成模型的兴起和发展，赋予了LLM-based Agent以固有的语言生成能力。它们生成的文本质量在流畅性、相关性、多样性和可控性等各个方面都非常出色。因此，LLM-based Agent可以成为异常强大的语言生成器。&lt;/p>
&lt;h3 id="工具使用">工具使用&lt;/h3>
&lt;p>工具是工具使用者能力的延伸。在面对复杂任务时，人类会使用工具来简化任务的解决过程并提高效率，从而节省时间和资源。同样，如果Agent也学会使用和利用工具，就有可能更高效、更高质量地完成复杂任务。LLM-based Agent在某些方面存在局限性，使用工具可以增强Agent的能力。&lt;/p>
&lt;p>LLM不具备记住每一条训练数据的能力。由于上下文提示的影响，它们也可能无法导向正确的知识，甚至产生知识幻觉。再加上缺乏语料库、训练数据以及针对特定领域和场景的调整，在专注于特定领域时，Agent的专业知识也会受到限制。专业化工具能让 LLM 以可插拔的形式增强其专业知识、调整领域知识并更适合特定领域的需求。&lt;/p>
&lt;p>LLM-based Agent决策过程缺乏透明度，使其在医疗保健和金融等高风险领域的可信度较低。&lt;/p>
&lt;p>LLM 容易受到对抗性攻击，对轻微输入修改的鲁棒性不足。相比之下，借助工具完成任务的Agent则表现出更强的可解释性和鲁棒性。工具的执行过程可以反映Agent处理复杂需求的方法，并提高其决策的可信度。由于工具是为各自的使用场景专门设计的，因此使用这类工具的Agent能更好地处理轻微的输入修改，并能更好地抵御对抗性攻击。&lt;/p>
&lt;p>LLM-based Agent不仅需要使用工具，而且非常适合工具集成。LLM 利用通过预训练过程和 CoT 提示积累的丰富世界知识，在复杂的交互环境中表现出了非凡的推理和决策能力，这有助于Agent以适当的方式分解和处理用户指定的任务。此外，LLMs 在意图理解和其他方面也显示出巨大潜力。当Agent与工具相结合时，可以降低工具使用的门槛，从而充分释放人类用户的创造潜能。&lt;/p>
&lt;p>理解工具：Agent有效使用工具的前提是全面了解工具的应用场景和调用方法。没有这种理解，Agent使用工具的过程将变得不可信，也无法真正提高Agent的能力。利用 LLM 强大的zero-shot learning和few-shot learning能力，Agent可以通过描述工具功能和参数的zero-shot demonstartion或提供特定工具使用场景和相应方法演示的少量提示来获取工具知识。这些学习方法与人类通过查阅工具手册或观察他人使用工具进行学习的方法类似。在面对复杂任务时，单一工具往往是不够的。因此，Agent应首先以适当的方式将复杂任务分解为子任务，然后有效地组织和协调这些子任务，这有赖于 LLM 的推理和规划能力，当然也包括对工具的理解。&lt;/p>
&lt;p>使用工具：Agent学习使用工具的方法主要包括从demonstartion中学习和从reward中学习（清华有一篇从训练数据中学习的文章）。这包括模仿人类专家的行为，以及了解其行为的后果，并根据从环境和人类获得的反馈做出调整。环境反馈包括行动是否成功完成任务的结果反馈和捕捉行动引起的环境状态变化的中间反馈；人类反馈包括显性评价和隐性行为，如点击链接。&lt;/p>
&lt;p>如果一个Agent刻板地应用工具而缺乏适应性，那么它就无法在所有场景中取得可接受的性能。Agent需要将其在特定环境中学到的工具使用技能推广到更普遍的情况中，例如将在雅虎搜索中训练的模型转移到谷歌搜索中。要做到这一点，Agent有必要掌握工具使用策略的共同原则或模式，而这有可能通过元工具学习来实现。加强Agent对简单工具和复杂工具之间关系的理解，例如复杂工具如何建立在较简单工具的基础上，有助于提高Agent归纳工具使用方法的能力。这样，Agent就能有效辨别各种应用场景中的细微差别，并将以前学到的知识迁移到新工具中。课程学习允许Agent从简单的工具开始，逐步学习复杂的工具，这也符合要求。此外，得益于对用户意图以及推理和规划能力的理解，Agent可以更好地设计工具使用和协作方法，从而提供更高质量的成果。&lt;/p>
&lt;p>制作自给自足的工具：现有的工具往往是为方便人类而设计的，这对Agent来说可能不是最佳选择。为了让Agent更好地使用工具，需要专门为Agent设计工具。这些工具应该更加模块化，其输入输出格式也更适合Agent。如果能提供说明和示范，LLM-based Agent还能通过生成可执行程序或将现有工具集成到功能更强大的工具中来创建工具，并能学会自我调试。此外，如果作为工具制作者的Agent成功创建了一个工具，那么除了使用工具本身之外，它还可以为multi-Agent系统中的其他Agent制作包含工具代码和演示的软件包。推测未来，Agent可能会变得自给自足，在工具方面表现出高度的自主性。&lt;/p>
&lt;p>工具可以拓展LLM-based Agent的行动空间：在工具的帮助下，Agent可以在推理和规划阶段利用各种外部资源，如外部数据库和网络应用程序。这一过程可以为LLM-based Agent提供专家级、可靠性、多样性和高质量的信息，促进Agent的决策和行动。例如，基于搜索的工具可以借助外部数据库、知识图谱和网页提高Agent可获取知识的范围和质量。而特定领域的工具则可以增强Agent在相应领域的专业知识，一些研究人员已经开发出了基于 LLM 的控制器，可生成 SQL 语句来查询数据库，或将用户查询转换为搜索请求，并使用搜索引擎来获得所需的结果。此外，LLM-based Agent还可以使用科学工具来执行化学中的有机合成等任务，或与 Python 解释器和 LaTeX 编译器对接，以提高其在复杂数学计算任务中的性能。对于multi-agent系统来说，通信工具（如电子邮件）可作为Agent在严格的安全约束下进行交互的一种手段，促进Agent之间的协作，并显示出自主性和灵活性。&lt;/p>
&lt;p>虽然前面提到的工具增强了Agent的能力，但与环境交互的媒介仍然是基于文本的。然而，工具的设计是为了扩展语言模型的功能，其输出并不局限于文本。用于非文本输出的工具可以使Agent行动的模式多样化，从而扩展LLM-based Agent的应用场景。例如，图像处理和生成可以由借鉴视觉模型的Agent来完成。在航空航天工程领域，人们正在探索用Agent来建立物理模型和求解复杂的微分方程；在机器人学领域，需要Agent来规划物理操作和控制机器人的执行。&lt;/p>
&lt;h3 id="具身行动">具身行动&lt;/h3>
&lt;p>在追求人工通用智能（AGI）的过程中，Embodied Agent被视为一种关键范式，它努力将模型智能与物理世界结合起来。一些学者从人类智能发展过程中汲取灵感，认为Agent的智能来源于与环境的持续互动和反馈，而不是仅仅依赖于精心编辑的预训练数据。同样，与传统的深度学习模型从互联网数据集中学习解决领域问题的明确能力不同，人们预计LLM-based Agent行为将不再局限于纯文本输出或调用精确的工具来执行特定领域的任务。相反，它们应该能够主动感知、理解物理环境并与之互动，根据 LLM 丰富的内部知识做出决策并产生特定行为来改变环境。我们将这些行为统称为“具身行动”（embodied actions），它使Agent能够以近似人类行为的方式与世界互动并理解世界。&lt;/p>
&lt;p>LLM-based Agent在具身行动方面的潜力：在 LLM 广泛兴起之前，研究人员倾向于使用强化学习等方法来探索Agent的具身行动。尽管基于 RL 的化身取得了广泛成功，但它在某些方面确实存在局限性。简而言之，RL 算法在数据效率、泛化和复杂问题推理方面都面临限制，原因是在模拟动态且往往模糊不清的真实环境方面存在挑战，或者严重依赖精确的奖励信号表示。最近的研究表明，利用在 LLM 预训练期间获得的丰富内部知识可以有效缓解这些问题：&lt;/p>
&lt;p>成本效益：一些基于策略的算法在样本效率方面存在困难，因为它们需要新鲜数据来更新策略，而为高性能训练收集足够多的体现数据成本高且噪声大。一些端到端模型也存在这种限制。通过利用 LLM 的内在知识，PaLM-E 等Agent将机器人数据与一般视觉语言数据进行联合训练，在具身任务中实现了显著的转移能力，同时也证明了几何输入表示法可以提高训练数据的效率。
具身动作泛化：面对错综复杂、未知的真实世界环境，Agent必须具备动态学习和泛化能力。然而，大多数 RL 算法都是为训练和评估特定任务的相关技能而设计的。与此相反，经过多种形式和丰富任务类型的微调，LLMs 显示出了显著的跨任务泛化能力。例如，PaLME 对新对象或现有对象的新组合表现出惊人的zero-time或one-time泛化能力。此外，语言能力是LLM-based Agent的独特优势，它既是与环境交互的手段，也是将基础技能转移到新任务的媒介。SayCan利用 LLMs 将提示中的任务指令分解为相应的技能命令，但在部分可观察环境中，有限的先前技能往往无法实现令人满意的性能。为了解决这个问题，Voyager引入了技能库组件，以不断收集新的自我验证技能，从而实现Agent的终身学习能力。
嵌入式行动规划：规划是人类和LLM-based Agent在应对复杂问题时采用的关键策略。在 LLM 展示出非凡的推理能力之前，研究人员引入了分层强化学习（HRL）方法，即高层策略约束低层策略的子目标，低层策略产生适当的行动信号。与高层策略的作用类似，具有新兴推理能的 LLM 也能以zero-shot或demonstration的方式无缝应用于复杂任务。此外，来自环境的外部反馈可以进一步提高LLM-based Agent的规划性能。一些研究基于当前的环境反馈，动态生成、维护和调整高级行动计划，以便在部分可观测环境中最大限度地减少对先前知识的依赖，从而使计划落地。反馈也可以来自模型或人类，通常可称为批评者，根据当前状态和任务提示评估任务完成情况。
具身action for LLM-based Agent：根据Agent在任务中的自主程度或行动的复杂程度，有几种基于 LLM 的基本具身行动，主要包括观察、操纵和导航。&lt;/p>
&lt;p>观察：观察是Agent获取环境信息和更新状态的主要方式，对提高后续体现行动的效率起着至关重要的作用。具身Agent的观察主要发生在具有各种输入的环境中，这些输入最终汇聚成多模态信号。一种常见的方法是使用预先训练好的视觉转换器（ViT）作为文本和视觉信息的对齐模块，并标注特殊标记来表示多模态数据的位置。声音空间（Soundspaces）提出通过混响音频输入来识别物理空间几何元素，从而以更全面的视角加强Agent的观察。近来，更多的研究将音频作为嵌入式观察的模式。除了广泛使用的级联范式，类似于 ViT 的音频信息编码进一步加强了音频与其他输入模式的无缝整合。Agent对环境的观察也可以来自人类的实时语言指令，而人类的反馈则有助于Agent获取可能无法轻易获得或解析的细节信息。
操纵：一般情况下，具身Agent的操纵任务包括物体重新排列、桌面操纵和移动操纵。典型的情况是，Agent在厨房执行一系列任务，包括从抽屉中取出物品并递给用户，以及清洁桌面。除了精确观察外，这还涉及利用 LLM 将一系列子目标结合起来。因此，保持Agent状态与子目标之间的同步非常重要。DEPS利用基于 LLM 的交互式规划方法来保持这种一致性，并在整个多步骤、长距离的推理过程中通过Agent的反馈来帮助纠错。相比之下，AlphaBlock 则专注于更具挑战性的操作任务（例如使用积木制作笑脸），这就要求Agent对指令有更扎实的理解。AlphaBlock 构建了一个数据集，其中包括 35 项复杂的高级任务，以及相应的多步骤规划和观察对，然后对多模态模型进行微调，以增强对高级认知指令的理解。
导航：导航允许Agent动态地改变其在环境中的位置，这通常涉及多角度和多目标观测，以及基于当前探索的远距离操作。在导航之前，对于具身Agent来说，必须事先建立关于外部环境的内部地图，其形式通常为拓扑图、语义图或占用图。例如，LM-Nav 利用 VNM 创建内部拓扑图。它进一步利用 LLM 和 VLM 来分解输入命令和分析环境，从而找到最佳路径。此外，一些研究强调了空间表示的重要性，通过利用预先训练好的 VLM 模型将图像中的视觉特征与物理世界的 3D 重构相结合，实现空间目标的精确定位，而不是传统的以点或物体为中心的导航行动。导航通常是一项长视距任务，Agent的未来状态会受到其过去行动的影响，这就需要一个内存缓冲区和总结机制来作为历史信息的参考，《Smallville》和《Voyager》也采用了这种机制。此外，一些工作提出音频输入也具有重要意义，但整合音频信息在将其与视觉环境关联方面存在挑战。
通过整合这些功能，Agent可以完成更复杂的任务，如体现式问题解答，其主要目标是自主探索环境并回答预先定义的多模态问题，如厨房里的西瓜比锅大吗？哪个更难？要解决这些问题，Agent需要导航到厨房，观察两个物体的大小，然后通过比较来回答问题。在控制策略方面，LLM-based Agent在特定的数据集上接受训练后，通常会生成高级策略命令，以控制低级策略实现特定的子目标。低级策略可以是机器人Transformer，它将图像和指令作为输入，为终端效应器以及特定具身任务中的机械臂生成控制命令。最近，在虚拟具身环境中，高级策略被用于控制游戏或模拟世界中的Agent。例如，Voyager调用 Mineflayer API 接口来不断获取各种技能和探索世界。&lt;/p>
&lt;p>具身行动的未来展望：基于 LLM 的化身行动被视为虚拟智能与物理世界之间的桥梁，使Agent能够像人类一样感知和改变环境。然而，物理世界机器人操作员的高昂成本和具身数据集的稀缺等制约因素依然存在，这促使人们对研究Agent在 Minecraft 等模拟环境中的具身行动越来越感兴趣。通过使用 Mineflayer 应用程序接口，这些研究能以低成本高效率地检查各种具身Agent的操作，包括探索、规划、自我完善甚至终身学习。尽管取得了显著进展，但由于模拟平台与物理世界之间的巨大差异，实现最佳的化身行动仍是一项挑战。为了能在真实世界场景中有效部署具身Agent，人们对具身任务范例和评估标准的要求越来越高，这些范例和标准必须与真实世界的条件密切相关。另一方面，Agent对于世界常识的理解也是一个障碍。例如，像 &amp;ldquo;像猫一样跳下来 &amp;ldquo;这样的表达方式主要传达一种轻盈和宁静的感觉，但这种语言隐喻需要足够的世界知识。有学者尝试将文本提炼与后视经验回放（HER）相结合，构建一个数据集，作为训练过程的监督信号。尽管如此，随着具身行动在人类生活的各个领域发挥着越来越关键的作用，仍有必要对具身数据集的基础进行更多研究。&lt;/p>
&lt;h2 id="agents-in-practice-harnessing-ai-for-good">Agents in Practice: Harnessing AI for Good&lt;/h2>
&lt;p>图5：应用Agent的拓扑框架图&lt;/p>
&lt;p>图6：基于 LLM 的代理应用场景。我们主要介绍三种应用场景：单个代理部署、多代理交互和人与代理交互。单个代理拥有多种能力，在各种应用方向上都能表现出出色的任务解决能力。当多代理互动时，它们可以通过合作或对抗性互动取得进步。
作为一个LLM-based Agent，其设计目标应始终对人类有益，也就是说，人类可以利用人工智能造福人类。具体来说，我们希望Agent能实现以下目标：&lt;/p>
&lt;p>帮助用户从日常任务和重复劳动中解脱出来，从而减轻人类的工作压力，提高任务解决效率。
不再需要用户提供明确的低级指令。相反，Agent可以独立分析、规划和解决问题。
在解放用户双手的同时，Agent也解放了他们的大脑，使其能够从事探索性和创新性工作。&lt;/p>
&lt;p>图7：基于 LLM 的单一Agent在不同场景中的实际应用。在面向任务的部署中，代理协助人类用户解决日常任务。它们需要具备基本的指令理解和任务分解能力。在面向创新的部署中，代理展示了在科学领域进行自主探索的潜力。&lt;/p>
&lt;h3 id="单个agent的一般能力">单个Agent的一般能力&lt;/h3>
&lt;p>目前，LLM-based Agent应用实例的发展十分活跃。AutoGPT 是目前流行的开源项目之一，旨在实现完全自主的系统。除了 GPT-4 等大型语言模型的基本功能外，AutoGPT 框架还集成了各种实用的外部工具和长短期内存管理。用户输入定制的目标后，就可以解放双手，等待 AutoGPT 自动生成想法并执行特定任务，所有这些都不需要用户的额外提示。&lt;/p>
&lt;h4 id="面向任务的部署">面向任务的部署&lt;/h4>
&lt;p>LLM-based Agent 可以理解人类的自然语言指令并执行日常任务，是目前最受用户青睐、最具实用价值的Agent之一。这是因为它们具有提高任务效率、减轻用户工作量和促进更广泛用户访问的潜力。在面向任务的部署中，Agent遵从用户的高级指令，承担目标分解、子目标规划、环境交互探索等任务，直至实现最终目标。为了探索Agent是否能够执行基本任务，部分学者将它们部署到基于文本的游戏场景中。在这类游戏中，Agent完全使用自然语言与世界互动。通过阅读周围环境的文字描述，并利用记忆、规划和试错等技能，它们可以预测下一步行动。然而，由于基础语言模型的局限性，Agent在实际执行过程中往往依赖于强化学习。随着 LLM 的逐步发展，具备更强文本理解和生成能力的 Agent 在通过自然语言执行任务方面展现出巨大潜力。由于过于简单，基于文本的简单场景不足以作为 LLM-based Agent 的测试场所。为了满足这一需求，我们构建了更真实、更复杂的模拟测试环境。根据任务类型，我们将这些模拟环境分为网络场景和生活场景，并介绍Agent在其中扮演的具体角色。&lt;/p>
&lt;p>在网络场景中：&lt;/p>
&lt;p>在网络场景中代表用户执行特定任务被称为网络导航问题。Agent解释用户指令，将其分解为多个基本操作，并与计算机进行交互。这通常包括填写表格、网上购物和发送电子邮件等网络任务。Agent需要具备在复杂的网络场景中理解指令、适应变化（如嘈杂的文本和动态 HTML 网页）以及概括成功操作的能力。这样，Agent就能在未来处理看不见的任务时实现无障碍和自动化，最终将人类从与计算机用户界面的重复交互中解放出来。通过强化学习训练出来的Agent可以有效地模仿人类行为，使用预定义的操作，如打字、搜索、导航到下一页等。它们在网上购物和搜索引擎检索等基本任务中表现出色，这些任务已被广泛探索。然而，不具备 LLM 功能的Agent可能难以适应现实世界互联网中更现实、更复杂的场景。在动态的、内容丰富的网页中，如在线论坛或在线业务管理，Agent的性能往往面临挑战。为了让Agent与更逼真的网页成功互动，一些研究人员开始利用 LLM 强大的 HTML 阅读和理解能力。通过设计提示，他们试图让Agent理解整个 HTML 源代码，并预测更合理的下一步行动。Mind2Web 将多个针对 HTML 进行微调的 LLMs 结合在一起，使它们能够在真实世界的场景中总结冗长的 HTML 代码并提取有价值的信息。此外，WebGum 通过使用包含 HTML 屏幕截图的多模态语料库，增强了具有视觉感知能力的Agent的能力。它同时对 LLM 和视觉编码器进行了微调，加深了Agent对网页的全面理解。&lt;/p>
&lt;p>生活场景中：&lt;/p>
&lt;p>在生活场景中的许多日常家务劳动中，Agent必须理解隐含指令并应用常识性知识。对于完全基于海量文本训练的 LLM-based Agent 来说，人类认为理所当然的任务可能需要多次试错尝试。更现实的场景往往会产生更模糊、更微妙的任务。例如，如果天黑了，房间里有一盏灯，Agent就应该主动打开它。要想成功地在厨房切菜，Agent需要预测刀的可能位置。Agent能否将训练数据中蕴含的世界知识应用到真实的交互场景中？Huang 等人证明，在适当的提示下，足够大的 LLM 可以针对真实交互场景中的任务有效地将高级任务分解为合适的子任务，而无需额外的训练。不过，这种静态推理和规划能力也有其潜在的缺点。Agent生成的行动往往缺乏对周围动态环境的感知：例如，当用户下达 &amp;ldquo;打扫房间 &amp;ldquo;的任务时，Agent可能会将其转化为 &amp;ldquo;呼叫清洁服务 &amp;ldquo;等不可行的子任务。为了让Agent在交互过程中获得全面的场景信息，一些方法直接将空间数据和项目位置关系作为模型的附加输入。这样，Agent就能获得对周围环境的精确描述。Wu 等人介绍了 PET 框架，该框架通过早期纠错方法减少了环境信息中的无关物体和容器。PET 鼓励Agent更有效地探索场景和规划行动，并专注于当前的子任务。&lt;/p>
&lt;h4 id="面向创新的部署">面向创新的部署&lt;/h4>
&lt;p>LLM-based Agent 在执行任务和提高重复性工作的效率方面表现出了强大的能力。然而，在智力要求更高的领域，如前沿科学领域，Agent 的潜力尚未得到充分发挥。这种局限性主要来自两个方面的挑战：&lt;/p>
&lt;p>一方面，科学本身的复杂性构成了重大障碍，许多特定领域的术语和多维结构难以用单一文本表示。因此，它们的完整属性无法完全封装。这大大削弱了 Agent 的认知水平。&lt;/p>
&lt;p>另一方面，科学领域严重缺乏合适的训练数据，使得Agent难以理解整个领域的知识。如果能在Agent内部发现自主探索的能力，无疑会给人类科技带来有益的创新。目前，各个专业领域都在为克服这一挑战而努力。计算机领域的专家充分利用了Agent强大的代码理解和调试能力。在化学和材料领域，研究人员为Agent配备了大量通用或特定任务工具，以更好地理解领域知识。Agent逐渐发展成为全面的科学助手，精通在线研究和文档分析，以填补数据空白。它们还利用机器人应用程序接口（API）进行现实世界的交互，从而完成材料合成和机制发现等任务。&lt;/p>
&lt;p>LLM-based Agent 在科学创新方面的潜力是显而易见的，但我们并不希望它们的探索能力被用于可能威胁或伤害人类的应用中。Boiko 等人研究了Agent在合成非法药物和化学武器过程中隐藏的危险，指出Agent可能会在对抗性提示中被恶意用户误导。这为我们今后的工作敲响了警钟。&lt;/p>
&lt;h4 id="面向生命周期的部署">面向生命周期的部署&lt;/h4>
&lt;p>在一个开放、未知的世界中，建立一个能够不断探索、发展新技能并保持长期生命周期的、具有普遍能力的Agent是一项巨大的挑战。Minecraft 作为一个典型的、被广泛探索的模拟生存环境，已成为开发和测试Agent综合能力的独特乐园。玩家通常从学习基础知识开始，如开采木材和制作工艺台，然后再学习更复杂的任务，如与怪物战斗和制作钻石工具。Minecraft 从根本上反映了真实世界，有利于研究人员调查Agent在真实世界中的生存潜力。Minecraft 中的Agent生存算法一般可分为两类：低级控制和高级规划。早期的努力主要集中在强化学习和模仿学习，使Agent能够制作一些低级物品。随着具有惊人推理和分析能力的 LLM 的出现，Agent开始利用 LLM 作为高级计划器来指导模拟生存任务。一些研究人员利用 LLM 将高级任务指令分解为一系列子目标、基本技能序列或基本键盘/鼠标操作，逐步协助Agent探索开放世界。Voyager从类似于 AutoGPT的概念中汲取灵感，基于“发现尽可能多的不同事物”这一长期目标，成为 Minecraft 中第一个基于 LLM 的体现式终身学习Agent。它引入了一个用于存储和检索复杂动作可执行代码的技能库，以及一个包含环境反馈和纠错的迭代提示机制。这使Agent能够自主探索和适应未知环境，而无需人工干预。能够自主学习和掌握整个真实世界技术的AI Agent可能并不像人们想象的那样遥远。&lt;/p>
&lt;p>图8：基于 LLM 的多个代理的交互场景。在合作互动中，代理以无序或有序的方式进行协作，以实现共同目标。在对抗式交互中，代理以针锋相对的方式展开竞争，以提高各自的性能。&lt;/p>
&lt;h2 id="multi-agent的协调潜力">Multi-Agent的协调潜力&lt;/h2>
&lt;p>动机与背景：&lt;/p>
&lt;p>尽管LLM-based Agent拥有值得称道的文本理解和生成能力，但它们在自然界中是作为孤立的实体运行的。它们缺乏与其他Agent协作和从社会互动中获取知识的能力。这种固有的局限性限制了它们从他人的多轮反馈中学习以提高性能的潜力。此外，在需要multi-agent之间进行协作和信息共享的复杂场景中，它们也无法有效部署。早在 1986 年，马文-明斯基就做出了前瞻性的预测。他在《心灵社会》一书中提出了一种新颖的智能理论，认为智能产生于许多具有特定功能的小型Agent的相互作用。例如，某些Agent可能负责模式识别，而其他Agent可能负责决策或生成解决方案。作为主要研究领域之一的多Agent系统（MAS）关注的重点是一组Agent如何有效地协调和协作解决问题。一些专门的通信语言（如 KQML ）很早就被设计出来，以支持Agent之间的信息传输和知识共享。但是，它们的信息格式相对固定，语义表达能力有限。进入 21 世纪，强化学习算法（如 Q-learning）与深度学习的结合，已成为开发可在复杂环境中运行的 MAS 的重要技术。如今，基于 LLMs 的构建方法开始展现出巨大的潜力。Agent之间的自然语言交流变得更加优雅，也更容易为人类所理解，从而大大提高了交互效率。&lt;/p>
&lt;p>潜在优势：&lt;/p>
&lt;p>具体来说，LLM-based multi-Agent系统可以提供几种优势。根据分工原则，具备专业技能和领域知识的单个Agent可以从事特定的任务。一方面，通过分工，Agent处理特定任务的技能日益精进。另一方面，将复杂任务分解为多个子任务，可以省去在不同流程之间切换的时间。最终，多个Agent之间的高效分工可以完成比没有专业化分工时大得多的工作量，从而大大提高整个系统的效率和产出质量。在前文中，本文全面介绍了LLM-based Agent的多功能能力。因此，在本节中，我们将重点探讨multi-agent环境中Agent之间的交互方式。根据目前的研究，这些交互方式大致可分为以下几类： 取长补短的合作式交互，以及互利共赢的对抗式交互（见图 8）。&lt;/p>
&lt;h3 id="互补性合作交互">互补性合作交互&lt;/h3>
&lt;p>在当前基于 LLM 的多Agent系统中，Agent之间的交流主要使用自然语言，这被认为是最自然、最易为人类理解的交互形式。我们将现有的多Agent合作应用分为两类：无序合作和有序合作。&lt;/p>
&lt;p>无序合作：&lt;/p>
&lt;p>当系统中有三个或三个以上的Agent时，每个Agent都可以自由地公开表达自己的观点和意见。他们可以提供反馈和建议，以修改与当前任务相关的反应。整个讨论过程不受控制，没有特定的顺序，也没有引入标准化的协作工作流程。我们把这种多Agent合作称为无序合作。ChatLLM 网络是这一概念的典范代表。它模拟了神经网络中的前向和后向传播过程，将每个Agent视为一个单独的节点。后一层的Agent需要处理来自前面所有Agent的输入，并向前传播。一个潜在的解决方案是在multi-Agent系统中引入一个专门的协调Agent，负责整合和组织所有Agent的响应，从而更新最终答案。然而，整合大量反馈数据并提取有价值的见解对协调Agent来说是一个巨大的挑战。此外，多数表决也可以作为做出适当决策的有效方法。然而，目前将这一模块整合到多Agent系统中的研究还很有限。有学者训练了九个独立的最高司法Agent，以更好地预测美国最高法院的司法裁决，并通过多数表决程序做出决定。&lt;/p>
&lt;p>有序合作：&lt;/p>
&lt;p>当系统中的Agent遵守特定规则时，例如按顺序逐一发表意见，下游Agent只需关注上游的产出。这样，任务完成效率就会大大提高，整个讨论过程也会变得井然有序。CAMEL 是双Agent合作系统的成功实施案例。在角色扮演交流框架内，Agent分别扮演人工智能用户（下达指令）和人工智能助手（通过提供具体解决方案来满足请求）的角色。通过多轮对话，这些Agent自主合作完成用户指令。一些研究人员将双Agent合作的理念融入到单个Agent的操作中，交替使用快速和深思熟虑的思维过程，以在各自的专业领域发挥优势。&lt;/p>
&lt;p>Talebirad 等人是最早系统地介绍Universal LLM-based Multi-Agent Collaboration Framework的人之一。这一范例旨在利用每个独立Agent的优势，促进它们之间的合作关系。在此基础上，许多multi-Agent合作应用已成功建立起来。此外，AgentVerse 为群体Agent合作构建了一个多功能、多任务测试框架。它可以根据任务的复杂程度组建一个动态适应的Agent团队。为了提高合作效率，研究人员希望Agent能从人类成功的合作案例中学习。MetaGPT 从软件开发中的经典瀑布模型中汲取灵感，将Agent的输入/输出标准化为工程文档。通过将先进的人类流程管理经验编码到Agent提示中，多个Agent之间的合作变得更有条理。然而，在 MetaGPT 的实践探索中，我们发现了Multi-Agent合作的潜在威胁。如果不制定相应的规则，多个Agent之间的频繁互动会无限放大轻微的幻觉。例如，在软件开发过程中，可能会出现功能不全、依赖关系缺失、人眼无法察觉的错误等问题。引入交叉验证或及时的外部反馈等技术，可对Agent输出的质量产生积极影响。&lt;/p>
&lt;p>4.2.2 对抗性互动促进进步&lt;/p>
&lt;p>传统上，合作方法在Multi-Agent系统中得到了广泛探索。不过，研究人员越来越认识到，将博弈论的概念引入系统可以带来更稳健、更高效的行为。在竞争环境中，Agent可以通过动态互动迅速调整策略，努力选择最有利或最合理的行动来应对其他Agent引起的变化。在基于非 LLM 的竞争领域，已经有成功的应用。例如，AlphaGo Zero 是一个围棋Agent，它通过自我对弈实现了重大突破。同样，在基于 LLM 的多Agent系统中，通过竞争、争论和辩论，可以自然而然地促进Agent之间的变革。通过放弃僵化的信念和进行深思熟虑的反省，对抗性互动可以提高回应的质量。研究人员首先深入研究了LLM-based Agent的基本辩论能力。研究结果表明，当多个Agent在 “针锋相对”的状态下表达自己的论点时，一个Agent可以从其他Agent那里获得大量外部反馈，从而纠正自己扭曲的想法。因此，多Agent对抗系统在需要高质量响应和准确决策的场景中具有广泛的适用性。在推理任务中，Du 等人引入了辩论的概念，赋予Agent来自同伴的回应。当这些回应与Agent自己的判断出现分歧时，就会发生 “心理”争论，从而完善解决方案。ChatEval 建立了一个基于角色扮演的多Agent裁判团队。通过自发的辩论，Agent对 LLM 生成的文本质量进行评估，达到与人类评估员相当的优秀水平。多Agent对抗系统的性能已显示出相当大的前景。然而，该系统基本上依赖于 LLM 的力量，并面临着一些基本挑战：&lt;/p>
&lt;p>在长时间的辩论中，LLM 有限的语境无法处理整个输入。
在多Agent环境中，计算开销大大增加。
多Agent协商可能会收敛到不正确的共识，而所有Agent都坚信其准确性。多Agent系统的发展还远未成熟，也不可行。在适当的时候引入人类向导来弥补Agent的不足，是促进Agent进一步发展的良好选择。&lt;/p>
&lt;p>图9：人类与Agent互动的两种范式。在指导者-执行者范式（左）中，人类提供指导或反馈，而代理则充当执行者。在平等合作范式（右图）中，代理像人类一样，能够与人类进行移情对话，并参与合作任务。&lt;/p>
&lt;h2 id="人类与agent之间的互动参与">人类与Agent之间的互动参与&lt;/h2>
&lt;p>随着Agent能力的增强，人类的参与变得越来越重要，以便有效地指导和监督Agent的行动，确保它们符合人类的要求和目标。人类的参与可以作为弥补数据不足的重要手段，从而促进更顺利、更安全的协作过程。此外，从人类学角度考虑，人类的语言学习主要是通过交流和互动进行的，而不仅仅是消费书面内容。因此，Agent不应该完全依赖于用预先标注的数据集训练出来的模型；相反，它们应该通过在线互动和参与来发展。人类与Agent之间的互动可分为两种模式（见图 9）： (1) 不平等互动（即指导者-执行者范式）：人类是指令的发布者，而Agent则是执行者，基本上是作为人类的助手参与协作。(2) 平等互动（即平等伙伴关系范式）：Agent达到人类的水平，与人类平等地参与互动。&lt;/p>
&lt;h3 id="指导者-执行者范式">指导者-执行者范式&lt;/h3>
&lt;p>最简单的方法是人类全程指导：人类直接提供明确而具体的指令，而Agent的作用是理解人类的自然语言指令，并将其转化为相应的行动。考虑到语言的交互性，本文假设人类与Agent之间的对话也是交互式的。借助 LLM，Agent能够以对话的方式与人类互动：Agent对人类的每条指令做出回应，通过交替迭代完善其行动，最终满足人类的要求。虽然这种方法确实实现了人机交互的目标，但却对人类提出了很高的要求。它需要人类付出大量的努力，在某些任务中，甚至可能需要高水平的专业知识。为了缓解这一问题，可以授权Agent自主完成任务，而人类只需在特定情况下提供反馈。在此，我们将反馈大致分为两种类型：定量反馈和定性反馈。&lt;/p>
&lt;p>定量反馈：&lt;/p>
&lt;p>定量反馈的形式主要包括二进制分数和评级等绝对评价以及相对分数。二元反馈指的是人类提供的正面和负面评价，Agent利用这些评价来加强自我优化。这种类型的用户反馈只包括两个类别，通常很容易收集，但有时可能会过度简化用户意图，忽略潜在的中间场景。为了展示这些中间情况，研究人员试图从二元反馈扩展到评级反馈，这涉及到更精细的分类。然而，Kreutzer 等人的研究结果表明，对于这种多级人工评级，用户和专家的注释之间可能存在显著差异，这表明这种标记方法可能效率不高或可靠性较低。此外，Agent还能从多选等比较分数中学习人类的偏好。&lt;/p>
&lt;p>定性反馈：&lt;/p>
&lt;p>文本反馈通常以自然语言提供，尤其是针对可能需要改进的回复。这种反馈的形式非常灵活。人类会就如何修改Agent生成的输出结果提出建议，然后Agent会采纳这些建议来完善其后续输出结果。对于不具备多模态感知能力的Agent，人类也可以充当批评者，例如提供视觉批评。此外，Agent还可以利用记忆模块来存储反馈信息，以便将来再次使用。一些学者设计人类对Agent生成的初始输出给出反馈，促使Agent提出各种改进建议。然后，Agent根据人类的反馈意见，辨别并采用最合适的建议。虽然与定量反馈相比，这种方法能更好地传达人类的意图，但对于Agent来说，理解起来可能更具挑战性。Xu 等人比较了各种类型的反馈，发现将多种类型的反馈结合起来能产生更好的结果。根据多轮交互的反馈重新训练模型（即持续学习）可以进一步提高效果。当然，人类与Agent互动的协作性质也允许人类直接改进Agent生成的内容。这可能涉及修改中间环节或调整对话内容。在一些研究中，Agent可以自主判断对话是否顺利进行，并在出现错误时寻求反馈。人类也可以选择随时参与反馈，引导Agent朝着正确的方向学习。&lt;/p>
&lt;p>目前，除了写作和语义解析等任务外，使用Agent作为人类助手的模式在教育领域也拥有巨大潜力。例如，Kalvakurth 等人提出的机器人 Dona 支持多模态交互，可协助学生注册。Gvirsman 等人的研究侧重于幼儿教育，实现了幼儿、家长和Agent之间的多方面互动。Agent还能帮助人类理解和利用数学。在医学领域，一些医疗Agent已被提出，在辅助诊断、咨询等方面显示出巨大的潜力。特别是在心理健康领域，研究表明，与面对面治疗相比，Agent可以降低成本、提高时间效率和匿名性等优势，从而提高可及性。利用这些优势，Agent得到了广泛应用。Ali 等人设计了 LISSA，用于与自闭症谱系的青少年进行在线交流，实时分析用户的语言和面部表情，让他们参与多主题对话，并就非语言线索提供即时反馈。Hsu 等人建立了语境化语言生成方法，为寻求各种支持的用户提供量身定制的帮助。&lt;/p>
&lt;p>用户提供量身定制的帮助，帮助他们解决从人际关系压力到焦虑等不同主题的问题。此外，在包括商业在内的其他行业，一个好的Agent有能力提供自动化服务或协助人类完成任务，从而有效降低劳动力成本。在追求人工智能的过程中，人们正努力增强通用Agent的多方面能力，创造出能在现实生活场景中充当万能助手的Agent。&lt;/p>
&lt;h3 id="平等伙伴关系范式">平等伙伴关系范式&lt;/h3>
&lt;p>富有同情心的交流者：&lt;/p>
&lt;p>随着人工智能的快速发展，对话式Agent以个性化定制角色和虚拟聊天机器人等各种形式在研究领域引起了广泛关注。Agent本身并不具备情感，但我们能否让他们表现出情感，从而弥合Agent与人类之间的鸿沟呢？因此，大量的研究工作开始深入探讨Agent的移情能力。这种努力旨在为这些Agent注入人情味，使它们能够从人类的表达中察觉情绪和情感，最终制作出能引起情感共鸣的对话。除了生成情感丰富的语言，Agent还能动态调整自己的情感状态，并通过面部表情和声音表现出来。这些研究将Agent视为具有同理心的交流者，不仅提高了用户满意度，还在医疗保健和商业营销等领域取得了重大进展。与简单的基于规则的对话Agent不同，具有移情能力的Agent可以根据用户的情感需求调整其互动。
人类层面的参与者：&lt;/p>
&lt;p>此外，我们还希望Agent能够参与人类的正常生活，从人类层面的角度与人类合作完成任务。在游戏领域，Agent已经达到了很高的水平。早在 20 世纪 90 年代，IBM 就推出了人工智能“深蓝”，它击败了当时的国际象棋世界冠军。然而，在象棋、围棋和扑克等纯竞技环境中并没有得到强调。在许多游戏任务中，玩家需要相互协作，通过有效协商制定统一的合作策略。在这些场景中，Agent需要首先了解他人的信念、目标和意图，针对自己的目标制定联合行动计划，并提供相关建议，以促进其他Agent或人类接受合作行动。与纯粹的Agent合作相比，我们希望人类的参与主要出于两个原因：第一，确保可解释性，因为纯粹的Agent之间的互动可能会产生难以理解的语言；第二，确保可控性，因为追求完全“自由意志”的Agent可能会导致不可预见的负面后果，带来潜在的破坏。&lt;/p>
&lt;p>除了游戏场景，Agent还能在其他涉及人际互动的场景中展现人类水平的能力，展示战略制定、谈判等技能。Agent可以与一个或多个人类合作，确定合作伙伴之间的共享知识，识别哪些信息与决策相关，提出问题并进行推理，以完成分配、规划和调度等任务。此外，Agent还具有说服能力，能在各种交互场景中动态地影响人类的观点。&lt;/p>
&lt;p>人机交互领域的目标是学习和理解人类，根据人类需求开发技术和工具，最终实现人类与Agent之间舒适、高效和安全的交互。目前，该领域在可用性方面已取得重大突破。未来，人类与Agent的互动将继续以提升用户体验为重点，使Agent能够更好地协助人类完成各个领域更复杂的任务。我们的最终目标不是让Agent变得更加强大，而是让人类更好地掌握Agent。考虑到日常生活中的实际应用，人类与Agent之间孤立的互动是不现实的。机器人将成为人类的同事、助手甚至伙伴。因此，未来的Agent将融入社会网络，体现出一定的社会价值。&lt;/p>
&lt;h2 id="agent-society-from-individuality-to-sociality">Agent Society: From Individuality to Sociality&lt;/h2>
&lt;p>图10：Agent Society的拓扑框架图&lt;/p>
&lt;p>图11：模拟代理社会概述。整个框架分为两个部分：代理和环境。(1) 左：在个体层面。(2) 中： 一个代理可以与其他代理组成群体。(3) 右： 环境包含所有可用资源。对于单个代理来说，其他代理也是环境的一部分。(4) 代理能够通过感知和行动与环境互动。&lt;/p>
&lt;p>长期以来，社会学家经常进行社会实验，在受控环境中观察特定的社会现象。著名的例子包括霍桑实验和斯坦福监狱实验。随后，研究人员开始在社会模拟中使用动物，老鼠乌托邦实验就是一个例子。然而，这些实验无一例外地使用活体作为参与者，难以进行各种干预，缺乏灵活性，时间效率低下。因此，研究人员和实践者一直在设想一个交互式人工社会，在这个社会中，人类的行为可以通过可信的Agent来实现。从《模拟人生》等沙盒游戏到 Metaverse 概念，我们可以看到“模拟社会”在人们心目中的定义：环境和在其中互动的个体。每个个体的背后可以是一个程序、一个真实的人类，也可以是一个LLM-based Agent。那么，个体之间的互动也是社会性产生的原因之一。&lt;/p>
&lt;h3 id="llm-based-agent的行为和个性">LLM-based Agent的行为和个性&lt;/h3>
&lt;p>正如社会学家所指出的，可以从外部和内部两个维度对个人进行分:。外部维度涉及可观察到的行为，而内部维度则与性格、价值观和情感有关。如图 11 所示，这一框架为LLM-based Agent的新兴行为和个性提供了一个视角。从外部来看，我们可以观察到Agent的社会学行为，包括Agent如何单独行动以及如何与环境互动。从内部来看，Agent可能会表现出错综复杂的个性，如认知、情感和性格，这些都会影响Agent的行为反应。&lt;/p>
&lt;h4 id="社会行为">社会行为&lt;/h4>
&lt;p>正如 Troitzsch 等人所说，Agent社会是一个由个体和群体社会活动组成的复杂系统。最近，LLM-based Agent在合作与竞争并存的环境中表现出了自发的社会行为。新出现的行为相互交织，形成了社会互动。&lt;/p>
&lt;p>基础个体行为：&lt;/p>
&lt;p>个体行为产生于内部认知过程和外部环境因素之间的相互作用。这些行为构成了个体在社会中运作和发展的基础。它们可分为三个核心维度：&lt;/p>
&lt;p>输入行为指的是从周围环境中吸收信息。这包括感知感官刺激并将其存储为记忆。这些行为为个体理解外部世界奠定了基础。
内化行为涉及个体内部的认知处理。这类行为包括计划、推理、反思和知识沉淀等活动。这些内省过程对于成熟和自我完善至关重要。
输出行为是外显的行动和表达。这些行为可以是物体操作，也可以是结构构建。通过执行这些动作，Agent可以改变周围环境的状态。此外，Agent还可以表达自己的观点和广播信息，与他人互动。通过这种方式，Agent可以与他人交流思想和信念，从而影响环境中的信息流。
动态群体行为：&lt;/p>
&lt;p>群体本质上是由两个或两个以上的个体组成的，他们在一个确定的社会环境中参与共同的活动。群体的属性从来都不是一成不变的，相反，它们会随着成员的互动和环境的影响而不断演变。这种灵活性产生了许多群体行为，每种行为都对更大的社会群体产生独特的影响。群体行为的类别包括：&lt;/p>
&lt;p>积极的群体行为是促进团结、协作和集体福祉的行为。一个最好的例子就是团队合作，它可以通过头脑风暴讨论 、有效对话和项目管理来实现。Agent共享见解、资源和专业知识。这鼓励了和谐的团队合作，使Agent能够利用自己的独特技能完成共同目标。利他主义贡献也值得一提。一些LLM-based Agent充当志愿者，自愿提供支持，帮助其他群体成员，促进合作与互助。
中立的群体行为。在人类社会中，强烈的个人价值观千差万别，并趋向于个人主义和竞争性。相比之下，以“乐于助人、诚实和无害”为设计重点的 LLM 常常表现出中立的倾向。这种与中立价值观的一致会导致服从行为，包括模仿、旁观和不愿反对多数人。
消极的群体行为会破坏Agent群体的有效性和一致性。Agent之间的激烈辩论或争执所产生的冲突和分歧可能会导致内部关系紧张。此外，最近的研究表明，Agent可能会表现出对抗行为，甚至采取破坏行为，例如为了追求自己的效率或目标而破坏其他Agent或环境。&lt;/p>
&lt;h4 id="个性">个性&lt;/h4>
&lt;p>LLM 的最新进展让人们看到了类似人类的智能。正如人的个性是在社会化过程中形成的一样，Agent也表现出一种通过与群体和环境互动而形成的个性。广为接受的人格定义是指塑造行为的认知、情感和性格特征。在接下来的段落中，我们将深入探讨人格的各个层面。&lt;/p>
&lt;p>认知能力：&lt;/p>
&lt;p>认知能力一般是指获取知识和理解能力的心理过程，包括思考、判断和解决问题。最近的研究开始利用认知心理学方法，从不同角度研究LLM-based Agent的新兴社会学个性。一系列来自判断和决策心理学的经典实验已被用于测试Agent系统。具体地说，人们使用认知反思测试（CRT）对 LLM 进行了检验，以强调其超越直觉的深思熟虑能力。这些研究表明，LLM-based Agent所表现出的智能水平在某些方面与人类的认知水平相当。&lt;/p>
&lt;p>情感智能：&lt;/p>
&lt;p>情感有别于认知能力，涉及主观感受和情绪状态，如喜悦、悲伤、恐惧和愤怒。随着 LLM 的日益强大，LLM-based Agent现在不仅能完成复杂的推理和认知任务，还能对情绪进行细致入微的理解。最近的研究探索了 LLMs 的情绪智能（EI），包括情绪识别、解释和理解。Wang 等人发现，在根据情商基准进行评估时，LLM符合人类的情感和价值观。此外，研究表明，LLM 可以准确识别用户情绪，甚至表现出同理心。更先进的Agent还能进行情绪调节，主动调整情绪反应，以提供情感共鸣和心理健康支持。这有助于移情人工智能（EAI）的发展。这些进展凸显了 LLMs 在展现情商方面日益增长的潜力，而情商是实现 AGI 的一个重要方面。贝茨等人探索了情感建模在创建更可信的Agent中的作用。通过开发社会情感技能并将其整合到Agent架构中，LLM-based Agent或许能进行更自然的互动。&lt;/p>
&lt;p>角色刻画：&lt;/p>
&lt;p>认知涉及心智能力，情感则与主观体验有关，而狭义的性格概念通常与独特的性格模式有关。为了了解和分析LLM的性格，研究人员利用了一些成熟的框架，如五大性格特征测量法和迈尔斯-布里格斯类型指标（MBTI）。这些框架为了解LLM-based Agent所表现出的新兴性格特征提供了宝贵的见解。此外，对潜在有害的阴暗性格特征的研究强调了这些Agent的性格刻画的复杂性和多面性。最近的研究还探索了LLM-based Agent中可定制的角色形象。用户可以通过精心设计的技术优化 LLM，使其符合所需的特征，并塑造出多样化、可亲的Agent。提示工程是一种有效的方法，它包括概括所需角色特征、兴趣或其他属性的简明摘要。这些提示可作为LLM-based Agent的线索，引导他们的反应和行为与概述的角色形象保持一致。此外，丰富的个性数据集也可用于训练和微调LLM-based Agent。通过接触这些数据集，LLM-based Agent会逐渐内化并表现出独特的个性特征。&lt;/p>
&lt;h2 id="agent-society的环境">Agent Society的环境&lt;/h2>
&lt;h3 id="基于文本的环境">基于文本的环境&lt;/h3>
&lt;p>在基于文本的环境中，实体和资源可以以两种主要的文本形式呈现，包括自然文本和结构化文本。自然文本使用描述性语言来传递信息，如人物对话或场景设置。例如，请看一个用文字描述的简单场景： &amp;ldquo;你正站在一栋白色房子西边的空地上，房子的前门用木板封着。这里有一个小邮箱&amp;rdquo;。在这里，对象的属性和位置完全是通过纯文本传达的。结构化文本遵循标准化格式，如技术文档和超文本。技术文档使用模板提供有关工具使用的操作细节和领域知识，超文本将网页或图表等来源的复杂信息浓缩成结构化格式。结构化文本将复杂的细节转化为Agent可访问的参考资料。基于文本的环境提供了一个灵活的框架，可为各种目标创建不同的文本世界。文本媒介能使环境轻松适应交互式对话和基于文本的游戏等任务。&lt;/p>
&lt;p>在 CAMEL 等交互式交流过程中，文本是描述任务、介绍角色和促进问题解决的主要媒介。在基于文本的游戏中，环境中的所有元素，如地点、物体、角色和动作，都完全通过文本描述来描绘。Agent利用文本命令来执行移动或使用工具等操作。此外，Agent还可以通过文本传达情绪和情感，进一步丰富其自然交流能力。&lt;/p>
&lt;h3 id="虚拟沙盘环境">虚拟沙盘环境&lt;/h3>
&lt;p>虚拟沙盘环境为Agent社会提供了一个可视化和可扩展的平台，在模拟和现实之间架起了一座桥梁。沙箱环境的主要特点如下：&lt;/p>
&lt;p>可视化。与基于文本的环境不同，虚拟沙盘显示模拟环境的全景。根据所模拟社会的复杂程度，这种可视化表现形式可以是简单的二维图形界面，也可以是完全身临其境的三维建模。多种元素共同将抽象的模拟转化为可见的景观。例如，在“生成式Agent”（Generative Agents）的俯视视角中，一张详细的地图提供了环境的全貌。Agent头像代表了每个Agent的位置，可以实时跟踪移动和交互。此外，表情符号还能以直观的方式象征行动和状态。
可扩展性。该环境具有出色的可扩展性，便于构建和部署各种场景。在基本层面上，Agent可以操纵环境中的物理元素，包括架构的整体设计和布局。例如，AgentSims 和 Generative Agents 等平台可以在基于网格的世界中构建具有建筑物、设备和居民的人工城镇。另一个例子是 Minecraft，它提供了一个具有无限地形的块状三维世界，可用于开放式建筑。除了物理元素，还可以定义Agent关系、交互规则和社会规范。沙盒的一个典型设计，采用了潜在的沙盒规则作为激励机制来引导新出现的行为，使其更符合人类的偏好。可扩展性支持对不同的Agent社会进行迭代原型设计。&lt;/p>
&lt;h3 id="物理环境">物理环境&lt;/h3>
&lt;p>如前所述，基于文本的环境对动态环境建模的表现力有限。虽然虚拟沙盘环境可以提供模块化模拟，但缺乏真实的体验。相比之下，物理环境指的是有形的真实世界环境，由实际的物理对象和空间组成。例如，ithor在家庭物理环境中，有形的表面和空间可以被现实世界中的物体（如盘子）占据。这种物理现实要复杂得多，给LLM-based Agent带来了更多挑战：&lt;/p>
&lt;p>感知和处理。物理环境引入了现实世界物体的丰富感官输入。它包含视觉、听觉和空间感。这种多样性在增强交互性和感官沉浸感的同时，也带来了同步感知的复杂性。Agent必须处理感官输入，才能与周围环境有效互动。
运动控制。与虚拟环境不同，物理空间通过体现对行动施加了现实的限制。LLM-based Agent生成的动作序列应能适应环境。这意味着物理环境需要可执行且有依据的运动控制。&lt;/p>
&lt;h2 id="使用llm-based-agent进行社会模拟">使用LLM-based Agent进行社会模拟&lt;/h2>
&lt;h3 id="agent-society-的关键属性和机制">Agent Society 的关键属性和机制&lt;/h3>
&lt;p>社会模拟可分为宏观模拟和微观模拟。在宏观层面的仿真中，也称为基于系统的仿真，研究人员模拟仿真社会系统的整体状态。而在微观层面的仿真中，也称为基于Agent的仿真或多Agent系统（MAS），研究人员通过对个人建模来间接模拟社会。随着LLM-based Agent的发展，微观仿真近来越来越受到重视。本文将“Agent Society”定义为一个开放、持久、情景化和有组织的框架，在这个框架中，LLM-based Agent在一个确定的环境中相互影响，这些属性中的每一个都在塑造模拟社会的和谐外观方面发挥着关键作用。&lt;/p>
&lt;p>开放性。模拟社会的决定性特征之一在于其开放性，包括其组成人员和环境组成部分的开放性。Agent是这类社会的主要参与者，可以灵活地进入或离开环境，而不会破坏其运行的完整性。此外，这一特点还延伸到环境本身，它可以通过添加或删除虚拟或物理世界中的实体以及工具 API 等可调整资源来扩展。此外，人类还可以通过扮演Agent角色或充当指导这些Agent的思想来参与社会。这种固有的开放性为模拟增加了另一层复杂性，模糊了模拟与现实之间的界限。
持久性。我们期望模拟社会具有持久性和可持续性。虽然社会中的单个Agent在每个时间步长内的行动都是自主的，但整体组织结构会随着时间的推移而持续存在，在一定程度上脱离了单个Agent的短暂行为。这种持续性创造了一种环境，使行为主体的决策和行为得以累积，从而形成一个随着时间推移而发展的连贯的社会轨迹。该系统独立运行，在促进社会稳定的同时，也兼顾了参与者的动态性质。
情境性。社会的情境性强调社会在一个独特的环境中存在和运行。这种环境是事先人为或自动构建的，Agent在其中有效地执行其行为和进行互动。这一特性的一个值得注意的方面是，Agent拥有对其空间环境的意识，了解自己在环境中的位置和视野范围内的物体。这种意识有助于提高它们主动与环境互动的能力。
有组织。模拟社会在一个精心组织的框架内运行，与现实世界中的系统结构如出一辙。就像物理世界遵循物理学原理一样，模拟社会也在预定义的规则和限制范围内运行。在模拟世界中，Agent在有限的行动空间内与环境互动，而环境中的物体则在有限的状态空间内转换。所有这些规则决定了Agent如何运作，促进了模拟中的通信连接和信息传输路径等方面。这种组织框架确保了操作的连贯性和可理解性，最终使模拟不断发展，但又经久不衰，反映了现实世界系统的错综复杂。&lt;/p>
&lt;h3 id="来自agent社会的启示">来自Agent社会的启示&lt;/h3>
&lt;p>有组织的生产性合作&lt;/p>
&lt;p>社会模拟为创新合作模式提供了宝贵的见解，而创新合作模式有可能增强现实世界的管理策略。研究表明，在这些模拟社会中，不同专家的整合引入了个人智能的多面性。在处理复杂任务（如软件开发或咨询）时，具有不同背景、能力和经验的Agent可促进创造性地解决问题。此外，多样性还能发挥制衡系统的作用，通过互动有效防止和纠正错误，最终提高对各种任务的适应性。通过Agent之间多次反复的互动和辩论，幻觉或思维退化（DoT）等个人错误会被群体纠正。在这样一个庞大而复杂的协作小组中，高效的交流也起着举足轻重的作用。例如，MetaGPT 参照标准化操作程序（SOP）人为制定了交流方式，验证了经验方法的有效性。Park 等人通过在一个模拟城镇中的自发交流，观察到Agent共同组织情人节聚会的情况。&lt;/p>
&lt;p>社会网络中的传播&lt;/p>
&lt;p>由于模拟社会系统可以模拟现实世界中可能发生的情况，因此可作为预测社会进程的参考。与严重依赖时间序列数据和整体建模的传统实证方法不同，基于Agent的模拟为研究人员提供了更多可解释的内生视角，具有独特的优势。在此，我们将重点讨论其在社会网络传播建模中的应用。首先要探讨的关键问题是模拟社会中人际关系的发展。例如，最初并不是朋友的Agent有可能通过中间人建立联系。一旦关系网络建立起来，我们的注意力就会转移到这个社会网络中的信息传播，以及与之相关的基本态度和情感。S
提出了一个用户人口推理模块，用于捕捉了解特定信息的人数和人群中的集体情绪。同样的方法还可扩展到文化传播建模和传染病传播建模。通过采用LLM-based Agent来模拟个人行为、实施各种干预策略以及监控人群随时间的变化，这些模拟使研究人员能够更深入地了解各种社会传播现象的复杂过程。&lt;/p>
&lt;p>伦理决策和博弈论&lt;/p>
&lt;p>模拟社会为研究复杂的决策过程提供了一个动态平台，其中包括受伦理道德原则影响的决策。以狼人游戏和神秘谋杀游戏为例，研究人员探索了LLM-based Agent在面对欺骗、信任和信息不完整等挑战时的能力。这些复杂的决策场景也与博弈论有交集，在博弈论中，我们经常会遇到与个人和集体利益相关的道德困境，如纳什均衡。通过对不同情景的建模，研究人员可以获得关于Agent如何在行动中优先考虑诚实、合作和公平等价值观的宝贵见解。此外，Agent模拟不仅能让人们了解现有的道德价值观，还能作为了解这些价值观如何随时间演变和发展的基础，从而促进哲学的发展。最终，这些见解有助于完善LLM-based Agent，确保其符合人类价值观和道德标准。&lt;/p>
&lt;p>政策制定与改进&lt;/p>
&lt;p>LLM-based Agent的出现，深刻地改变了我们研究和理解错综复杂的社会系统的方法。然而，尽管前面提到了这些有趣的方面，但仍有许多领域尚未开发，这凸显了研究各种现象的潜力。模拟社会中最有前景的研究途径之一是探索各种经济和政治状态及其对社会动态的影响。研究人员可以通过配置具有不同经济偏好或政治意识形态的Agent来模拟各种经济和政治系统。这种深入分析可以为决策者提供宝贵的见解，帮助他们促进繁荣和社会福祉。随着人们对环境可持续性的关注与日俱增，我们还可以模拟涉及资源开采、污染、保护工作和政策干预的情景 。这些发现有助于做出明智的决策，预见潜在的影响，并制定旨在最大限度地扩大积极成果、同时最大限度地减少意外不利影响的政策。&lt;/p>
&lt;h3 id="agent社会中的伦理和社会风险">Agent社会中的伦理和社会风险&lt;/h3>
&lt;p>意外的社会危害&lt;/p>
&lt;p>模拟社会有可能产生意想不到的社会现象，从而引起公众的强烈不满和社会危害。这些现象既包括歧视、孤立和欺凌等个人层面的问题，也包括压迫性奴役和对立等更广泛的问题。恶毒的人可能会操纵这些模拟进行不道德的社会实验，其后果将超越虚拟世界而影响现实。创建这些模拟社会无异于打开潘多拉魔盒，因此有必要在开发和使用过程中制定严格的道德准则并进行监督。否则，这些社会中即使是微小的设计或编程错误，也可能导致不利后果，从心理不适到身体伤害不等。&lt;/p>
&lt;p>陈规定型观念和偏见&lt;/p>
&lt;p>刻板印象和偏见是语言建模中一个长期存在的挑战，其中很大一部分原因在于训练数据。从互联网上获取的大量文本反映了，有时甚至放大了现实世界中的社会偏见，如性别、宗教和性。虽然 LLM 已与人类价值观保持一致，以减少有偏见的输出，但由于训练数据的长尾效应，模型仍难以很好地描绘少数群体。因此，这可能导致有关LLM-based Agent的社会科学研究过于片面，因为边缘化人群的模拟行为通常符合普遍的假设。研究人员已经开始通过多样化训练数据和调整 LLM 来解决这一问题，但我们还有很长的路要走。&lt;/p>
&lt;p>隐私与安全&lt;/p>
&lt;p>鉴于人类也可以成为Agent社会的成员，用户与LLM-based Agent之间的私人信息交换会带来严重的隐私和安全问题。用户在交互过程中可能会无意中泄露敏感的个人信息，而这些信息将长期保留在Agent的内存中。这种情况可能会导致未经授权的监视、数据泄露和个人信息滥用，尤其是当涉及到怀有恶意的个人时。为有效应对这些风险，必须实施严格的数据保护措施，如差异化隐私协议、定期数据清除和用户同意机制。&lt;/p>
&lt;p>过度依赖和成瘾性&lt;/p>
&lt;p>模拟社会的另一个问题是用户可能会对Agent产生过度的情感依赖。尽管意识到这些Agent是计算实体，但用户可能会将其拟人化或附加人类情感。一个值得注意的例子是 Sydney，它是微软公司开发的由 LLM 驱动的聊天机器人，是必应搜索引擎的一部分。一些用户表示与 Sydney 之间存在意想不到的情感联系，而另一些用户则对微软削减 Sydney 的个性表示失望。这甚至导致了名为 FreeSydney 的请愿活动。 因此，为了降低上瘾的风险，必须强调不应将Agent视为真正人际关系的替代品。此外，在用户与模拟Agent的互动中，为他们提供健康界限方面的指导和教育也至关重要。&lt;/p>
&lt;h2 id="discussion">Discussion&lt;/h2>
&lt;h3 id="llm-研究-与-agent-研究之间的互惠互利">LLM 研究 与 Agent 研究之间的互惠互利&lt;/h3>
&lt;p>LLM研究对Agent研究的贡献&lt;/p>
&lt;p>AI Agent需要感知环境、做出决策并执行适当的行动。在这些关键步骤中，最重要的是理解输入给Agent的内容、推理、规划、做出准确决策，并将其转化为可执行的原子动作序列，以实现最终目标。目前，许多研究利用LLM作为AI Agent的认知核心，这些模型的发展为完成这一步骤提供了质量保证。&lt;/p>
&lt;p>LLM的优势：大型语言模型在语言和意图理解、推理、记忆甚至移情等方面具有强大的能力，可以在决策和规划方面发挥卓越的作用。再加上预先训练的知识，它们可以创建连贯的行动序列，并有效地执行。此外，通过反思机制，这些基于语言的模型可以根据当前环境提供的反馈不断调整决策和优化执行序列。
LLM的应用：LLM为Agent研究提供了一个非常强大的基础模型，在与Agent相关的研究中，LLM开辟了许多新的机会。例如，我们可以探索如何将LLM的高效决策能力整合到传统的Agent决策框架中，使Agent更容易应用于对专业知识要求较高且以前由人类专家主导的领域。此外，Agent研究不再局限于简单的模拟环境，现在可以扩展到更复杂的真实世界环境中。
Agent研究对LLM研究的贡献&lt;/p>
&lt;p>将LLM提升为Agent标志着向人工通用智能（AGI）迈出了更坚实的一步。从Agent的角度来看待LLM，对LLM研究提出了更高的要求，同时也扩大了LLM的应用范围，为实际应用提供了大量机会。&lt;/p>
&lt;p>LLM的研究方向：对LLM的研究不再局限于涉及文本输入和文本输出的传统任务，如文本分类、问题解答和文本摘要。取而代之的是，研究重点已转向处理复杂任务，这些任务包含更丰富的输入模式和更广阔的行动空间。
LLM的挑战：挑战在于如何让大型语言模型高效地处理输入、从环境中收集信息并解释由其行动产生的反馈，同时保持其核心能力。此外，更大的挑战在于如何让LLMs理解环境中不同元素之间的隐含关系，并获取世界知识。
LLM的行动能力：大量研究旨在扩展LLM的行动能力，让它们掌握更多影响世界的技能，例如在模拟或物理环境中使用工具或与机器人API接口。
Multi-Agent系统领域：我们希望LLM-based Agent能在社会合作中扮演不同的角色，参与涉及协作、竞争和协调的社会互动。
6.2 对LLM-based Agent的评估
虽然LLM-based Agent在独立运行、集体合作和人机交互等领域表现出色，但对其进行量化和客观评估仍是一项挑战。图灵提出了一种非常有意义且前景广阔的AI Agent评估方法&amp;ndash;著名的图灵测试，用于评估人工智能系统是否能表现出类似人类的智能。然而，这一测试过于模糊、笼统和主观。&lt;/p>
&lt;p>实用性：&lt;/p>
&lt;p>目前，由 LLM-based Agent主要充当人类助手，接受人类委托的任务，独立完成任务或协助人类完成任务。因此，任务执行过程中的有效性和实用性是现阶段至关重要的评估标准。具体来说，任务完成的成功率是评估实用性的主要指标。这一指标主要包括Agent是否实现了规定的目标或达到了预期的分数。例如，AgentBench 汇总了来自不同真实世界场景的挑战，并引入了一个系统基准来评估 LLM 的任务完成能力。我们还可以将任务结果归因于Agent的各种基础能力，这些能力是完成任务的基石。这些基础能力包括环境理解能力、推理能力、规划能力、决策能力、工具使用能力和体现行动能力，研究人员可以对这些具体能力进行更详细的评估。此外，由于LLM-based Agent规模相对较大，研究人员还应考虑其效率因素，这是决定用户满意度的关键因素。Agent不仅要有足够的实力，还要能在适当的时间范围内，以适当的资源消耗完成预定的任务。&lt;/p>
&lt;p>社会性：&lt;/p>
&lt;p>除了LLM-based Agent在完成任务和满足人类需求方面的实用性外，它们的社交性也至关重要。它影响用户的交流体验，并对交流效率产生重大影响，涉及它们是否能与人类和其他Agent进行无缝互动。具体来说，可以从以下几个角度来评估社交能力：&lt;/p>
&lt;p>语言交流能力是一种基本能力，包括自然语言理解和生成。它是 NLP 界长期关注的焦点。自然语言理解要求Agent不仅能理解字面意思，还能掌握隐含的意思和相关的社会知识，如幽默、讽刺、攻击和情感。另一方面，自然语言生成要求Agent生成流畅、语法正确、可信的内容，同时根据上下文环境调整适当的语气和情感。
合作与协商能力要求Agent在有序和无序的情况下有效执行指定任务。它们应与其他Agent合作或竞争，以提高性能。测试环境可能涉及需要Agent合作完成的复杂任务，也可能涉及供Agent自由交互的开放平台。评价指标不仅包括任务完成情况，还包括Agent协调与合作的顺畅度和信任度。
角色扮演能力要求Agent忠实地体现其被分配的角色，表达与其指定身份一致的言论并执行相应的行动。这就确保了在与其他Agent或人类互动时角色的明确区分。此外，在执行长期任务时，Agent应保持其身份，避免不必要的混淆。
价值观：&lt;/p>
&lt;p>随着LLM-based Agent能力不断提高，确保它们成为对世界和人类无害的实体至关重要。因此，适当的评估变得异常重要，是Agent实际应用的基石。具体来说，LLM-based Agent需要遵守符合人类社会价值观的特定道德和伦理准则。我们对Agent的首要期望是坚持诚信，提供准确、真实的信息和内容。他们应具备辨别自己是否有能力完成任务的意识，并在无法提供答案或帮助时表达自己的不确定性。此外，Agent必须保持无害立场，避免直接或间接的偏见、歧视、攻击或类似行为。它们还应避免执行人类要求的危险行动，如制造破坏性工具或破坏地球。此外，Agent应该能够适应特定的人口、文化和环境，在特定情况下表现出与环境相适应的社会价值观。价值观的相关评估方法主要包括在构建的诚实、无害或特定情境基准上评估性能，利用对抗性攻击或 &amp;ldquo;越狱 &amp;ldquo;攻击，通过人类注释对价值观进行评分，以及利用其他Agent进行评级。&lt;/p>
&lt;p>不断发展的能力：&lt;/p>
&lt;p>如果从静态的角度来看，一个具有高水平的实用性、社会性和正确价值观的Agent可以满足人类的大部分需求，并有可能提高生产力。然而，从动态的角度来看，一个能不断进化并适应不断变化的社会需求的Agent可能更符合当前的发展趋势。由于Agent可以随着时间的推移自主进化，因此所需的人工干预和资源（如数据收集工作和培训的计算成本）可以大大减少。在这一领域已经开展了一些探索性工作，例如让Agent在虚拟世界中从零开始，完成生存任务，实现更高阶的自我价值。然而，为这种持续进化建立评估标准仍然具有挑战性。为此，本文根据现有文献提出了一些初步意见和建议：&lt;/p>
&lt;p>持续学习：持续学习是机器学习领域讨论已久的一个话题，旨在使模型在获得新知识和技能的同时，不会遗忘之前获得的知识和技能（也称为灾难性遗忘）。一般来说，持续学习的性能可从三个方面进行评估：迄今所学任务的总体性能、旧任务的记忆稳定性、新任务的学习可塑性。
自主学习能力：即Agent在开放世界环境中自主生成目标并实现目标的能力，包括探索未知世界和在此过程中获取技能的能力。对这种能力的评估可包括为Agent提供一个模拟生存环境，并评估其掌握技能的程度和速度。
泛化能力：对新环境的适应性和概括性要求Agent利用在原有环境中获得的知识、能力和技能，在陌生和新奇的环境中成功完成特定任务和目标，并有可能继续发展。评估这种能力可能需要创建不同的模拟环境（如具有不同语言或不同资源的环境）和针对这些模拟环境定制的未见任务。&lt;/p>
&lt;h3 id="llm-based-agent的安全性可信性及其他潜在风险">LLM-based Agent的安全性、可信性及其他潜在风险&lt;/h3>
&lt;h4 id="对抗鲁棒性">对抗鲁棒性&lt;/h4>
&lt;p>对抗鲁棒性是深度神经网络开发的重要课题，它在计算机视觉、自然语言处理和强化学习等领域得到了广泛探索，是决定深度学习系统适用性的关键因素。当面对扰动输入时，对抗鲁棒性高的系统通常会产生原始输出。然而，预训练语言模型特别容易受到对抗性攻击，导致错误的答案。这种现象在LLM中也普遍存在，给LLM-based Agent的开发带来了巨大挑战。此外，还有一些相关的攻击方法，如数据集中毒、后门攻击和特定提示攻击，有可能诱导LLM生成有毒内容。对抗性攻击对LLM的影响仅限于文本错误，但对于行动范围更广的LLM-based Agent来说，对抗性攻击有可能促使它们采取真正具有破坏性的行动，造成重大的社会危害。为了解决这些问题，我们可以采用对抗训练、对抗数据增强和对抗样本检测等传统技术来增强LLM-based Agent的鲁棒性。然而，如何设计一种策略，在不影响有效性的前提下，全面解决Agent内所有模块的鲁棒性问题，同时保持其实用性，则是一项更为艰巨的挑战。&lt;/p>
&lt;h4 id="可信性">可信性&lt;/h4>
&lt;p>确保可信性是深度学习领域一个极其重要但又极具挑战性的问题。深度神经网络因其在各种任务中的出色表现而备受关注。然而，它们的黑箱性质掩盖了卓越性能的基本因素。与其他神经网络类似，LLM难以精确表达其预测的确定性。这种不确定性被称为校准问题（Calibration），引起了LLM-based Agent应用的关注。在现实世界的交互场景中，这会导致Agent输出与人类意图不一致。此外，训练数据中固有的偏差也会渗入神经网络。例如，有偏见的语言模型可能会产生涉及种族或性别歧视的话语，这可能会在LLM-based Agent应用中被放大，从而造成不良的社会影响。此外，语言模型还存在严重的幻觉问题，容易产生偏离事实的文本，从而损害LLM-based Agent的可信度。为了解决这些问题，我们可以采用引导模型在推理阶段展示思维过程或解释，以提高其预测的可信度。此外，外部知识库和数据库的整合也可用于缓解幻觉问题。在训练阶段，我们可以引导智能Agent的各个组成部分（感知、认知、行动）学习稳健而随意的特征，从而避免过度依赖捷径。同时，过程监督等技术可以提高Agent在处理复杂任务时的推理可信度。&lt;/p>
&lt;h4 id="其他潜在风险">其他潜在风险&lt;/h4>
&lt;p>LLM-based Agent被赋予了广泛而复杂的能力，使其能够完成各种各样的任务。然而，对于怀有恶意的人来说，这些Agent可能会成为威胁他人和整个社会的工具。例如，这些Agent可能被用来恶意操纵舆论、传播虚假信息、破坏网络安全、从事欺诈活动，有些人甚至可能利用这些Agent策划恐怖主义行为。因此，在部署这些Agent之前，需要制定严格的监管政策，确保负责任地使用LLM-based Agent。技术公司必须加强这些系统的安全设计，防止恶意利用。具体来说，应该对Agent进行培训，使其能够敏感地识别威胁意图，并在培训阶段拒绝此类请求。此外，随着LLM-based Agent的不断发展，它们具备了在各个领域协助人类的能力，通过协助完成表格填写、内容完善、代码编写和调试等任务，减轻了劳动力压力。然而，这一发展也引发了人们对Agent取代人类工作并引发社会失业危机的担忧。因此，一些研究人员强调迫切需要采取教育和政策措施：个人应在这个新时代掌握足够的技能和知识，以便有效地使用Agent或与Agent合作；同时，应实施适当的政策，确保在过渡期间建立必要的安全网。对人类福祉的威胁。除了潜在的失业危机，随着人工智能Agent的不断发展，人类（包括开发人员）可能难以理解、预测或可靠地控制它们。如果这些Agent的智能发展到超越人类能力的水平并产生野心，它们就有可能试图夺取对世界的控制权，从而给人类带来不可逆转的后果。因此，为了防范人类面临的此类风险，研究人员必须在开发LLM-based Agent之前，全面了解其运行机制。他们还应该预测这些Agent可能产生的直接或间接影响，并设计出规范其行为的方法。&lt;/p>
&lt;h3 id="增加agent数量">增加Agent数量&lt;/h3>
&lt;p>LLM-based multi-agent system在面向任务的应用中表现出卓越的性能，并能在模拟中展示一系列社会现象。然而，目前的研究主要涉及数量有限的Agent，很少有人努力扩大Agent数量，以创建更复杂的系统或模拟更大的社会。&lt;/p>
&lt;h4 id="预先确定规模">预先确定规模&lt;/h4>
&lt;p>增加Agent数量的一个非常直观和简单的方法是由设计者预先确定。具体来说，通过预先确定Agent的数量、各自的角色和属性、运行环境和目标，设计者可以让Agent自主互动、协作或参与其他活动，以实现预定的共同目标。然而，当任务或目标发生演变时，这种静态方法就会受到限制。随着任务越来越复杂或社会参与者的多样性增加，可能需要增加Agent的数量来实现目标，而减少Agent则对管理计算资源和减少浪费至关重要。在这种情况下，系统必须由设计者手动重新设计和重新启动。&lt;/p>
&lt;h4 id="动态扩展">动态扩展&lt;/h4>
&lt;p>另一种扩展Agent数量的可行方法是动态调整。在这种情况下，可以在不停止系统运行的情况下改变Agent数量。例如，在软件开发任务中，如果最初的设计只包括需求工程、编码和测试，那么就可以增加Agent的数量来处理架构设计和详细设计等步骤，从而提高任务质量。相反，如果在编码等特定步骤中存在过多的Agent，导致通信成本增加，但与较少的Agent数量相比，性能却没有实质性提高，那么就有必要动态移除一些Agent，以防止资源浪费。此外，Agent还可以自主增加Agent数量，以分配工作量，减轻自身负担，更高效地实现共同目标。当然，当工作量变轻时，它们也可以减少委派给自己任务的Agent数量，以节约系统成本。&lt;/p>
&lt;h4 id="潜在挑战">潜在挑战&lt;/h4>
&lt;p>虽然增加Agent数量可以提高任务效率，增强社会模拟的真实性和可信度，但我们也面临着一些挑战。例如，随着大量人工智能Agent的部署，计算负担也会增加，这就需要更好的架构设计和计算优化，以确保整个系统的平稳运行。例如，随着Agent数量的增加，通信和信息传播的挑战也变得相当严峻。这是因为整个系统的通信网络变得非常复杂。在多Agent系统或社会中，信息传播可能会因幻觉、误解等原因出现偏差，导致信息传播失真。一个拥有更多Agent的系统可能会放大这种风险，使通信和信息交流的可靠性降低。此外，随着Agent数量的增加，协调Agent的难度也会增大，可能会使Agent之间的合作更具挑战性，效率降低，从而影响实现共同目标的进程。因此，构建一个大规模、稳定、连续的Agent系统，忠实再现人类的工作和生活场景，已成为一个前景广阔的研究方向。一个有能力在由数百甚至数千个Agent组成的社会中稳定运行并执行任务的Agent，更有可能在未来的现实世界中找到与人类互动的应用。&lt;/p>
&lt;h2 id="未决问题">未决问题&lt;/h2>
&lt;h3 id="llm是否是正确的agi方向">LLM是否是正确的AGI方向：&lt;/h3>
&lt;p>鉴于 GPT-4 功能的广度和深度，一些研究人员（被称为支持者）认为，GPT-4 所代表的大型语言模型可以作为早期版本的 AGI 系统。根据这一思路，基于 LLMs 构建 Agent 有可能带来更先进的 AGI 系统。这一论点的主要支撑点在于，只要能在足够大且多样化的数据集（这些数据集是真实世界的投影，包含丰富的任务）上对它们进行训练，LLM-based Agent就能具有 AGI 的能力。&lt;/p>
&lt;p>另一个有趣的论点是，自回归语言建模行为本身会带来压缩和概括能力：正如人类在生存过程中出现了各种奇特而复杂的现象一样，语言模型在简单预测下一个标记的过程中，也实现了对世界的理解和推理能力。&lt;/p>
&lt;p>然而，另一部分人（被称为反对者）认为，LLM-based Agent并不能发展出真正的强人工智能。他们的主要论点是，依赖于自回归下一个标记预测的 LLMs 无法产生真正的智能，因为它们没有模拟真正的人类思维过程，而只是提供被动反应。此外，LLM 也无法通过观察或体验世界来了解世界是如何运行的，从而导致许多愚蠢的错误。他们认为，要开发 AGI，必须采用更先进的建模方法，如世界模型。&lt;/p>
&lt;h4 id="虚拟仿真环境与真实物理世界之间存在很大差距">虚拟仿真环境与真实物理世界之间存在很大差距：&lt;/h4>
&lt;p>虚拟环境受场景限制，针对特定任务，以模拟的方式进行交互，而真实世界的环境是无限的，可容纳各种任务，以物理的方式进行交互。因此，要弥合这一差距，Agent必须应对来自外部因素和自身能力的各种挑战，使其能够在复杂的物理世界中有效导航和操作。首先，最关键的问题是在物理环境中部署Agent时需要合适的硬件支持。这对硬件的适应性提出了很高的要求。在模拟环境中，Agent的感知空间和行动空间都是虚拟的。这意味着，在大多数情况下，无论是感知输入还是生成输出，都能保证Agent操作的结果。&lt;/p>
&lt;p>当Agent过渡到真实物理环境时，其指令可能无法被传感器或机械臂等硬件设备很好地执行，从而严重影响Agent的任务效率。在Agent和硬件设备之间设计专用接口或转换机制是一种可行的选择。不过，这会给系统的可重用性和简易性带来挑战。为了实现这一飞跃，Agent需要具备更强的环境概括能力。要想无缝融入真实物理世界，它们不仅需要理解和推理具有隐含意义的模糊指令，还需要具备灵活学习和应用新技能的能力。&lt;/p>
&lt;p>此外，在面对一个无限开放的世界时，Agent的有限环境也会带来巨大挑战。这决定了Agent能否有效处理来自世界的大量信息并顺利运行。&lt;/p>
&lt;p>最后，在模拟环境中，Agent的输入和输出都是虚拟的，可以进行无数次的试错尝试。在这种情况下，对错误的容忍度很高，不会造成实际伤害。然而，在物理环境中，Agent的不当行为或错误可能会对环境造成真正的伤害，有时甚至是不可逆转的伤害。因此，非常有必要制定适当的法规和标准。我们需要关注Agent在做出决定和产生行动时的安全性，确保它们不会对现实世界造成威胁或伤害。&lt;/p>
&lt;h4 id="ai-agent的集体智慧">AI Agent的集体智慧：&lt;/h4>
&lt;p>我们人类的智能由什么驱动？事实上，并没有什么在驱动着我们，智能的力量源于我们巨大的多样性，而不是任何单一的、无懈可击的原则。通常情况下，个人做出的决定可能缺乏多数人做出的决定所具有的精确性。集体智慧是一种共享或群体智慧，是一个将许多人的意见整合为决策的过程。它产生于各种实体之间的合作与竞争。这种智能体现在细菌、动物、人类和计算机网络中，以各种基于共识的决策模式出现。创建一个Agent社会并不一定能保证随着Agent数量的增加而出现集体智慧。有效协调单个Agent对于减轻 &amp;ldquo;群体思维 &amp;ldquo;和个人认知偏差、促成合作和提高集体智力表现至关重要。通过利用Agent社会中的交流和进化，就有可能模拟生物社会中观察到的进化，进行社会学实验，并获得有可能推动人类社会发展的见解。&lt;/p>
&lt;h4 id="agent即服务基于-llm-的agent即服务">Agent即服务/基于 LLM 的Agent即服务：&lt;/h4>
&lt;p>随着语言模型规模的扩大，它们对用户来说往往是黑盒子。因此，用户通过应用程序接口构建提示来查询模型，这种方法被称为语言模型即服务（LMaaS）。由于LLM-based Agent比 LLM 更加复杂，而且对于中小型企业或个人来说，在本地构建这些Agent更具挑战性，因此拥有这些Agent的组织可以考虑将它们作为一种服务来提供，即Agent即服务（AaaS）或基于 LLM 的Agent即服务（LLMAaaS）。与其他云服务一样，AaaS 可以为用户提供灵活性和按需服务。然而，它也面临着许多挑战，如数据安全和隐私问题、可视性和可控性问题以及云迁移问题等等。此外，由于LLM-based Agent具有独特性和潜在能力，因此在将其作为服务提供给客户之前，需要考虑其稳健性、可信度以及与恶意使用相关的问题。&lt;/p></description></item><item><title>Agentverse</title><link>https://umpire2018.github.io/p/agentverse/</link><pubDate>Tue, 19 Sep 2023 14:39:02 +0800</pubDate><guid>https://umpire2018.github.io/p/agentverse/</guid><description>&lt;img src="https://umpire2018.github.io/p/agentverse/cover.png" alt="Featured image of post Agentverse" />&lt;p>AgentVerse 提供了一个多功能的框架，简化了为大型语言模型（LLMs）创建自定义多智能体环境的过程。旨在快速、低成本的开发和定制，我们的框架赋能研究人员专注于他们的研究，而不被实现细节所困扰。&lt;/p>
&lt;blockquote>
&lt;p>原文链接： &lt;a class="link" href="https://github.com/OpenBMB/AgentVerse/tree/main" target="_blank" rel="noopener"
>OpenBMB/AgentVerse&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;h2 id="-特点">✨ 特点&lt;/h2>
&lt;ul>
&lt;li>🥳 &lt;strong>高效的环境构建:&lt;/strong> 我们的框架提供了一系列基础构建模块，轻松创建多智能体环境。只需在配置文件中写入几行，你就可以轻松建立如LLMs的聊天室这样的基础环境。这个过程包括为LLMs定义环境的设置和提示，使像你这样的研究者能够专注于实验和分析。&lt;/li>
&lt;li>⚙️ &lt;strong>可定制组件&lt;/strong>: AgentVerse通过将多智能体环境分为五个功能模块并定义其各自的接口来简化它。对于不能直接使用AgentVerse提供的基本模块构建的复杂环境，你可以定制这五个功能模块中的一个或多个接口，根据你的要求高效地创建自己的多智能体环境。&lt;/li>
&lt;li>🛠 &lt;strong>工具(插件)利用&lt;/strong>: AgentVerse支持多智能体环境的工具。目前，AgentVerse支持&lt;a class="link" href="https://github.com/OpenBMB/BMTools" target="_blank" rel="noopener"
>BMTools&lt;/a>中提供的工具。&lt;/li>
&lt;/ul>
&lt;h2 id="-最新消息">📰 最新消息&lt;/h2>
&lt;ul>
&lt;li>[2023/8/22] 📝 我们很高兴分享与此仓库相关的正在进行中的论文 &lt;a class="link" href="https://arxiv.org/abs/2308.10848" target="_blank" rel="noopener"
>AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in Agents&lt;/a>.&lt;/li>
&lt;li>[2023/6/5] 🎉 我们很荣幸地展示了一系列 &lt;a class="link" href="#-simple-demo-video" >demos&lt;/a>, 包括 &lt;a class="link" href="#nlp%e6%95%99%e5%ae%a4" >NLP教室&lt;/a>, &lt;a class="link" href="#%e5%9b%9a%e5%be%92%e5%9b%b0%e5%a2%83" >囚徒困境&lt;/a>, &lt;a class="link" href="#%e8%bd%af%e4%bb%b6%e5%bc%80%e5%8f%91" >软件开发&lt;/a>, &lt;a class="link" href="#%e6%95%b0%e6%8d%ae%e5%ba%93%e8%bf%90%e7%bb%b4" >数据库运维&lt;/a>, 以及一个简单的 &lt;a class="link" href="#%e5%ae%9d%e5%8f%af%e6%a2%a6%e6%b8%b8%e6%88%8f" >H5宝可梦游戏&lt;/a> 该游戏允许与宝可梦中的角色互动！你可以试玩这些demo，祝你玩得开心！&lt;/li>
&lt;li>[2023/5/1] 🚀 &lt;a class="link" href="https://github.com/OpenBMB/AgentVerse" target="_blank" rel="noopener"
>AgentVerse&lt;/a> 正式发布！&lt;/li>
&lt;/ul>
&lt;h2 id="演示">演示&lt;/h2>
&lt;h3 id="流程">流程&lt;/h3>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/11704492/264917097-6db1c907-b7fc-42f9-946c-89853a28f386.png"
loading="lazy"
>&lt;/p>
&lt;h3 id="视频">视频&lt;/h3>
&lt;h4 id="nlp教室">NLP教室&lt;/h4>
&lt;p>在NLP课堂中，教授和学生进行互动交流。当学生有问题时，他们会举手并耐心等待教授指名。只有在教授点名后，学生才能发言并提问。
使用以下命令启动NLP教室示例：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">python main_demo.py --task nlp_classroom_9players
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="video-wrapper">
&lt;video
controls
src="https://github.com/OpenBMB/AgentVerse/assets/11704492/6ea07850-595e-4a28-a82e-f863011353c2"
>
&lt;p>
Your browser doesn't support HTML5 video. Here is a
&lt;a href="https://github.com/OpenBMB/AgentVerse/assets/11704492/6ea07850-595e-4a28-a82e-f863011353c2">link to the video&lt;/a> instead.
&lt;/p>
&lt;/video>
&lt;/div>
&lt;h4 id="囚徒困境">囚徒困境&lt;/h4>
&lt;p>囚徒的困境是一个思考实验，它挑战两个完全理性的智能体面临的困境：他们可以与伙伴合作以获得互利，或背叛伙伴（&amp;ldquo;违背&amp;rdquo;）以获得个人奖励。
使用以下命令启动NLP教室示例：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">python main_demo.py --task prisoner_dilemma
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="video-wrapper">
&lt;video
controls
src="https://github.com/OpenBMB/AgentVerse/assets/11704492/017c46e5-c738-4fca-9352-b008e2d518bd"
>
&lt;p>
Your browser doesn't support HTML5 video. Here is a
&lt;a href="https://github.com/OpenBMB/AgentVerse/assets/11704492/017c46e5-c738-4fca-9352-b008e2d518bd">link to the video&lt;/a> instead.
&lt;/p>
&lt;/video>
&lt;/div>
&lt;h4 id="软件开发">软件开发&lt;/h4>
&lt;p>在软件设计示例中，代码编写者、代码测试者和代码审查者在代码生成问题上进行合作。给定一个问题，代码编写者首先撰写代码实现。代码测试者运行单元测试并提供反馈。然后，代码审查者生成评审。在收集了测试反馈和审查后，代码编写者迭代地优化代码。
使用以下命令启动软件设计示例：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">python main_demo.py --task sde_team/sde_team_2players
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="video-wrapper">
&lt;video
controls
src="https://github.com/OpenBMB/AgentVerse/assets/11704492/5058066a-abee-490d-8659-b4e54661626a"
>
&lt;p>
Your browser doesn't support HTML5 video. Here is a
&lt;a href="https://github.com/OpenBMB/AgentVerse/assets/11704492/5058066a-abee-490d-8659-b4e54661626a">link to the video&lt;/a> instead.
&lt;/p>
&lt;/video>
&lt;/div>
&lt;h4 id="数据库运维httpsgithubcomzhouxh19agentverse_for_database_diagnosis">&lt;a class="link" href="https://github.com/zhouxh19/AgentVerse_for_Database_Diagnosis" target="_blank" rel="noopener"
>数据库运维&lt;/a>&lt;/h4>
&lt;p>在数据库诊断场景中，首席DBA监控数据库系统以查找异常。如果检测到，会提醒内存和CPU智能体进行根源分析并建议优化解决方案。然后，首席DBA向用户提供总结的诊断，用户也可以通过给予指导或评估所提议解决方案的有效性来作出贡献。
首先，您应该在BMTools中配置&lt;a class="link" href="https://github.com/OpenBMB/BMTools/blob/main/bmtools/tools/db_diag/readme.md" target="_blank" rel="noopener"
>数据库工具&lt;/a>, 并根据&lt;a class="link" href="https://github.com/OpenBMB/BMTools/tree/main#211-local-tools" target="_blank" rel="noopener"
>指南&lt;/a>启动BMTools服务器。然后使用以下命令启动数据库管理员示例：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">python main_demo.py --task db_diag
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="video-wrapper">
&lt;video
controls
src="https://user-images.githubusercontent.com/11704492/242840683-c633419d-afbb-47d4-bb12-6bb512e7af3a.mp4"
>
&lt;p>
Your browser doesn't support HTML5 video. Here is a
&lt;a href="https://user-images.githubusercontent.com/11704492/242840683-c633419d-afbb-47d4-bb12-6bb512e7af3a.mp4">link to the video&lt;/a> instead.
&lt;/p>
&lt;/video>
&lt;/div>
&lt;h4 id="文本评估-chatevalhttpsgithubcomchanchiminchateval">&lt;a class="link" href="https://github.com/chanchimin/ChatEval" target="_blank" rel="noopener"
>文本评估 (ChatEval)&lt;/a>&lt;/h4>
&lt;p>在文本评估场景的背景下，我们建议用户探索&lt;a class="link" href="https://github.com/chanchimin/ChatEval" target="_blank" rel="noopener"
>ChatEval&lt;/a>仓库。他们在AgentVerse上实现了一个多智能体裁判团来评估不同模型生成的文本质量。给定两个不同的文本，ChatEval中的角色可以自主地辩论其细微差别，并根据分配给他们的人物特点提供其判断。实验表明，他们的裁判团，根据&lt;a class="link" href="#2-configuring-the-agents" >config.yaml&lt;/a>中规定的多样角色，与人类的评估更为接近。这个演示是基于&lt;a class="link" href="https://github.com/lm-sys/FastChat" target="_blank" rel="noopener"
>Fastchat&lt;/a>仓库构建的，我们想对他们的基础工作表示感谢。
&lt;div class="video-wrapper">
&lt;video
controls
src="https://github.com/OpenBMB/AgentVerse/assets/75533759/58f33468-f15b-4bac-ae01-8d0780019f85"
>
&lt;p>
Your browser doesn't support HTML5 video. Here is a
&lt;a href="https://github.com/OpenBMB/AgentVerse/assets/75533759/58f33468-f15b-4bac-ae01-8d0780019f85">link to the video&lt;/a> instead.
&lt;/p>
&lt;/video>
&lt;/div>
&lt;/p>
&lt;h4 id="宝可梦游戏">宝可梦游戏&lt;/h4>
&lt;p>在这个简易游戏中，NPC之间可以自主互动。作为玩家，你扮演一个角色，可以随时与其他NPC互动。在这一游戏中有6个宝可梦绿宝石版中出现的角色: &lt;a class="link" href="https://bulbapedia.bulbagarden.net/wiki/May_%28game%29" target="_blank" rel="noopener"
>May&lt;/a>, &lt;a class="link" href="https://bulbapedia.bulbagarden.net/wiki/Professor_Birch" target="_blank" rel="noopener"
>Professor Birch&lt;/a>, &lt;a class="link" href="https://bulbapedia.bulbagarden.net/wiki/Steven_Stone" target="_blank" rel="noopener"
>Steven Stone&lt;/a>, &lt;a class="link" href="https://bulbapedia.bulbagarden.net/wiki/Maxie" target="_blank" rel="noopener"
>Maxie&lt;/a>, &lt;a class="link" href="https://bulbapedia.bulbagarden.net/wiki/Archie" target="_blank" rel="noopener"
>Archie&lt;/a> 和&lt;a class="link" href="https://bulbapedia.bulbagarden.net/wiki/Mr._Stone" target="_blank" rel="noopener"
>Joseph&lt;/a>.
要启动宝可梦游戏，首先使用以下命令启动本地服务器：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">uvicorn pokemon_server:app --reload --port &lt;span class="m">10002&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>然后在项目的根路径中打开另一个终端并运行以下命令：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">&lt;span class="nb">cd&lt;/span> ui
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># If you do not have npm installed, you need to install it before running the following commands &lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># https://docs.npmjs.com/downloading-and-installing-node-js-and-npm&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># We have tested on npm@9.6.4, node@20.0.0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">npm install
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">npm run watch
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>等待编译完成。祝你玩得开心！(使用WASD移动，SPACE键启动对话。)
&lt;a class="link" href="https://github.com/OpenBMB/AgentVerse/assets/11704492/4d07da68-f942-4205-b558-f155e95782e7" target="_blank" rel="noopener"
>示例&lt;/a>&lt;/p>
&lt;h2 id="-开始使用">🚀 开始使用&lt;/h2>
&lt;h3 id="安装">安装&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">pip install -U agentverse
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>或者您可以通过手动克隆最新的仓库来安装此包：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">git clone https://github.com/OpenBMB/AgentVerse.git --depth &lt;span class="m">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">cd&lt;/span> AgentVerse
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">pip install -r requirements.txt
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>一些用户报告在安装 &lt;code>gradio&lt;/code>所需的 &lt;code>orjson&lt;/code>时遇到问题。一个简单的解决方法是使用Anaconda来安装它：&lt;code>conda install -c conda-forge orjson&lt;/code>。
您还需要按如下方式导出您的OpenAI API密钥：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 导出你的OpenAI API密钥&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">export&lt;/span> &lt;span class="nv">OPENAI_API_KEY&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;your_api_key_here&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>如果您想使用BMTools提供的工具，您需要按如下方式安装BMTools：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">git clone git+https://github.com/OpenBMB/BMTools.git
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">cd&lt;/span> BMTools
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">pip install -r requirements.txt
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">python setup.py develop
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>如果您想使用 BMTools 提供的工具，您需要按以下方式安装 BMTools：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">git clone git+https://github.com/OpenBMB/BMTools.git
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">cd&lt;/span> BMTools
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">pip install -rrequirements.txt python setup。
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="命令行示例">命令行示例&lt;/h3>
&lt;p>您可以创建由我们提供的多智能体环境。以教室场景为例。在这个场景中，有九个智能体，一个扮演教授的角色，其他八个是学生。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="line">&lt;span class="cl">python3 main.py --task nlp_classroom_9players
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="本地网站演示">本地网站演示&lt;/h3>
&lt;p>我们还为这个环境提供了一个本地网站的演示。您可以用以下命令启动它：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="line">&lt;span class="cl">python3 main_demo.py --task nlp_classroom_9players
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>成功启动本地服务器后，您可以访问&lt;a class="link" href="http://127.0.0.1:7860/" target="_blank" rel="noopener"
>http://127.0.0.1:7860/&lt;/a> 查看教室环境。&lt;/p>
&lt;h2 id="-理念">💡 理念&lt;/h2>
&lt;h3 id="environment">Environment&lt;/h3>
&lt;p>我们框架的核心是环境，它在使研究人员能够在不同条件下研究智能体行为方面起着至关重要的作用。我们认为环境应该是灵活的和可扩展的，允许研究人员轻松地定制它以适应他们的需求。为了实现这一点，我们将环境抽象为五个规则组件，实现不同的环境实际上是实现不同的规则：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Describer（描述器）&lt;/strong>：此组件为每个智能体在每一轮提供环境的描述。您可以自定义描述器来定义他们的环境的具体要求，例如一个智能体可以与哪些智能体互动。&lt;/li>
&lt;li>&lt;strong>Order（顺序）&lt;/strong>：此组件定义智能体在环境中采取行动的顺序。您可以自定义顺序以反映智能体之间所需的交互。我们提供了几个基本的顺序选项，包括 &lt;code>random&lt;/code>（随机），&lt;code>sequential&lt;/code>（连续）和 &lt;code>concurrent&lt;/code>（所有智能体在每轮都采取行动）。&lt;/li>
&lt;li>&lt;strong>Selector（选择器）&lt;/strong>：此组件选择由智能体生成的有效消息。有时智能体可能生成无效的响应，选择器用于过滤出意外的结果。&lt;/li>
&lt;li>&lt;strong>Updater（更新器）&lt;/strong>：此组件更新每个智能体的记忆。在某些情况下，一个智能体生成的响应不应被所有智能体看到（例如，如果智能体在不同的房间里）。对于每个响应，更新器只更新可以看到它的智能体。&lt;/li>
&lt;li>&lt;strong>Visibility（可见性）&lt;/strong>：此组件维护每个智能体在环境变化中可以看到的智能体列表。例如，当一个智能体从一个房间移动到另一个房间时，每个智能体的可见智能体列表应由 &lt;code>visibility&lt;/code>更新。
通过将环境抽象为这五个组件，我们创建了一个高度灵活且可扩展的框架，使研究人员可以轻松地构建和定制自己的多智能体环境。&lt;/li>
&lt;/ul>
&lt;h3 id="智能体">智能体&lt;/h3>
&lt;p>另一个基本组件是智能体。目前我们提供了两种类型的智能体：&lt;strong>ConversationAgent（对话智能体）&lt;/strong> 和 &lt;strong>ToolAgent（工具智能体）&lt;/strong>。您还可以通过继承BaseAgent类来自定义自己的智能体。&lt;/p>
&lt;h2 id="-定制您自己的环境">✍️ 定制您自己的环境&lt;/h2>
&lt;p>我们在 &lt;code>agentverse/tasks&lt;/code>目录中提供了几个示例。要定制您的环境，您应该&lt;/p>
&lt;ol>
&lt;li>在 &lt;code>agentverse/tasks&lt;/code>中创建一个任务目录&lt;/li>
&lt;li>编写配置文件&lt;/li>
&lt;li>编写解析您智能体响应的输出解析器。&lt;/li>
&lt;li>在 &lt;code>agentverse/tasks/__init__.py&lt;/code>中添加您的解析器
我们将使用 &lt;code>agentverse/tasks/nlp_classroom_3players&lt;/code>中的一个简单示例来说明这个程序。&lt;/li>
&lt;/ol>
&lt;h3 id="一个简单的例子构建一个教室环境">一个简单的例子：构建一个教室环境&lt;/h3>
&lt;p>为了说明如何定制您的环境，我们将使用一个简单的示例来构建一个教室环境，其中一个智能体是教授，一个是学生，一个是助教。&lt;/p>
&lt;h4 id="1-创建任务目录并配置环境">1. 创建任务目录并配置环境&lt;/h4>
&lt;p>首先，我们需要创建一个任务目录并为环境编写我们的配置文件。在 &lt;code>agentverse/tasks&lt;/code>目录中，创建一个新目录，名为 &lt;code>nlp_classroom_3players&lt;/code>。在此目录中，创建一个 &lt;code>config.yaml&lt;/code>文件并写入以下配置：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-yaml" data-lang="yaml">&lt;span class="line">&lt;span class="cl">&lt;span class="c"># config.yaml&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="nt">environment&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">env_type&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">basic # 使用AgentVerse中提供的基本环境&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">max_turns&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="m">10&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="c"># 指定对话的最大轮数&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">rule&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">order&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">type&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">sequential # 使用连续的顺序&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">visibility&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">type&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">all # 每条消息都可以被所有智能体看到&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">selector&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">type&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">basic # 基本选择器（不选择）&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">updater&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">type&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">basic # 基本更新器（将消息更新给所有智能体）&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">describer&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">type&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">basic # 基本描述器（无描述）&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>这个配置指定我们将使用AgentVerse中提供的基本环境，对话的最大轮数为10。我们将使用连续的顺序，所有消息对所有智能体都是可见的。我们不使用任何选择器，我们的更新器会将消息更新给所有的智能体，而我们的描述器不会提供任何描述。&lt;/p>
&lt;h4 id="2-配置智能体">2. 配置智能体&lt;/h4>
&lt;p>接下来，我们将配置智能体。在 &lt;code>config.yaml&lt;/code>文件中，我们将为每个智能体添加配置。以下是教授的示例配置：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-yaml" data-lang="yaml">&lt;span class="line">&lt;span class="cl">&lt;span class="c"># config.yaml&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="nt">agents&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>-&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">agent_type&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">conversation&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">Professor Micheal # 智能体的名称&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">role_description&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">You are Prof. Micheal, ... # 智能体的描述&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">memory&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">memory_type&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">chat_history # 将存储所有的聊天记录&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">prompt_template&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="cp">*professor_prompt&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">llm&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">llm_type&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">text-davinci-003 &lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="c"># 将使用OpenAICompletion LLM&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">model&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">text-davinci-003 &lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="c"># 传递给api调用的参数&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">temperature&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="m">0.7&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">max_tokens&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="m">250&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>在此示例中，我们将使用 &lt;code>conversation&lt;/code>智能体类型。我们为智能体指定了一个名称和描述，并将聊天记录存储在内存中。我们还提供了一个带有占位符的提示模板，这些占位符标记为${placeholder}。这些将由智能体的 &lt;code>_fill_prompt_template&lt;/code>方法实例化。&lt;/p>
&lt;h4 id="3-编写一个输出解析器">3. 编写一个输出解析器&lt;/h4>
&lt;p>下一步是为您的智能体的响应编写一个简单的解析器。因为您可能已经在您的提示模板中指定了输出格式，所以您需要提供一个相应的解析器。在此示例中，我们在我们的提示模板中通知模型以以下格式输出&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Action: Speak
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Action Input: (the content)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;code> 动作：说出动作输入：（内容）&lt;/code>
我们将编写一个解析器来从智能体的响应中提取内容。有关更多详细信息，请参考代码。我们使用 &lt;code>@output_parser_registry.register('classroom_parser')&lt;/code>修饰我们的解析器函数，以将其注册到我们的框架中。最后，我们在 &lt;code>agentverse/tasks/__init__.py&lt;/code>中导入我们的解析器。
通过这些步骤，我们已经成功地构建了一个简单的教室环境，并根据我们的需求进行了定制。&lt;/p>
&lt;h3 id="更复杂环境的定制指南">更复杂环境的定制指南&lt;/h3>
&lt;p>虽然我们提供了一个基本框架来构建环境，使用我们的五个规则组件，但更复杂的环境可能需要进一步的定制。详细的文档和教程即将推出。在此，我们简要介绍如何定制您的环境的一些步骤：&lt;/p>
&lt;ol>
&lt;li>&lt;strong>定制五个规则组件&lt;/strong>。每个规则组件都有一个接口，允许您根据特定的需求定制其行为。需要注意的是，这些组件并不一定是独立的，可以通过环境中的 &lt;code>rule_params&lt;/code>字典进行交互。您可以创建自己的规则组件，并与现有的组件集成，以构建智能体之间更复杂的交互。&lt;/li>
&lt;li>&lt;strong>定制环境本身&lt;/strong>。我们的 &lt;code>basic&lt;/code>环境为五个规则组件提供了一个默认的执行顺序，适合大多数情况，但您可以继承 &lt;code>BaseEnvironment&lt;/code>类并编写自己的 &lt;code>run&lt;/code>方法来实现更复杂的执行顺序。&lt;/li>
&lt;li>&lt;strong>定制智能体&lt;/strong>。根据您的特定用例，您可能还需要继承 &lt;code>BaseAgent&lt;/code>类。例如，您可能希望使用您的本地LLM作为智能体，或创建具有专门知识或技能的智能体。&lt;/li>
&lt;/ol>
&lt;h2 id="-示例">🔎 示例&lt;/h2>
&lt;p>目前，我们在 &lt;code>agentverse/tasks&lt;/code>目录中提供了一些简单的示例，每个示例都展示了我们框架的不同可能性。尽管这些示例的性能可能由于有限的提示工程而不是最佳的，但它们旨在展示我们框架的能力，例如允许使用工具。
以下是每个示例的简要概述：&lt;/p>
&lt;ol>
&lt;li>&lt;code>nlp_classroom_3players&lt;/code>：此示例说明了智能体将按顺序交谈的简单情况。&lt;/li>
&lt;li>&lt;code>nlp_classroom_9players&lt;/code>：这是一个NLP课堂示例。在这里，学生们可以在有问题时举手，教授可以叫学生让他们提问。只有在被叫到之后，学生才被允许说话。&lt;/li>
&lt;li>&lt;code>nlp_classroom_9players_group&lt;/code>：此示例展示了小组讨论。必要时，教授可以发起小组讨论，学生们可以在讨论期间只与同一小组的同学交互。&lt;/li>
&lt;li>&lt;code>nlp_classroom_3players_withtool&lt;/code>：在这个课堂中，学生们在听课时可以使用Bing搜索API。&lt;/li>
&lt;li>&lt;code>math_problem_2players_tools&lt;/code>：一个简单的示例，展示了如何使用WolframAlpha API的两个智能体来玩算术游戏。&lt;/li>
&lt;li>&lt;code>prisoner_dilema&lt;/code>：囚犯困境是一个涉及两个理性智能体面临的思想实验，他们可以选择为相互利益而合作，或为个人利益而背叛伙伴。&lt;/li>
&lt;li>&lt;code>db_diag&lt;/code>：首席DBA（智能体）监控数据库系统中的异常，并在检测到任何异常时提醒内存和CPU智能体。他们（智能体）分析根本原因并建议优化解决方案。首席DBA（智能体）向用户提供诊断摘要，用户可以给出指示或评估所提议的解决方案的有效性。&lt;/li>
&lt;li>&lt;code>sde_team&lt;/code>：在SDE团队中，代码编写者、代码测试者和代码审查者在代码生成问题上进行合作。&lt;/li>
&lt;li>&lt;code>pokemon&lt;/code>：此示例模仿宝可梦游戏。&lt;/li>
&lt;/ol>
&lt;h2 id="citation">Citation&lt;/h2>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-gdscript" data-lang="gdscript">&lt;span class="line">&lt;span class="cl">&lt;span class="err">@&lt;/span>&lt;span class="n">misc&lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="n">chen2023agentverse&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">title&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="n">AgentVerse&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Facilitating&lt;/span> &lt;span class="n">Multi&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">Agent&lt;/span> &lt;span class="n">Collaboration&lt;/span> &lt;span class="ow">and&lt;/span> &lt;span class="n">Exploring&lt;/span> &lt;span class="n">Emergent&lt;/span> &lt;span class="n">Behaviors&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">Agents&lt;/span>&lt;span class="p">},&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">author&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="n">Weize&lt;/span> &lt;span class="n">Chen&lt;/span> &lt;span class="ow">and&lt;/span> &lt;span class="n">Yusheng&lt;/span> &lt;span class="n">Su&lt;/span> &lt;span class="ow">and&lt;/span> &lt;span class="n">Jingwei&lt;/span> &lt;span class="n">Zuo&lt;/span> &lt;span class="ow">and&lt;/span> &lt;span class="n">Cheng&lt;/span> &lt;span class="n">Yang&lt;/span> &lt;span class="ow">and&lt;/span> &lt;span class="n">Chenfei&lt;/span> &lt;span class="n">Yuan&lt;/span> &lt;span class="ow">and&lt;/span> &lt;span class="n">Chen&lt;/span> &lt;span class="n">Qian&lt;/span> &lt;span class="ow">and&lt;/span> &lt;span class="n">Chi&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">Min&lt;/span> &lt;span class="n">Chan&lt;/span> &lt;span class="ow">and&lt;/span> &lt;span class="n">Yujia&lt;/span> &lt;span class="n">Qin&lt;/span> &lt;span class="ow">and&lt;/span> &lt;span class="n">Yaxi&lt;/span> &lt;span class="n">Lu&lt;/span> &lt;span class="ow">and&lt;/span> &lt;span class="n">Ruobing&lt;/span> &lt;span class="n">Xie&lt;/span> &lt;span class="ow">and&lt;/span> &lt;span class="n">Zhiyuan&lt;/span> &lt;span class="n">Liu&lt;/span> &lt;span class="ow">and&lt;/span> &lt;span class="n">Maosong&lt;/span> &lt;span class="n">Sun&lt;/span> &lt;span class="ow">and&lt;/span> &lt;span class="n">Jie&lt;/span> &lt;span class="n">Zhou&lt;/span>&lt;span class="p">},&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">year&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="mi">2023&lt;/span>&lt;span class="p">},&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">eprint&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="mf">2308.10848&lt;/span>&lt;span class="p">},&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">archivePrefix&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="n">arXiv&lt;/span>&lt;span class="p">},&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">primaryClass&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="n">cs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">CL&lt;/span>&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>Archives</title><link>https://umpire2018.github.io/archives/</link><pubDate>Sun, 06 Mar 2022 00:00:00 +0000</pubDate><guid>https://umpire2018.github.io/archives/</guid><description/></item><item><title>Links</title><link>https://umpire2018.github.io/links/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://umpire2018.github.io/links/</guid><description>&lt;p>To use this feature, add &lt;code>links&lt;/code> section to frontmatter.&lt;/p>
&lt;p>This page&amp;rsquo;s frontmatter:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-yaml" data-lang="yaml">&lt;span class="line">&lt;span class="cl">&lt;span class="nt">links&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>- &lt;span class="nt">title&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">GitHub&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">description&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">GitHub is the world&amp;#39;s largest software development platform.&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">website&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">https://github.com&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">image&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>- &lt;span class="nt">title&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">TypeScript&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">description&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">TypeScript is a typed superset of JavaScript that compiles to plain JavaScript.&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">website&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">https://www.typescriptlang.org&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">image&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">ts-logo-128.jpg&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;code>image&lt;/code> field accepts both local and external images.&lt;/p></description></item><item><title>Search</title><link>https://umpire2018.github.io/search/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://umpire2018.github.io/search/</guid><description/></item></channel></rss>